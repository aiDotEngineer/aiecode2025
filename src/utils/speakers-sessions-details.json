[
  {
    "Speaker ID": "ccad15eb-e444-4773-9c0c-8f331f2b5c13",
    "Name": "Tom Smoker",
    "Company": "WhyHow.AI",
    "Company Domain": "whyhow.ai",
    "Company URL": "https://www.whyhow.ai/",
    "Company Website": "https://www.whyhow.ai/",
    "Title": "Co-Founder",
    "TagLine": "Technical Founder ",
    "Bio": "Co-Founder @ WhyHow.AI",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/thomassmoker",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/32a2-400o400o1-72WfcKvQhQ3sFATn9wQxqr.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "900332",
        "Title": "Beyond Documents: Implementing Knowledge Graphs in Legal Agents",
        "Description": "Structured Representations are pretty important in the law, where the relationships between clauses, documents, entities, and multiple parties matter. Structured Representation means Structured Context Injection. Better Context, Less Hallucinations. We walk through a couple of case studies of systems that we‚Äôve built in production for legal use-cases - from recursive contractual clause retrieval, to HITL legal reasoning news agents.\r\n\r\nYou'll gain insights into how structured representations significantly improve the effectiveness and reliability of legal agents.\r\n",
        "Format": "",
        "Level": "Intermediate",
        "Scope": "",
        "Tracks": "GraphRAG",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "fa5f22ad-339b-485d-bbf2-620cbd069be9",
    "Name": "Damien Murphy",
    "Company": "Bench Computing",
    "Company Domain": "bench.io",
    "Company URL": "https://bench.io/",
    "Company Website": "https://bench.io",
    "Title": "Full Stack Developer",
    "TagLine": "Founding Engineer",
    "Bio": "Full Stack Dev for 20+ years focusing on AI Agents",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/damienm1/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/2926-400o400o1-ptD5NY2jT64p32qQh2v4M2.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "911821",
        "Title": "A2A & MCP: Automating Business Processes with LLMs",
        "Description": "Ever wished your webhooks could think for themselves? Join us to discover how A2A agents can transform passive webhook endpoints into intelligent workflow processors.\r\n\r\nIn this session, we'll show you how to build a system that automatically spawns AI Agents to handle incoming webhooks. \r\n\r\nUsing Google's Agent-to-Agent framework and MCP, you'll learn how to create dynamic AI agents that respond to events, communicate with external services, and make decisions based on content analysis.\r\n\r\nSee the future of workflow automation where webhooks don't just trigger actions‚Äîthey trigger intelligence!",
        "Format": "Workshop",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "MCP",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "bb2ab6f3-c148-4f33-b1c8-da2ecdc1b6c7",
    "Name": "Samuel Colvin",
    "Company": "Pydantic Inc.",
    "Company Domain": "pydantic.dev",
    "Company URL": "",
    "Company Website": "https://pydantic.dev/",
    "Title": "Founder",
    "TagLine": "Founder of Pydantic",
    "Bio": "Samuel Colvin is a Python and Rust developer, and Founder of Pydantic Inc., backed by Sequoia to build Pydantic Logfire (AI observability) and PydanticAI (production grade Agent Framework).\r\n\r\n The Pydantic library, which he created in 2017, is downloaded over 300M times per month and is a core component of virtually every GenAI Python library (both provider SDKs and agent frameworks).",
    "X (Twitter)": "https://x.com/samuel_colvin",
    "LinkedIn": "https://www.linkedin.com/in/samuel-colvin/",
    "Blog": "https://github.com/samuelcolvin",
    "Profile Picture": "https://sessionize.com/image/bbf4-400o400o1-Y9XzjuwEQJkVe5LdLiuGmB.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "911925",
        "Title": "MCP is all you need",
        "Description": "Everyone is talking about agents, and right after that, they‚Äôre talking about agent-to-agent communications. Not surprisingly, various nascent, competing protocols are popping up to handle it.\r\n\r\nBut maybe all we need is MCP ‚Äî the OG of GenAI communication protocols (it's from way back in 2024!).\r\n\r\nLast year, Jason Liu gave the second most watched AIE talk ‚Äî ‚ÄúPydantic is all you need‚Äù.\r\n\r\nThis year, I (the creator of Pydantic) am continuing the tradition by arguing that MCP might be all we need for agent-to-agent communications.\r\n\r\nWhat I‚Äôll cover:\r\n\r\n- Misusing Common Patterns: MCP was designed for desktop/IDE applications like Claude Code and Cursor. How can we adapt MCP for autonomous agents?\r\n- Many Common Problems: MCP is great, but what can go wrong? How can you work around it? Can the protocol be extended to solve these issues?\r\n- Monitoring Complex Phenomena: How does observability work (and not work) with MCP?\r\n- Multiple Competing Protocols: A quick run-through of other agent communication protocols like A2A and AGNTCY, and probably a few more by June üò¥\r\n- Massive Crustaceans Party: What might success look like if everything goes to plan?",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "MCP",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "59c828a3-f138-42e6-aef6-658fb368a5f5",
    "Name": "Dani Grant",
    "Company": "Jam.dev",
    "Company Domain": "jam.dev",
    "Company URL": "https://jam.dev/",
    "Company Website": "https://jam.dev",
    "Title": "CEO",
    "TagLine": "CEO",
    "Bio": "Dani Grant is the CEO of Jam, a dev tools startup helping 65,000+ improve their bug reporting process, backed by executives from Apple, GitHub, and Vercel, and VCs such as Village Global (LPs include Mark Zuckerberg, Bill Gates, Jeff Bezos). Before Jam, Dani was an early product manager at Cloudflare, where she worked on core developer products such as 1.1.1.1 (now used by 10 million+ people). She also worked as a VC at Union Square Ventures.",
    "X (Twitter)": "https://x.com/thedanigrant",
    "LinkedIn": "https://www.linkedin.com/in/danigrant/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/f54d-400o400o1-BmuFhJE6JSR34GDt7z5Gok.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "913965",
        "Title": "The AI Engineer‚Äôs Guide to Raising VC",
        "Description": "A no fluff, all tactics discussion. More AI engineers should build startups, the world needs more software. But there‚Äôs a way to raise VC and it‚Äôs hard to do it if you‚Äôve never seen it done. We are going to walk through the exact playbook to raise your first round of funding. We will show you real pitch decks, real cold emails and real term sheets so when you go out to raise your first round of funding, you are setup to do it. Every AI Engineer should be equip to start their own company and this session makes sure raising $$$ is not going to be the blocker.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Leadership: Architects",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "1e3aac41-c748-4eae-a84a-5234414c6983",
    "Name": "Chelcie Taylor",
    "Company": "Notable Capital",
    "Company Domain": "notablecap.com",
    "Company URL": "https://www.notablecap.com/",
    "Company Website": "",
    "Title": "Early Stage AI Apps Investment Lead",
    "TagLine": "Investor ",
    "Bio": "Leading early stage AI apps investments at Notable Capital ($5B AUM VC). ",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/c820-400o400o1-NLe4TJ95okX5sEofbe6bjJ.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "913965",
        "Title": "The AI Engineer‚Äôs Guide to Raising VC",
        "Description": "A no fluff, all tactics discussion. More AI engineers should build startups, the world needs more software. But there‚Äôs a way to raise VC and it‚Äôs hard to do it if you‚Äôve never seen it done. We are going to walk through the exact playbook to raise your first round of funding. We will show you real pitch decks, real cold emails and real term sheets so when you go out to raise your first round of funding, you are setup to do it. Every AI Engineer should be equip to start their own company and this session makes sure raising $$$ is not going to be the blocker.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Leadership: Architects",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "979f5c8a-93fc-406a-aaea-5bab9ca54c8d",
    "Name": "Harald Kirschner",
    "Company": "Microsoft",
    "Company Domain": "microsoft.com",
    "Company URL": "",
    "Company Website": "https://code.visualstudio.com/",
    "Title": "Principal Product Manager",
    "TagLine": "VS Code Team Member",
    "Bio": "I'm Harald Kirschner, a Principal Product Manager at Microsoft working on Visual Studio Code and GitHub Copilot, supporting over 40 million active developers code faster and more efficiently across virtually any programming language. Before Microsoft, I led Developer Experience at Mozilla, where I led Firefox DevTools and helped deliver Firefox Quantum, which doubled browser performance. My background in software engineering, including early work on MooTools, gives me hands-on insight into the challenges developers face daily. When I'm not working, I enjoy hiking California's coastal trails and experimenting with generative art. As a speaker at the AI Engineer Summit, I'm excited to share insights from our work on AI coding tools and Model Context Protocol to help developers achieve flow state even in complex environments.",
    "X (Twitter)": "https://x.com/digitarald",
    "LinkedIn": "https://www.linkedin.com/in/digitarald",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/b3aa-400o400o1-QY9ZDq5tRjNCVFZg4W6j3h.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914489",
        "Title": "Full Spectrum MCP: Uncovering Hidden Servers and Clients Capabilities",
        "Description": "The true power of Model Context Protocol emerges when clients and servers collaborate across the full spectrum of the specification. This talk presents practical examples of how VS Code's comprehensive implementation of MCP transforms the capabilities of AI assistants, making them more contextual, efficient, and user-friendly. We'll showcase advanced features like dynamic tool discovery and workspace-aware roots, demonstrating how they create experiences impossible with standard tools integrations while confronting the reality gap between MCP's theoretical potential and practical implementation challenges.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "MCP",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "0880058d-a4ab-45cd-a57a-912c18d09bd0",
    "Name": "Adam Behrens",
    "Company": "New Generation",
    "Company Domain": "new-gen.ai",
    "Company URL": "https://www.new-gen.ai/",
    "Company Website": "https://www.new-gen.ai/",
    "Title": "Co-founder and CEO",
    "TagLine": "CEO",
    "Bio": "Adam Behrens is the co-founder and CEO of a, a company that partners with global brands and merchants to unlock AI native commerce opportunities. New Gen builds infrastructure for brands to host their own conversational AI experiences and to connect their data into 3rd party chat clients like ChatGPT and Claude. Adam previously worked on trading infrastructure at Bridgewater and Banking-as-a-Service at Stripe. Outside of training AI models he is busy training his 8 month old Vizsla puppy.",
    "X (Twitter)": "https://x.com/etpuisfume",
    "LinkedIn": "https://www.linkedin.com/in/adam-behrens/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/dd9a-400o400o1-aK2KD9ofRRFnkVARmm586d.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914891",
        "Title": "Machines of Buying & Selling Grace",
        "Description": "How to go beyond browser automation to truly agentic commerce, where AI can buy, sell and negotiate on behalf of users and merchants.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Leadership: Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "e770d774-d3ce-487e-b76e-ec767ab4b0e3",
    "Name": "Alex Volkov",
    "Company": "Weights & Biases",
    "Company Domain": "gmail.com",
    "Company URL": "https://wandb.ai/",
    "Company Website": "https://wandb.ai",
    "Title": "AI Evangelist",
    "TagLine": "AI Evangelist",
    "Bio": "Alex Volkov is an AI Evangelist at Weights & Biases as well as the founder and host of ThursdAI, a weekly newsletter and podcast that explores the latest innovations in AI, their practical applications, and the open-source AI community. Alex is an AI startup founder with 20 years of full-stack software engineering experience, offering a deep well of insights into AI innovation. He‚Äôs celebrated for his ability to clarify and summarize the complexities of the rapid AI advances and advocating for its beneficial uses.",
    "X (Twitter)": "https://x.com/altryne",
    "LinkedIn": "",
    "Blog": "https://sub.thursdai.news",
    "Profile Picture": "https://sessionize.com/image/b6dc-400o400o1-n42m8vkZMc2L1ZmuTGD5JD.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915013",
        "Title": "Observable tools - the state of MCP observability",
        "Description": "AI Engineers deserve observable tools! \r\n\r\nMCP getting adoption means that less and less of your agents code is running under your control, and this has DX and observability challenges, let's fix that! \r\n\r\nJoin Alex Volkov from Weights & Biases and Steve Manual from mcp.run on this recap of the current state of MCP observability, including the observable.tools initiative, a recap of where the field stands and what to look forward to + a practical example of MCP tool usage evaluation framework from mcp.run! ",
        "Format": "Talk",
        "Level": "Expert",
        "Scope": "Technical deep dive",
        "Tracks": "MCP",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "ea8c6f3b-982d-4ac8-8a1b-08e569262e93",
    "Name": "Steve Manuel",
    "Company": "Dylibso",
    "Company Domain": "dylibso.com",
    "Company URL": "https://dylibso.com/",
    "Company Website": "https://dylibso.com",
    "Title": "Co-founder & CEO",
    "TagLine": "CEO",
    "Bio": "Steve is the co-founder & CEO of Dylibso, creators of mcp.run. He is an entrepreneur, programmer, guitarist, and general tinkerer. He has been taking things apart and putting them back together since before he can remember‚Ä¶ his first words were, ‚Äúphillips‚Äù and ‚Äúflathead‚Äù.",
    "X (Twitter)": "https://x.com/nilslice",
    "LinkedIn": "https://linkedin.com/in/stevemanuel",
    "Blog": "https://docs.mcp.run/blog",
    "Profile Picture": "https://sessionize.com/image/de67-400o400o1-LvvRAywopMF9HRKLyGKJKh.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915013",
        "Title": "Observable tools - the state of MCP observability",
        "Description": "AI Engineers deserve observable tools! \r\n\r\nMCP getting adoption means that less and less of your agents code is running under your control, and this has DX and observability challenges, let's fix that! \r\n\r\nJoin Alex Volkov from Weights & Biases and Steve Manual from mcp.run on this recap of the current state of MCP observability, including the observable.tools initiative, a recap of where the field stands and what to look forward to + a practical example of MCP tool usage evaluation framework from mcp.run! ",
        "Format": "Talk",
        "Level": "Expert",
        "Scope": "Technical deep dive",
        "Tracks": "MCP",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "6af0adad-3637-4d37-a604-570e28f53773",
    "Name": "Benjamin Eckel",
    "Company": "Dylibso",
    "Company Domain": "dylibso.com",
    "Company URL": "https://www.mcp.run/",
    "Company Website": "https://dylibso.com/",
    "Title": "Co-founder and CTO",
    "TagLine": "Co-Founder of Dylibso",
    "Bio": "Benjamin has over a decade of experience as a software engineer and is the co-founder and CTO of Dylibso. He previously led DX at Recurly and worked on integrations and edge observability at Datadog.",
    "X (Twitter)": "https://twitter.com/bhelx",
    "LinkedIn": "https://www.linkedin.com/in/benjamin-eckel-b025831a3/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/7fc5-400o400o1-sjzbuhKVSFiePoYuFoAtfo.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915013",
        "Title": "Observable tools - the state of MCP observability",
        "Description": "AI Engineers deserve observable tools! \r\n\r\nMCP getting adoption means that less and less of your agents code is running under your control, and this has DX and observability challenges, let's fix that! \r\n\r\nJoin Alex Volkov from Weights & Biases and Steve Manual from mcp.run on this recap of the current state of MCP observability, including the observable.tools initiative, a recap of where the field stands and what to look forward to + a practical example of MCP tool usage evaluation framework from mcp.run! ",
        "Format": "Talk",
        "Level": "Expert",
        "Scope": "Technical deep dive",
        "Tracks": "MCP",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "15688085-28bc-44b9-9c4e-08843c881790",
    "Name": "David Hsu",
    "Company": "Retool ",
    "Company Domain": "retool.com",
    "Company URL": "https://retool.com ",
    "Company Website": "https://retool.com ",
    "Title": "Founder and CEO",
    "TagLine": "CEO",
    "Bio": "David Hsu is the Founder and CEO of Retool, the leading platform for building custom internal tools. Under his leadership, Retool has transformed how companies like Amazon, DoorDash, and Airbnb develop enterprise applications‚Äîhelping them move beyond rigid SaaS solutions to AI-powered, custom-built software that fit their unique workflows. ",
    "X (Twitter)": "https://x.com/dvdhsu",
    "LinkedIn": "https://www.linkedin.com/in/dvdhsu/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/0fa4-400o400o1-JkQHMM1HQ2EBxoYgf3BoaB.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915616",
        "Title": "How agents will unlock the $500B promise of AI",
        "Description": "AI agents are on the cusp of revolutionizing work as we know it. The number of use cases software can tackle is set to explode as AI handles tasks requiring real judgment. But to cross the gap between an interesting AI prototype and an essential business tool, you need agents built by developers with real guardrails and security.\r\n\r\nThis means blending AI assistance with traditional coding in a multimodal approach that maximizes efficiency and control. The future isn't about dropping in an LLM ‚Äî it requires integrating any model, any data, any system to deliver results. \r\n\r\nCompanies utilizing this approach can finally turn their slice of the $500B+ of total AI investment into real business results. \r\n",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Leadership: Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "152141e8-8994-4813-857d-c9dedda1f73f",
    "Name": "Sahil Yadav",
    "Company": "TelemeTrak",
    "Company Domain": "outlook.com",
    "Company URL": "",
    "Company Website": "https://telemetrak.com",
    "Title": "Chief Product Officer",
    "TagLine": "Chief Product Officer",
    "Bio": "Sahil Yadav is Chief Product Officer at TelemeTrak, where he leads AI-powered infrastructure platforms for government and industrial clients. He has previously launched AI based network automation platforms at Cisco, AI driven predictive analytics products at GE, and industrial AI safety systems at Guardhat, each used by Fortune 500 firms and mission-critical operations. With 13+ years of experience in AI product management, he specializes in scaling edge/cloud AI, driving enterprise adoption and operationalizing AI trust. His expertise lies in building resilient, AI-driven systems that work where others break, behind firewalls, across compliance borders, and in zero-trust environments.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/yadavsahil/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/aa4b-400o400o1-PetSwTEPaDhLYGSGW4QQAQ.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916025",
        "Title": "CIOs and Industry Leaders: Do You Trust Your AI‚Äôs Inferences?",
        "Description": "Enterprise AI adoption is accelerating, but with it comes a hard question: Do we trust the model‚Äôs decisions? In this 18-minute talk, I‚Äôll explore the invisible risks behind automated decision-making in safety-critical and revenue-sensitive environments. Drawing on case studies across manufacturing, telecom, and industrial IoT, I‚Äôll highlight how explainability, traceability, and robust guardrails drive adoption and protect enterprise value.\r\nAttendees will walk away with:\r\n‚Ä¢\tA 3-step framework for operationalizing AI trust\r\n‚Ä¢\tReal-world lessons from building guardrails in on-prem and hybrid systems\r\n‚Ä¢\tTools and techniques for debugging and explaining inferences at scale\r\n‚Ä¢\tA blueprint for building trust between models, engineers, and executive stakeholders",
        "Format": "Talk",
        "Level": "Expert",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "1a0174dc-9579-4c49-ace9-af98edbf57ca",
    "Name": "Hariharan Ganesan",
    "Company": "TelemeTrak",
    "Company Domain": "umich.edu",
    "Company URL": "https://telemetrak.com/",
    "Company Website": "",
    "Title": "Sr. Solutions Architect",
    "TagLine": "Sr. Solutions Architect",
    "Bio": "Hari. Gn is a Sr. Solutions Architect with over 15 years of experience delivering supply-chain solutions for global companies such as Google, Wayfair, and Toyota. He specializes in demand forecasting, inventory optimization, and constraint-driven planning, translating complex analytics into actionable, real-world tools.\r\n\r\nPassionate about practical applications of Explainable AI (XAI), Hari has authored two papers in the Journal of Business Forecasting and regularly shares insights with executive-level stakeholders. He believes in a straightforward, no-nonsense approach to AI: clear, practical, and genuinely usable.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/harigsn/",
    "Blog": "https://medium.com/@harign/life-the-universe-and-everything-in-supply-chain-85d0772c79a4",
    "Profile Picture": "https://sessionize.com/image/5953-400o400o1-JQ5nmny3kR7gDvYpVbNu6B.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916025",
        "Title": "CIOs and Industry Leaders: Do You Trust Your AI‚Äôs Inferences?",
        "Description": "Enterprise AI adoption is accelerating, but with it comes a hard question: Do we trust the model‚Äôs decisions? In this 18-minute talk, I‚Äôll explore the invisible risks behind automated decision-making in safety-critical and revenue-sensitive environments. Drawing on case studies across manufacturing, telecom, and industrial IoT, I‚Äôll highlight how explainability, traceability, and robust guardrails drive adoption and protect enterprise value.\r\nAttendees will walk away with:\r\n‚Ä¢\tA 3-step framework for operationalizing AI trust\r\n‚Ä¢\tReal-world lessons from building guardrails in on-prem and hybrid systems\r\n‚Ä¢\tTools and techniques for debugging and explaining inferences at scale\r\n‚Ä¢\tA blueprint for building trust between models, engineers, and executive stakeholders",
        "Format": "Talk",
        "Level": "Expert",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "111470f8-a384-4efd-ae2a-a3babbdfe45c",
    "Name": "Shrestha Basu Mallick",
    "Company": "Google DeepMind",
    "Company Domain": "gmail.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "Group Product Manager and product lead for Gemini API",
    "TagLine": "Product lead, Gemini Developer API",
    "Bio": " Shrestha Basu Mallick is Group Product Manager and product lead for Gemini API at Google DeepMind. Prior to this, Shrestha led product development for AI assistance across all Google coding surfaces. Shrestha‚Äôs first role in Alphabet was at X, the Moonshot Factory, as Head of Product for a materials discovery platform that has since graduated to become its own startup. Before Google, Shrestha has had various roles in product and strategy at Salesforce Einstein, McKinsey, and Docusign. Shrestha holds a PhD in Applied Physics from Stanford.",
    "X (Twitter)": "https://x.com/shresbm",
    "LinkedIn": "https://www.linkedin.com/in/shresthabm/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/1569-400o400o1-pzrEnDpftzqN5XbBvmj6nF.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916131",
        "Title": "Milliseconds to Magic: Real‚ÄëTime Workflows using the Gemini Live API and Pipecat",
        "Description": "The Gemini Live API GA  is now powered by Google's best cost-effective thinking model Gemini 2.5 Flash. We will do a deep dive on the capabilities that the Gemini Live API combined with Pipecat unlock for devs with special focus on session management, turn detection, tool use (including async function calls), proactivity, multilinguality and integration with telephony and other infra. We will demo some of the more innovative capabilities. We will also talk through some customer use cases - especially how customers can use Pipecat to extend these realtime multimodal capabilities to client side applications such as customer support agents, gaming agents, tutoring agents etc. In addition, we also have an experimental version of the Live API powered by with Google's native audio offering that can be tried in an experimental capacity . This experimental model  can communicate with seamless, emotive, steerable, multilingual dialogue and enhances use cases where more natural voices can be a big differentiator. ",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Voice",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "607fd16a-9612-483a-87ba-1d3031d3a155",
    "Name": "Kwindla Kramer",
    "Company": "Daily",
    "Company Domain": "daily.co",
    "Company URL": "https://www.daily.co/",
    "Company Website": "https://openai.com/",
    "Title": "Originator of Pipecat and WebRTC Infrastructure Engineer",
    "TagLine": "CEO ",
    "Bio": "Kwin works on large-scale WebRTC infrastructure at Daily. He is the originator of Pipecat, the widely used, open source, vendor neutral voice agent framework supported by NVIDIA, Google, AWS and used by hundreds of startups. Before co-fonding Daily, Kwin built the sci-fi user interfaces in Minority Report and Iron Man.",
    "X (Twitter)": "https://x.com/kwindla",
    "LinkedIn": "https://www.linkedin.com/in/kwkramer/",
    "Blog": "https://www.linkedin.com/in/sean-dubois/",
    "Profile Picture": "https://sessionize.com/image/d6ae-400o400o1-HJCEgwnJadsHAkcAkU46oh.jpg",
    "Session Count": 4,
    "Sessions": [
      {
        "Session ID": "916131",
        "Title": "Milliseconds to Magic: Real‚ÄëTime Workflows using the Gemini Live API and Pipecat",
        "Description": "The Gemini Live API GA  is now powered by Google's best cost-effective thinking model Gemini 2.5 Flash. We will do a deep dive on the capabilities that the Gemini Live API combined with Pipecat unlock for devs with special focus on session management, turn detection, tool use (including async function calls), proactivity, multilinguality and integration with telephony and other infra. We will demo some of the more innovative capabilities. We will also talk through some customer use cases - especially how customers can use Pipecat to extend these realtime multimodal capabilities to client side applications such as customer support agents, gaming agents, tutoring agents etc. In addition, we also have an experimental version of the Live API powered by with Google's native audio offering that can be tried in an experimental capacity . This experimental model  can communicate with seamless, emotive, steerable, multilingual dialogue and enhances use cases where more natural voices can be a big differentiator. ",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Voice",
        "Room": "",
        "Scheduled At": ""
      },
      {
        "Session ID": "933493",
        "Title": "Realtime conversational video with Pipecat and Tavus",
        "Description": "Tavus shipped the world's first realtime video avatar platform last year. Developers use Tavus' conversational video APIs to create education, social, and customer support agents. The Tavus team built their innovative product using the Pipecat open source framework and Daily's global WebRTC infrastructure. Join us for a technical deep dive into conversational video.",
        "Format": "",
        "Level": "Introductory and overview",
        "Scope": "Technical deep dive",
        "Tracks": "Generative Media",
        "Room": "",
        "Scheduled At": ""
      },
      {
        "Session ID": "933589",
        "Title": "Pipecat Cloud: Enterprise Voice Agents Built On Open Source",
        "Description": "Voice AI agents today can conduct natural, human-like conversations and perform a wide variety of tasks: customer support, lead qualification, healthcare patient intake, market research, and more.\r\n\r\nToday's best voice agents combine: realtime responsiveness, open-ended conversational intelligence, reliable instruction following, and flexible integration with existing back-end systems.\r\n\r\nLearn how to build state of the art voice agents using Pipecat's open source, vendor neutral tooling. You can deploy Pipecat agents to your own infrastructure or to Pipecat Cloud.\r\n\r\nPipecat is used and supported by teams at NVIDIA, AWS, Google DeepMind, OpenAI, and hundreds of other companies.",
        "Format": "",
        "Level": "Intermediate",
        "Scope": "Product launch",
        "Tracks": "Voice",
        "Room": "",
        "Scheduled At": ""
      },
      {
        "Session ID": "915028",
        "Title": "[Voice Keynote] Your realtime AI is ngmi",
        "Description": "Sean DuBois of OpenAI and Pion, and Kwindla Hultman Kramer of Daily and Pipecat, will talk about why you have to design realtime AI systems from the network layer up.\r\n\r\nMost people who build realtime AI apps and frameworks get it wrong. They build from either the model out or the app layer down. But unless you start with the network layer and build up, you'll never be able to deliver realtime audio and video streams reliably. And perhaps even worse, you'll get core primitives wrong: interruption handling, conversation state management, asynchronous function calling.\r\n\r\nSean and Kwin agree on most things: old-school realtime systems people against the rest of the world. But they disagree on some important things, too, and will argue about those things live on stage. Do you need to give developers \"thick\" client-side realtime SDKs? Can you build truly great vendor neutral APIs? (You'll be surprised which of them argues which side, on that topic.)",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "Voice",
        "Room": "Foothill E: Voice",
        "Scheduled At": "4 Jun 2025 11:15 AM"
      }
    ]
  },
  {
    "Speaker ID": "13aa4fa5-29c4-4019-b4e1-ee83caaecb54",
    "Name": "Jerry Liu",
    "Company": "LlamaIndex",
    "Company Domain": "runllama.ai",
    "Company URL": "llamaindex.ai",
    "Company Website": "",
    "Title": "Co-founder/CEO",
    "TagLine": "CEO",
    "Bio": "Jerry is the co-founder/CEO of LlamaIndex, the most accurate and flexible way to automate your document workflows with AI agents. Before this, he led the ML monitoring team at Robust Intelligence, did self-driving AI research at Uber ATG and worked on recommendation systems at Quora.",
    "X (Twitter)": "https://twitter.com/jerryjliu0",
    "LinkedIn": "https://www.linkedin.com/in/jerry-liu-64390071/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/61b9-400o400o1-3brCmcVKAHmSGaKS6QsZmA.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "925259",
        "Title": "Building AI Agents that actually automate Knowledge Work",
        "Description": "Agents are all the rage in 2025, and every single b2b SaaS startup/incumbent promises AI agents that can \"automate work\" in some way. \r\n\r\nBut how do you actually build this? The answer is two fold: \r\n1. really really good tools \r\n2. carefully tailored agent reasoning over these tools that range from assistant-to-automation based UXs.  \r\n\r\nThe main goal of this talk is to a practical overview of agent architectures that can automate real-world work, with a focus on document-centric tasks. Learn the core building blocks of best-in-class \"tools\" around processing, manipulating, and indexing/retrieving PDFs to Excel spreadsheets. Also learn the range of agent architectures suited for different tasks, from chat assistant-based UXs with high human-in-the-loop, to automation UXs that rely on encoding a business process into an end-to-end task solver. These architectures have to be generalizable but also highly accurate as agents get increasingly better at reasoning and code-writing. ",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "592da3f8-71f2-4512-83a7-6d429034e3c4",
    "Name": "Jan Curn",
    "Company": "Apify",
    "Company Domain": "apify.com",
    "Company URL": "https://apify.com/",
    "Company Website": "https://apify.com/",
    "Title": "Founder and CEO",
    "TagLine": "CEO",
    "Bio": "Jan Curn is the founder and CEO of Apify, a full-stack web scraping and automation platform that powers (not only) AI agents with up-to-date data. He has a lifelong passion for software engineering, which earned him an MSc and PhD in computer science and eventually led him to founding Apify. Jan lives between SF and Prague, is active in the tech community in both cities, organizes meetups, and talks about software, startups, or AI.\r\n",
    "X (Twitter)": "https://x.com/jancurn",
    "LinkedIn": "https://www.linkedin.com/in/jancurn/",
    "Blog": "https://blog.apify.com/author/jancurn/",
    "Profile Picture": "https://sessionize.com/image/a3e7-400o400o1-E6G56RwwfBTEJPLpBmoVm2.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "926313",
        "Title": "The rise of the agentic economy on the shoulders of MCP",
        "Description": "Thanks to MCP and all the MCP server directories, agents can now autonomously discover new tools and other agents. This lays down the foundation for the future agentic economy, where businesses will sell to autonomous agents (B2A) and eventually agents will sell to other agents (A2A).\r\n\r\nBut one key part is still missing: agents do not have a standard way to subscribe to external services and pay for them.\r\n\r\nIn this talk, we‚Äôll show how to give agents full autonomy to discover and pay for new external MCP-enabled services, even if those services don‚Äôt support it, using a little-known MCP server nesting capability. We‚Äôll also cover how to monetize AI agents and the B2A/A2A business models.\r\n",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "MCP",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "779d4c60-5b5f-4fed-8ef9-ce0ae17118a5",
    "Name": "Jerome Swannack",
    "Company": "Anthropic",
    "Company Domain": "anthropic.com",
    "Company URL": "https://www.anthropic.com/",
    "Company Website": "https://www.anthropic.com/",
    "Title": "MCP Team Member",
    "TagLine": "Anthropic, MCP Team",
    "Bio": "[PLACEHOLDER]",
    "X (Twitter)": "https://x.com/jeromeswannack",
    "LinkedIn": "https://www.linkedin.com/in/jerome-swannack-1ba18173/",
    "Blog": "https://www.jeromeswannack.com/",
    "Profile Picture": "https://sessionize.com/image/495b-400o400o1-9jSKoLHfBgyuTQLzF5RoNR.png",
    "Session Count": 2,
    "Sessions": [
      {
        "Session ID": "927452",
        "Title": "[Placeholder] MCP Origins",
        "Description": "Early prototypes and demos from inside anthropic that have guided our thinking around MCP",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "MCP",
        "Room": "",
        "Scheduled At": ""
      },
      {
        "Session ID": "927453",
        "Title": "[PLACEHOLDER] Anthropic MCP team talk 2",
        "Description": "PLACEHOLDER",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "MCP",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "d74b6675-44e2-405a-a6ea-7aa9a936afcd",
    "Name": "Scott Wu",
    "Company": "Cognition AI",
    "Company Domain": "cognition.ai",
    "Company URL": "https://www.cognition.ai/",
    "Company Website": "",
    "Title": "Co-founder and CEO",
    "TagLine": "CEO, Cognition AI",
    "Bio": "Scott is the co-founder and CEO of Cognition AI. He previously competed in international programming competitions (3x IOI gold medalist) and co-founded Lunchclub, an AI-powered professional networking platform. Scott grew up in Louisiana and attended Harvard University.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/4451-400o400o1-Q2qxyaTy4WDg4wE4m1mRrf.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "929855",
        "Title": "Devin 2.0 and the Future of SWE",
        "Description": "A talk on the future of software engineering with Scott Wu of Cognition AI, the makers of Devin.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "SWE Agents",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "ca0c85d0-179e-481e-8fbd-b6afb70f18dd",
    "Name": "Peter Bar",
    "Company": "Intercom",
    "Company Domain": "intercom.io",
    "Company URL": "https://www.intercom.com/",
    "Company Website": "https://www.intercom.com/",
    "Title": "Product Lead",
    "TagLine": "Product Lead, Voice AI",
    "Bio": "I‚Äôm Peter Bar, a Product Lead with over 10 years of experience in the tech industry. At Intercom, I‚Äôm responsible for Voice AI initiatives and led the development and launch of Fin Voice, our AI voice agent. My background spans both B2B and consumer tech, blending technical depth with strategic product leadership. Before Intercom, I drove growth and customer experience efforts at Deliveroo (food delivery) and worked on music discovery products at Shazam. I hold a Master‚Äôs degree in Computer Science from Imperial College London.",
    "X (Twitter)": "https://x.com/PeterAlexBar",
    "LinkedIn": "https://www.linkedin.com/in/peterbar/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/3d1b-400o400o1-PDYvtgvYRGbRFtDmb13wfD.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "931123",
        "Title": "Shipping an Enterprise Voice‚ÄØAI Agent in 100‚ÄØDays",
        "Description": "What does it take to go from blank page to live enterprise voice agent in 100 days?\r\n\r\nThat‚Äôs the challenge we took on with Fin Voice at Intercom. Enterprise customer service demands high-quality, reliable voice interactions - but delivering that fast means wrestling with tough problems like latency, hallucinations, voice quality, and answer accuracy.\r\n\r\nWe rapidly evaluated and integrated a full voice stack - including transcription, language model, text-to-speech, retrieval-augmented generation, and telephony - while designing tools that fit seamlessly into existing human support workflows.\r\n\r\nIn this session, I‚Äôll share key lessons from our accelerated development of Fin Voice. We'll explore the technical and operational hurdles we faced, the trade-offs we made, and how we built deployment and handover tools that work for customer service teams. You'll leave with insights into building AI-driven voice products that are both powerful and practical.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Voice",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "7caad073-31e6-4fac-b598-3d8f2262fad2",
    "Name": "Tom Shapland, PhD",
    "Company": "LiveKit",
    "Company Domain": "livekit.io",
    "Company URL": "https://livekit.io/",
    "Company Website": "https://livekit.io/",
    "Title": "Product Manager",
    "TagLine": "Product Manager",
    "Bio": "Tom Shapland, PhD, is a Product Manager at LiveKit. LiveKit is an open source platform for building, deploying, and scaling realtime multimodal agents. He's passionate about the multimodal future of human-computer interfaces. Before LiveKit, he was the cofounder of a Voice AI observability platform (Canonical AI) and an agriculture technology startup (Tule, YC S14). He lives in the East Bay and coaches lacrosse for his two kids. ",
    "X (Twitter)": "https://x.com/tom_shapland",
    "LinkedIn": "https://www.linkedin.com/in/tom-shapland-b4494212/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/65a4-400o400o1-GmcsnSyyVoxcnDgAUP1AMp.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "932493",
        "Title": "Why ChatGPT Keeps Interrupting You",
        "Description": "ChatGPT Advanced Voice Mode isn‚Äôt interrupting just you. Interruptions, and turn-taking in general, are unsolved problems for all Voice AI agents. Nobody likes being cut short ‚Äì and people have much less patience for machines than they do for other humans. Turn-taking failures take many forms (e.g., the agent interrupts the user, the agent mistakes a cough for an interruption), and all of them lead to users immediately hanging up the phone.\r\n\r\nIn this talk, we use human conversation as a framework for understanding both today‚Äôs approaches to turn detection and where the field is headed. You‚Äôll learn about how linguists think about turn detection in human dialogue, what‚Äôs working (and what‚Äôs broken) in current methods, and how we might build Voice AIs that interrupt you less than your human brother. ",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Voice",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "b47f46a4-b920-4f97-aeaa-689185733e73",
    "Name": "Mukuntha Narayanan",
    "Company": "Pinterest, Inc.",
    "Company Domain": "pinterest.com",
    "Company URL": "www.pinterest.com",
    "Company Website": "",
    "Title": "Machine Learning Engineer",
    "TagLine": "Machine Learning Engineer",
    "Bio": "Mukuntha Narayanan is a Machine Learning Engineer at Pinterest, where he focuses on leveraging large language models to advance search relevance. Mukuntha‚Äôs background includes a Master‚Äôs in Machine Learning from Carnegie Mellon University, industry roles in developing robust language models at Observe.AI, and published research on both language and vision tasks at top venues like TPAMI, EMNLP-BlackboxNLP, and Interspeech. He is passionate about building scalable language technologies that shape how people discover and connect with information.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/mukuntha-n-s",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/9146-400o400o1-MxPhATdRSQ1s9yXEbkJCaZ.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "932498",
        "Title": "What We Learned from Using LLMs in Pinterest Search",
        "Description": "Pinterest Search integrates Large Language Models (LLMs) to enhance relevance scoring by combining search queries with rich multimodal content, including visual captions, link-based text, and user curation signals. A semi-supervised learning framework enables scaling to large and multilingual datasets, going beyond English and limited human labels. These LLM-driven models are distilled into efficient architectures for real-time serving, with experimental validation and large-scale deployment demonstrating substantial improvements in search relevance for Pinterest users worldwide.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "RecSys",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "a834abf6-7c03-4b20-89f6-46f826954443",
    "Name": "Han Wang",
    "Company": "Pinterest, Inc",
    "Company Domain": "pinterest.com",
    "Company URL": "https://newsroom.pinterest.com/company/",
    "Company Website": "",
    "Title": "Machine Learning Engineer",
    "TagLine": "Pinterest, Machine Learning Engineer",
    "Bio": "Han Wang is a Machine Learning Engineer at Pinterest, where she focuses on advancing search ranking and relevance. Her recent work leverages LLMs to improve the search relevance model at Pinterest, leading to improved overall relevance within the search feed and a better user experience. Before joining Pinterest, she earned her PhD in Statistics from North Carolina State University, where her research focused on reinforcement learning and missing data methodologies. ",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/han-wang-2626a713a/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/fcf8-400o400o1-7bRVVQbnRw2A6sZDp3BEN5.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "932498",
        "Title": "What We Learned from Using LLMs in Pinterest Search",
        "Description": "Pinterest Search integrates Large Language Models (LLMs) to enhance relevance scoring by combining search queries with rich multimodal content, including visual captions, link-based text, and user curation signals. A semi-supervised learning framework enables scaling to large and multilingual datasets, going beyond English and limited human labels. These LLM-driven models are distilled into efficient architectures for real-time serving, with experimental validation and large-scale deployment demonstrating substantial improvements in search relevance for Pinterest users worldwide.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "RecSys",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "53f93fd4-a3dc-4047-892a-ae2db2f3c173",
    "Name": "Yesu Feng",
    "Company": "Netflix",
    "Company Domain": "netflix.com",
    "Company URL": "netflix.com",
    "Company Website": "",
    "Title": "Staff Research Scientist/Engineer",
    "TagLine": "Netflix, Staff Research Scientist",
    "Bio": "Yesu Feng is a staff research scientist/engineer at Netflix, his work focused on generative foundation models for personalized recommendation. Before Netflix, he was at Linkedin and later Uber, worked on homepage feed and marketplace optimization, respectively.  ",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/d78c-400o400o1-Pyxn2ShL4g2YCAx7BJDYBb.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "932583",
        "Title": "One model to rule recommendations: Netflix's Big Bet",
        "Description": "Discuss the foundation model strategy for personalization at Netflix based on this post https://netflixtechblog.com/foundation-model-for-personalized-recommendation-1a0bd8e02d39 and recent developments. ",
        "Format": "Talk",
        "Level": "Expert",
        "Scope": "Technical deep dive",
        "Tracks": "RecSys",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "89141d5d-353b-4aa9-9792-0002a0a33f39",
    "Name": "Tomas Reimers",
    "Company": "Graphite",
    "Company Domain": "graphite.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "CPO and Co-founder",
    "TagLine": "Graphite CPO & Co-founder",
    "Bio": "Tomas Reimers, Forbes 30u30 class of ‚Äò23, is the CPO and Co-founder of Graphite, the NYC DevTools startup that‚Äôs revolutionizing how the fastest-moving engineers build and ship software. Prior to co-founding Graphite, Tomas was a dev-tools engineer at Meta, developing a framework that supported the work of 200+ product teams and more than 1000 developers. He is passionate about all things software and will enthusiastically debate best engineering and architecture practices with you for hours.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/4c3d-400o400o1-nkAAJo2pWhhLeubYDcA64E.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933472",
        "Title": "AI-powered entomology: Lessons from millions of AI code reviews",
        "Description": "This talk will explore insights from millions of automated code reviews, revealing trends in bugs, vulnerabilities, and code health that Graphite‚Äôs AI code review agent have uncovered. This talk will also provide meta commentary into the types of bugs AI code review agents are great at spotting, and how far the field of AI code review has come in the last year alone.",
        "Format": "",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "AI in Action, SWE Agents, Security",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "66c8ee2b-80f0-4167-a4b4-1dd6f87c6f32",
    "Name": "Chad Bailey",
    "Company": "Daily",
    "Company Domain": "daily.co",
    "Company URL": "",
    "Company Website": "",
    "Title": "Real-time Communication Engineer",
    "TagLine": "Member of Technical Staff, Daily",
    "Bio": "Chad Bailey started his career testing software for the Space Shuttle. After many years of building web apps, he's spent the last several working on real-time communication at Daily. Most recently, he's been building the Pipecat framework, and a series of increasingly ridiculous voice bots to show it off.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/7550-400o400o1-DPseyBDY58k9g5EXaxQnUq.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933493",
        "Title": "Realtime conversational video with Pipecat and Tavus",
        "Description": "Tavus shipped the world's first realtime video avatar platform last year. Developers use Tavus' conversational video APIs to create education, social, and customer support agents. The Tavus team built their innovative product using the Pipecat open source framework and Daily's global WebRTC infrastructure. Join us for a technical deep dive into conversational video.",
        "Format": "",
        "Level": "Introductory and overview",
        "Scope": "Technical deep dive",
        "Tracks": "Generative Media",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "1c666575-691e-4538-a337-ac4cc3ad6d1a",
    "Name": "Brian Johnson",
    "Company": "Tavus",
    "Company Domain": "tavus.com",
    "Company URL": "",
    "Company Website": "https://www.tavus.io/",
    "Title": "Staff Engineer",
    "TagLine": "Staff Engineer, Tavus",
    "Bio": "Brian Johnson is a Staff Engineer at Tavus, a market-leading generative AI video research company building foundational models and operating systems for human-AI interaction. With a background in electrical engineering and law, he brings decades of experience building and scaling systems across frontend, backend, and ML infrastructure. At Tavus, Brian leads development of real-time AI systems that power lifelike digital humans. His work focuses on combining technical precision with human-centered design to push the boundaries of conversational video AI.",
    "X (Twitter)": "https://x.com/code_brian",
    "LinkedIn": "https://www.linkedin.com/in/brpjohnson/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/37aa-400o400o1-QLbVd4LtYAG2D7mBtGZdzM.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933493",
        "Title": "Realtime conversational video with Pipecat and Tavus",
        "Description": "Tavus shipped the world's first realtime video avatar platform last year. Developers use Tavus' conversational video APIs to create education, social, and customer support agents. The Tavus team built their innovative product using the Pipecat open source framework and Daily's global WebRTC infrastructure. Join us for a technical deep dive into conversational video.",
        "Format": "",
        "Level": "Introductory and overview",
        "Scope": "Technical deep dive",
        "Tracks": "Generative Media",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "5b5f3a46-1cbf-4f1b-9caf-1268f88771b6",
    "Name": "Lou Bichard",
    "Company": "Gitpod",
    "Company Domain": "gitpod.io",
    "Company URL": "",
    "Company Website": "",
    "Title": "Product Manager",
    "TagLine": "Product Manager, Gitpod",
    "Bio": "Lou is Product Manager at Gitpod, a platform for secure development environments for both humans and agents powering some of the world's largest financial, insurance, and health care providers. Lou was previously Principal Engineer for developer experience at DAZN building a platform for ~15M global users in 150+ markets.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/c139-400o400o1-QEPBsUxsTae7ga8pqfrqjD.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933569",
        "Title": "Building CISO-approved agent fleet architecture",
        "Description": "Security is the biggest blocker for agent orchestration adoption in regulated industries for SWE agents. Gitpod's agent orchestration went from an originally self-hosted kubernetes architecture to the current 'bring your own cloud' model that enables deployment our SWE agent orchestration platform in secure environments. The architecture allows customers to securely connect their foundational models and agent memory solutions and comes with features like auto-suspend and resume for agent fleets. In this talk we deep dive into the architecture to share our years of learnings in how to secure agent workloads at scale in secure and regulated environments. ",
        "Format": "",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Security",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "ed128dfc-4ac2-47b2-b9dc-fa04efebd9e9",
    "Name": "Beyang Liu",
    "Company": "Sourcegraph",
    "Company Domain": "sourcegraph.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "Co-founder and CTO",
    "TagLine": "Co-founder and CTO, Sourcegraph",
    "Bio": "Beyang is the co-founder and CTO of Sourcegraph, the company behind Sourcegraph Code Search and Amp. Beyang started his career working on software for some of the largest banks as an engineer at Palantir, where he brought a background in machine learning and data analysis at Stanford.",
    "X (Twitter)": "https://x.com/beyang",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/6366-400o400o1-UTURJFDjBDBBfTLaoL6q8Y.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933575",
        "Title": "Amping it up: an experimental research demo of coding agents to uplevel humans building software",
        "Description": "If you're attending this conference, you've probably used agents to build new apps from scratch. Or fix a bug in your existing app. Or add a new feature. Or migrate some dependencies. Or review a messy code change to catch subtle bugs. Or grok a big legacy codebase. But have you tried to do all these things at once, in parallel, in front of a live audience? Come watch the spectacle as we redline context windows and try to stretch the power of LLMs and agentic tool use as far as we can",
        "Format": "",
        "Level": "Introductory and overview",
        "Scope": "Technical deep dive",
        "Tracks": "AI in Action, Agent Reliability, AI in Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "7cb31c6c-fcf2-4d0a-b4bb-6461d7776369",
    "Name": "Philip Kiely",
    "Company": "Baseten",
    "Company Domain": "baseten.co",
    "Company URL": "https://www.baseten.co/",
    "Company Website": "https://baseten.co",
    "Title": "Lead, Developer Relations",
    "TagLine": "Head of Developer Relations",
    "Bio": "Philip Kiely leads Developer Relations at Baseten. Prior to joining Baseten in 2022, he worked across software engineering and technical writing for a variety of startups. Outside of work, you'll find Philip practicing martial arts, reading a new book, or cheering for his adopted bay area sports teams.",
    "X (Twitter)": "https://twitter.com/philip_kiely",
    "LinkedIn": "https://linkedin.com/in/philipkiely",
    "Blog": "https://philipkiely.com",
    "Profile Picture": "https://sessionize.com/image/9495-400o400o1-U7SVLhc5ruNbNJ5xr6KF2Z.png",
    "Session Count": 2,
    "Sessions": [
      {
        "Session ID": "933580",
        "Title": "Optimizing inference for voice models in production",
        "Description": "How do you get time to first byte (TTFB) below 150 milliseconds for voice models -- and scale it in production? As it turns out, open-source TTS models like Orpheus have an LLM backbone that lets us use familiar tools and optimizations like TensorRT-LLM and FP8 quantization to serve the models with low latency. But client code, network infrastructure, and other outside-the-GPU factors can introduce latency in the production stack. In this talk, we'll cover the basic mechanics of TTS inference, common pitfalls to avoid in integrating them into production systems, and how to extend this high-performance system to serve customized models with voice cloning and fine-tuning.",
        "Format": "",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Voice",
        "Room": "",
        "Scheduled At": ""
      },
      {
        "Session ID": "916066",
        "Title": "Introduction to LLM serving with SGLang",
        "Description": "Do you want to learn how to serve models like DeepSeek and Qwen with SOTA speeds on launch day? SGLang is an open-source fast serving framework for LLMs and VLMs that generates trillions of tokens per day at companies like xAI, AMD, and Meituan. This workshop guides AI engineers who are familiar with serving models using frameworks like vLLM, Ollama, and TensorRT-LLM through deploying and optimizing their first model with SGLang, as well as providing guidance on when SGLang is the appropriate tool for LLM workloads.",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Infrastructure",
        "Room": "SOMA: Workshops",
        "Scheduled At": "3 Jun 2025 09:00 AM"
      }
    ]
  },
  {
    "Speaker ID": "20620580-0958-4f6e-a717-c8f8618e62bd",
    "Name": "Mark Backman",
    "Company": "Daily",
    "Company Domain": "daily.co",
    "Company URL": "",
    "Company Website": "",
    "Title": "VP of Product",
    "TagLine": "Head of Product, Daily",
    "Bio": "Mark Backman has 15 years of experience working with real-time communication systems and software. For the past 5 years, he‚Äôs served as Daily‚Äôs VP of Product, where he‚Äôs worked on building WebRTC tooling and infrastructure for developers. Over the last year, he‚Äôs focused on building and maintaining Pipecat, a leading voice and multimodal AI framework.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/9b3d-400o400o1-UQCzSHeVkPcXBcXujcLFug.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933589",
        "Title": "Pipecat Cloud: Enterprise Voice Agents Built On Open Source",
        "Description": "Voice AI agents today can conduct natural, human-like conversations and perform a wide variety of tasks: customer support, lead qualification, healthcare patient intake, market research, and more.\r\n\r\nToday's best voice agents combine: realtime responsiveness, open-ended conversational intelligence, reliable instruction following, and flexible integration with existing back-end systems.\r\n\r\nLearn how to build state of the art voice agents using Pipecat's open source, vendor neutral tooling. You can deploy Pipecat agents to your own infrastructure or to Pipecat Cloud.\r\n\r\nPipecat is used and supported by teams at NVIDIA, AWS, Google DeepMind, OpenAI, and hundreds of other companies.",
        "Format": "",
        "Level": "Intermediate",
        "Scope": "Product launch",
        "Tracks": "Voice",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "dd411263-9e2b-4674-8af8-1414e13312b1",
    "Name": "Arjun Desai",
    "Company": "Cartesia",
    "Company Domain": "cartesia.ai",
    "Company URL": "",
    "Company Website": "",
    "Title": "CTO and co-founder",
    "TagLine": "CTO, Cartesia",
    "Bio": "Cofounder @ Cartesia | Prev. Stanford ML PhD",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/982d-400o400o1-361rg9Cr9BxnPHp14xTYF6.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933599",
        "Title": "Serving Voice  AI at Scale",
        "Description": "Real-Time  Voice AI applications demand the lowest possible latencies to enhance user  experiences with more advanced reasoning and agentic capabilities. AWS is  hosting Arjun Desai, CTO and co-founder of Cartesia, in a fireside chat for a  technical deep dive into learnings and best practices for building a  state-of-the-art inference stack that serves global enterprise customers.",
        "Format": "",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Agent Reliability, Infrastructure, Voice",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "9f02f784-0f81-4e62-a173-d8e84c178bc5",
    "Name": "Suman Debnath",
    "Company": "Amazon Web Services",
    "Company Domain": "aws.amazon.com",
    "Company URL": "",
    "Company Website": "https://aws.amazon.com/?nc2=h_lg",
    "Title": "Principal Developer Advocate (AI/ML)",
    "TagLine": "Principal Developer Advocate (AI/ML)",
    "Bio": "Suman Debnath is a Principal Developer Advocate (AI/ML) at Amazon Web Services. His current focus areas include NLP, LLMs, and retrieval systems (RAG). Suman is committed to leveraging open-source tools such as LangChain, PyTorch, Numpy, and Pandas to advance machine learning. He has developed performance benchmarking and monitoring tools for distributed storage systems and has spoken at over 100 global events, including AI Engineer Summit, PyCon, PyData, ODSC, and many others across multiple countries.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/5e5d-400o400o1-sRANVScUVMrcgXD2Uo8LH8.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933603",
        "Title": "From Prototype to Production: Evaluating and Optimizing Agentic RAG Systems",
        "Description": "As RAG systems and AI agents mature from experimental demos to real-world deployments, the need for robust evaluation and optimization becomes critical. This session will provide a framework for systematically measuring agent performance, retrieval quality, latency, and cost-efficiency in production environments. We‚Äôll explore techniques for benchmarking agent reasoning, tuning retrieval pipelines, and identifying bottlenecks in orchestration workflows. Attendees will learn best practices for optimizing multi-agent coordination, prompt strategies, and embedding selection, as well as how to integrate observability and feedback loops for continuous improvement. Whether you‚Äôre scaling an LLM-based assistant or deploying domain-specific RAG apps, this session equips you with the tools and methodologies to move from functional to production-grade intelligence.",
        "Format": "",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "AI in Action, Evals, RAG, Support Agents",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "2160a4f6-9d55-4662-b017-4d4cf4e97552",
    "Name": "Mani Khanuja",
    "Company": "Amazon",
    "Company Domain": "amazon.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "unknown",
    "TagLine": "Principal ML Services SA",
    "Bio": "Coming soon! ",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/8446-400o400o1-LprTVAM4omLMmYfMSYUUhw.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933605",
        "Title": "Data is Your Differentiator: Building Secure and Tailored AI Systems",
        "Description": "As  organizations seek to harness their proprietary data while maintaining  security and compliance, Amazon Bedrock provides a comprehensive framework  for building tailored AI applications. Using Amazon Bedrock Knowledge Bases  and Amazon Bedrock Data Automation, organizations can create AI solutions  that truly understand their unique business context, terminology, and  requirements. Combined with Amazon Bedrock Guardrails, these capabilities  enhance the accuracy and relevance of AI-generated responses, while ensuring  that sensitive information remains protected within the organization's  control - enabling businesses to build secure and compliant enterprise-grade  generative AI solutions that accelerate time to value.",
        "Format": "",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "AI Architects, GraphRAG, Agent Reliability, Security, Infrastructure, RAG, AI in Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "cfe80e04-2c05-4704-a828-05eb7ab87579",
    "Name": "Laurie Voss",
    "Company": "npm, Inc.",
    "Company Domain": "npmjs.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "Co-founder",
    "TagLine": "VP Developer Relations, LlamaIndex",
    "Bio": "Laurie has been a web developer for 27 years, and along the way he co-founded npm, Inc.. He cares passionately about making technology accessible to everyone by demystifying complex technology topics.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/fb2f-400o400o1-R9cKxHYQDusBUF4SJvJawH.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933621",
        "Title": "Effective agent design patterns in production",
        "Description": "At LlamaIndex we see a lot of agents built every day, and we've got a sense of what works and what doesn't. We've distilled those learnings down into a series of patterns and best practices for building real-world, production agents, and we're here to share them. You'll learn patterns for applying structure and guidance to famously nondeterministic LLMs and get concrete instruction on how to implement them.",
        "Format": "",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "AI Architects, AI in Action, Agent Reliability",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "28f92a67-eeb8-4b93-b73d-f489577e8bf4",
    "Name": "Chris Hernandez",
    "Company": "Chime",
    "Company Domain": "chime.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "Manager of AI Speech Analytics",
    "TagLine": "Manager of AI Speech Analytics at Chime",
    "Bio": "I‚Äôm a Manager of Speech Analytics at Chime, where I lead a team in developing and implementing AI-powered insights to enhance member experiences and operational efficiency. With over a decade of experience in leadership, AI, and machine learning, I specialize in designing and scaling AI solutions that drive measurable impact.\r\n\r\nAt Chime, we believe that everyone can feel good about their money. We‚Äôre proud to be the most loved banking app‚Ñ¢, providing millions of members with transparent, easy-to-use tools that help them unlock financial progress. By leveraging AI, my team helps uncover insights that improve quality, efficiency, and overall member satisfaction.\r\n\r\nI joined Chime because of its mission and the opportunity to work alongside an incredible team focused on innovation. I‚Äôm excited about the future as we continue to push the boundaries of AI-driven quality solutions‚Äîand we‚Äôre just getting started! üöÄ\r\n\r\n**The views and opinions expressed here are my own and do not necessarily reflect the official policy or position of Chime.**",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/chrishernandezz/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/7a9d-400o400o1-K3HbWLnDZxYVn3w4dd77WK.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933622",
        "Title": "The Build-Run Divide: How Chime Bridges Product Vision and AI Operational Reality",
        "Description": "Product leaders see AI possibilities. Operations teams see implementation nightmares. The chasm between these perspectives kills promising AI features before they reach users.\r\n\r\nIn this talk, Chris Hernandez (Manager of AI Speech Analytics at Chime) and Jeremy Silva (Product Lead at Freeplay) share an integrated framework we've developed across product strategy and operations at a leading neo-bank. You'll see how we transformed siloed processes into a unified approach that connects prototyping, evaluations, human review workflows, and model benchmarking from day one.\r\n\r\nWe'll reveal the collaborative tools built to make trade-off decisions visible, the evaluation metrics that satisfy both business and technical stakeholders, and the governance model that enabled us to ship AI features 3x faster. Learn how to create processes where product and operations strengthen each other rather than compete, and build AI capabilities that scale beyond individual features into organization-wide advantage.\r\n",
        "Format": "",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "AI Product Management",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "15c39d6c-e8f6-465f-a24a-5b7d34d664d2",
    "Name": "Sam Alba",
    "Company": "Dagger",
    "Company Domain": "dagger.io",
    "Company URL": "",
    "Company Website": "https://dagger.io",
    "Title": "Co-founder",
    "TagLine": "Co-Founder of Dagger",
    "Bio": "Sam Alba is Co-founder of Dagger and was the first employee at Docker, where he served as VP of Engineering. At Docker, he built and led the core engineering teams responsible for Docker's Community Edition, Enterprise Edition, open-source core, and developer tools such as Docker Desktop and Compose, scaling the engineering organization from 3 to over 100 people. With deep expertise in software delivery, automation, and developer tooling, Sam now focuses on helping teams reliably automate complex workflows at Dagger.",
    "X (Twitter)": "https://x.com/sam_alba",
    "LinkedIn": "https://www.linkedin.com/in/samalba/",
    "Blog": "https://samalba.com/",
    "Profile Picture": "https://sessionize.com/image/610f-400o400o1-X6srzsk8NxCCim5MUKiP4r.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933629",
        "Title": "How to trust an agent with software delivery",
        "Description": "AI-powered agents promise faster, easier software delivery, but their unpredictable behavior often makes engineers hesitant to fully trust them with critical workflows. Sam Alba, Co-founder of Dagger (and previously co-creator of Docker), explains how teams can reliably integrate agents into their delivery pipelines by shifting how they structure and manage automation.\r\n\r\nHe'll share four practical strategies learned from real-world experience:\r\n\r\n1. Treat agents as workflow participants, not isolated tools.\r\nStop using agents as disconnected scripts or IDE plugins. Treating them as first-class parts of your delivery process simplifies your architecture, reduces hidden complexity, and makes agent outcomes more predictable.\r\n\r\n2. Use many small agents instead of one big one.\r\nJust as software evolved from monoliths to microservices, software delivery benefits from smaller, specialized agents with clearly defined responsibilities. Smaller agents are easier to understand, maintain, and integrate.\r\n\r\n3. Define clear environments‚Äîthe real lever for reliability.\r\nInstead of chasing perfect prompts or models, focus on clearly defining the tools, resources, and permissions around your agents. Precisely controlling their environments makes agents behave consistently and reliably.\r\n\r\n4. Design workflows for easy debugging and observability.\r\nAgents will sometimes fail unexpectedly. Sam will share simple, effective ways to build clear tracing and observability into your workflows from the start, making debugging quicker and less frustrating.\r\n\r\nYou'll leave with practical, immediately usable techniques that give you the confidence to trust AI agents in your software delivery pipelines.",
        "Format": "",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "AI in Action, Agent Reliability, SWE Agents",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "03a546b2-ff3e-4fc5-8fe2-0c29c95f1953",
    "Name": "Kshitij  Grover",
    "Company": "Orb",
    "Company Domain": "orb.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "Co-Founder and CTO",
    "TagLine": "Co-Founder & CTO, Orb Inc.",
    "Bio": "I‚Äôm Kshitij Grover, Co-Founder and CTO of Orb, where we‚Äôre building billing infrastructure that gives AI and SaaS teams the tools to treat pricing as a product. My focus is on designing systems that are correct, real-time, and intuitive for developers‚Äîbecause billing should be as thoughtfully engineered as the applications it supports. At Orb, we work closely with engineering teams to help them ship pricing changes with speed and confidence. I‚Äôm passionate about the intersection of infrastructure, data, and developer experience. As a speaker at the AI Engineering Summit, I‚Äôm excited to share what we‚Äôve learned about building billing systems that scale with modern AI workloads.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/4ffc-400o400o1-SkQekXYsdNqDueHnBrTTvT.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933641",
        "Title": "Revenue Engineering: How to Price (and Reprice) Your AI Product",
        "Description": "You‚Äôve trained the model‚Äînow it‚Äôs time to train the business. This talk dives into the engineering behind pricing systems that can evolve as fast as your AI stack.\r\n\r\nOrb CTO Kshitij Grover will walk through how leading AI companies design infrastructure to support experimentation, scale, and real-world monetization constraints.\r\n\r\nTopics include:\r\n- How to meter usage and map it to pricing with accuracy and auditability\r\n- Factoring in margins and underlying costs when designing pricing strategy\r\n- Handling complexity across motions: self-serve vs. enterprise, pay-as-you-go vs. committed contracts\r\n- How to test pricing changes safely (and roll them back when needed)\r\n\r\nWhether you‚Äôre bootstrapping a pricing system from scratch or replacing a brittle V1, you‚Äôll leave with architectural patterns and mental models to make pricing a first-class engineering concern.\r\n",
        "Format": "",
        "Level": "Introductory and overview",
        "Scope": "Technical deep dive",
        "Tracks": "AI Architects, AI in Action, Infrastructure",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "1feb3f6d-13cb-4ac8-9297-dbd4154ebfcf",
    "Name": "Aman Khan",
    "Company": "Arize",
    "Company Domain": "arize.com",
    "Company URL": "arize.com",
    "Company Website": "https://arize.com/",
    "Title": "Director of Product, LLM",
    "TagLine": "Director of Product",
    "Bio": "Aman is Director of Product, LLM at Arize AI. Prior to Arize, Aman was the PM on the Jukebox Feature Store in the ML Platform team at Spotify across ~50 data science teams. Aman was also PM for ML Evaluation frameworks across data science and engineering teams for self-driving cars at Cruise, which helped launch the first self-driving car service in an urban environment. Aman studied Mechanical Engineering at UC Berkeley and lived in the SF Bay Area for 9 years before moving to NYC. ",
    "X (Twitter)": "https://x.com/dat_attacked",
    "LinkedIn": "https://www.linkedin.com/in/datdarylngo/",
    "Blog": "https://github.com/arizedatngo",
    "Profile Picture": "https://sessionize.com/image/c833-400o400o1-Ny5azYCUjiB2ccBPSnHeQ2.jpeg",
    "Session Count": 2,
    "Sessions": [
      {
        "Session ID": "933645",
        "Title": "Engineering Better Evals: Scalable LLM Evaluation Pipelines That Work",
        "Description": "As LLM-powered products become more sophisticated, the need for scalable, reliable evaluation pipelines has never been more critical. This session dives deep into advanced LLM evaluation strategies that move beyond toy benchmarks and toward real-world production impact.\r\n\r\nWe‚Äôll explore how to architect and implement evaluation pipelines that work across both online and offline environments‚Äîreducing dev complexity and accelerating iteration. The session will cover:\r\n\r\n- LLM-as-a-judge frameworks\r\n- Human-in-the-loop evaluation\r\n- How hybrid approaches unlock more robust and nuanced performance assessments\r\n\r\nWe‚Äôll break down technical architectures, share real implementation patterns, and examine trade-offs between evaluation techniques to help engineers make informed choices.\r\nWhether you‚Äôre building from scratch or refining existing workflows, this talk offers practical strategies for crafting efficient, scalable, and accurate eval pipelines tailored to custom LLM products.\r\n",
        "Format": "",
        "Level": "Advanced",
        "Scope": "Introductory (landscape)",
        "Tracks": "Evals",
        "Room": "",
        "Scheduled At": ""
      },
      {
        "Session ID": "915269",
        "Title": "Shipping AI That Works: An Evaluation Framework for PMs",
        "Description": "GenAI is reshaping the product landscape, creating huge opportunities (along with new expectations) for product managers. Yet while prompt engineering and model tuning get the spotlight, one critical skill can get overlooked: rigorous evaluation.\r\n\r\nThis talk will help PMs move beyond gut-feel ‚Äúvibe checks‚Äù to adopt concrete, repeatable evaluation strategies for LLM-powered products. I'll break down essential eval methodologies, from human feedback and code-based checks to cutting-edge LLM-based evaluations. Drawing on real-world examples, I'll share a practical framework PMs can use to:\r\n\r\n-Confidently evaluate AI-driven features\r\n- Ground decisions in real, repeatable data\r\n- Build trust and delight through consistent quality\r\n",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "AI Product Management",
        "Room": "Foothill G1&2: Workshops",
        "Scheduled At": "3 Jun 2025 09:00 AM"
      }
    ]
  },
  {
    "Speaker ID": "b5eb465d-051d-4ebd-9ab6-8622baf27e47",
    "Name": "Mason Egger",
    "Company": "Temporal Technologies",
    "Company Domain": "temporal.io",
    "Company URL": "",
    "Company Website": "",
    "Title": "Senior Developer Advocate",
    "TagLine": "Sr. Developer Advocate - Temporal ",
    "Bio": "Mason is currently a Senior Developer Advocate at Temporal Technologies who specializes in building community, developer-focused educational content, distributed systems, and Python. Prior to his work at Temporal he worked in Developer Relations at DigitalOcean and as a backend engineer at various companies. He‚Äôs an avid programmer, speaker, educator, and writer/blogger. He is President of the PyTexas Foundation, Conference Chair of the PyTexas Conference, and a founding organizer of the PyTexas Meetup.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/e0f8-400o400o1-aeubqWhpCb2as2998tocSU.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933652",
        "Title": "Events are the Wrong Abstraction for Your AI Agents",
        "Description": "AI Agents are distributed systems. Agents need to connect and communicate with tools, data repositories, other agents, etc., all over a network. Event-Driven Architecture is a common pattern for facilitating this connectivity, using Events as the communication abstraction. However, this pattern introduces complexities as well, such as fragmented logic, increased latency, decreased observability, and more. But what if there were a way to get the benefits of Event-Driven Architecture without the complexities? Enter Durable Execution. In this talk, we'll discuss the pitfalls of Event-Driven Architecture, how Durable Execution solves these issues, and why Durable Execution, not Events, is the correct abstraction for building AI Agents.",
        "Format": "",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "Infrastructure",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "79afe59b-ceb1-48d0-b189-a458b7ef0082",
    "Name": "Nick Nisi",
    "Company": "WorkOS ",
    "Company Domain": "nisi.org",
    "Company URL": "https://workos.com",
    "Company Website": "https://nicknisi.com",
    "Title": "Software Engineer",
    "TagLine": "Software developer and panelist on the JS Party podcast",
    "Bio": " Nick Nisi is an elite software engineer who is a veteran of open source web development, a lover of karaoke, an advocate for diversity in tech, a conference organizer extraordinaire, a lover of new experiences, and a beacon of expertise, kindness and hope for his development team.",
    "X (Twitter)": "https://twitter.com/nicknisi",
    "LinkedIn": "https://www.linkedin.com/in/nicknisi/",
    "Blog": "https://nicknisi.com",
    "Profile Picture": "https://sessionize.com/image/7353-400o400o1-NyWb1iLwNiUgQbAtFfjFME.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933656",
        "Title": "Agents, Access, and the Future of Machine Identity",
        "Description": "AI agents are calling APIs, submitting forms, and sending emails‚Äîbut how do you control what they‚Äôre allowed to do? As agents act on behalf of users or organizations, traditional patterns like OAuth, session tokens, and role-based access often fall short.\r\nIn this talk, we‚Äôll explore how machine identity is evolving to meet this new landscape. You‚Äôll learn:\r\n\r\n- How to think about authentication for agents (not just humans)\r\n- What it means to authorize an action when the actor is an LLM or headless service\r\n- Real-world strategies from WorkOS and Cloudflare for assigning, managing, and revoking agent identity and access\r\n\r\nBy the end, you‚Äôll walk away with practical tools and mental models to build agent-powered systems that are secure, auditable, and scalable.",
        "Format": "",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Model Context Protocol (MCP), AI in Action, Security, Infrastructure",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "a9a319ef-c8e1-4212-bab1-6a4f46196bd5",
    "Name": "Kevin Hou",
    "Company": "Windsurf",
    "Company Domain": "windsurf.com",
    "Company URL": "",
    "Company Website": "https://windsurf.com",
    "Title": "Head of Product Engineering",
    "TagLine": "Head of Product, Windsurf",
    "Bio": "Kevin is the Head of Product Engineering at Windsurf, where he builds AI-powered developer tools. He has spent much of his career in AI, previously working as a tech lead manager at the Nuro, an autonomous vehicle startup, as well as other companies like Airbnb & Salesforce. Kevin enjoys photography, playing basketball, and woodworking. He studied computer science & ML at Princeton University.",
    "X (Twitter)": "https://x.com/kevinhou22",
    "LinkedIn": "https://www.linkedin.com/in/kevinhou22/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/2cdd-400o400o1-H8cP8CtFjRAB3WFEPxoyxc.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933675",
        "Title": "Windsurf everywhere, doing everything, all at once",
        "Description": "abstract tbd",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "Tiny Teams",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "d793f554-f4a0-41e4-9789-0c801136f26c",
    "Name": "Frank Liu",
    "Company": "MongoDB",
    "Company Domain": "mongodb.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "Staff Product Manager",
    "TagLine": "Staff Product Manager, MongoDB",
    "Bio": "Frank Liu is Staff Product Manager at MongoDB. He has over a decade of industry experience in machine learning and hardware engineering and presents at major industry events like the Open Source Summit Open Data Science Conference. In his spare time, he enjoys experimenting with and training models. Frank holds MS and BS degrees in Electrical Engineering from Stanford University.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/3bb7-400o400o1-RqafSobKcMXPufXa2vFxLq.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933689",
        "Title": "The State of AI-Powered Search and Retrieval",
        "Description": "In this talk, we examine the state-of-the-art in AI-powered search and retrieval. We detail techniques for enhancing performance beyond base embedding models, including hybrid search, reranking strategies, query decomposition and document enrichment, the use of domain-specific and fine-tuned embeddings, custom data processing pipelines (ETL), and contextualized chunking methods.",
        "Format": "",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "f2f4bba6-574f-4663-8a29-c10f4146eb1b",
    "Name": "Richmond Alake",
    "Company": "MongoDB",
    "Company Domain": "mongodb.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "Developer Advocate",
    "TagLine": "Staff Developer Advocate, AI/ML at MongoDB",
    "Bio": "Richmond Alake is a seasoned AI/ML practitioner and educator with a robust background in computer vision, robotics, and machine learning. Currently serving as a Developer Advocate at MongoDB, Richmond focuses on enabling and accelerating MongoDB‚Äôs most advanced customers and developers with their AI use cases through webinars, technical enablement sessions, consultation, and written content.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/richmondalake/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/1e5a-400o400o1-L9U137oieKPda7TqGaQpn4.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933692",
        "Title": "Architecting Agent Memory: Principles, Patterns, and Best Practices",
        "Description": "In the rapidly evolving landscape of agentic systems, memory management has emerged as a key pillar for building intelligent, context-aware AI Agents. Inspired by the complexity of human memory systems‚Äîsuch as episodic, working, semantic, and procedural memory‚Äîthis talk unpacks how AI agents can achieve believability, reliability, and capability by retaining and reasoning over past experiences.\r\nWe‚Äôll begin by establishing a conceptual framework based on real-world implementations from memory management libraries and system architectures:\r\nMemory Components representing various structured memory types (e.g., conversation, workflow, episodic, persona)\r\nMemory Modes reflecting operational strategies for short-term, long-term, and dynamic memory handling\r\nNext, the talk transitions to practical implementation patterns critical for effective memory lifecycle management:\r\nMaintaining rich conversation history and contextual awareness\r\nPersistence strategies leveraging vector databases and hybrid search\r\nMemory augmentation using embeddings, relevance scoring, and semantic retrieval\r\nProduction-ready practices for scaling memory in multi-agent ecosystems\r\nWe‚Äôll also examine advanced memory strategies within agentic systems:\r\nMemory cascading and selective deletion\r\nIntegration of tool use and persona memory\r\nOptimizing performance around memory retrieval and LLM context window limits\r\nWhether you're developing autonomous agents, chatbots, or complex workflow orchestration systems, this talk offers knowledge and tactical insights for building AI that can remember, adapt, and improve over time.\r\nThis session is ideal for:\r\nAI engineers and agent framework developers\r\nArchitects designing Agentic RAG or multi-agent systems\r\nPractitioners building contextual, personalized AI experiences\r\nBy the end of the session, you‚Äôll understand how to leverage memory as a strategic asset in agentic design‚Äîand walk away ready to build agents that not only act and reason but also remember.\t",
        "Format": "",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "AI Architects, Agent Reliability, RAG, Support Agents",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "64bac3f8-8b07-4015-89da-dea03221a28e",
    "Name": "Nir Gazit",
    "Company": "traceloop",
    "Company Domain": "traceloop.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "CEO",
    "TagLine": "CEO @ Traceloop, OpenLLMetry co-creator",
    "Bio": "CEO @ traceloop; ex-chief architect @ Fiverr, ex-tech lead @ Google; OpenTelemetry contributor",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/9382-400o400o1-QMULvZAAdvj5qzyKCiSQ79.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933712",
        "Title": "Prompt Engineering is Dead",
        "Description": "Manual prompt crafting doesn't scale. In this session, we'll explore how to replace it with a test-driven, automated approach. You'll see how to define output evaluators, write minimal prompts, and let agents iterate toward optimal performance‚Äîall without manual tweaking. If you're still hand-tuning prompts, you're doing it wrong.",
        "Format": "",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Evals",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "d3b124f8-5641-42bd-8cee-05ccd1c807b8",
    "Name": "Charles Frye",
    "Company": "Modal Labs",
    "Company Domain": "modal.com",
    "Company URL": "modal.com",
    "Company Website": "",
    "Title": "Educator and Evangelist",
    "TagLine": "Building useful technology out of large neural networks",
    "Bio": "Charles teaches people to build data, ML, and AI applications. He got his PhD from the University of California, Berkeley, in 2020 for work on the geometry of neural network optimization. He has since worked as an educator and evangelist for neural network applications at Weights & Biases, Full Stack Deep Learning, and now Modal Labs.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/dad1-400o400o1-SzdPZy7GnHqsMy5Tt9hM8C.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933716",
        "Title": "How fast are LLM inference engines anyway?",
        "Description": "Open weights models and open source inference servers have made massive strides in the year since we last got together at AIE World's Fair.\r\n\r\nWhere once we had only pirated LLaMA 2 weights and Transformers, we now have an embarrassment of riches. In fact, we have too many choices! What's an AI engineer looking to self-host inference to do?\r\n\r\nIn this session, we'll share our benchmarking results from hundreds of runs across models, frameworks, and hardware. We'll also share tips and tricks from working with teams deploying LLM inference at scale.",
        "Format": "",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "AI in Action",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "415efc97-c2d6-431b-9712-b990158280dc",
    "Name": "Charles Frye",
    "Company": "Modal Labs",
    "Company Domain": "modallabs.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "Educator and Evangelist",
    "TagLine": "Developer Advocate, Modal Labs",
    "Bio": "Charles teaches people to build data, ML, and AI applications. He got his PhD from the University of California, Berkeley, in 2020 for work on the geometry of neural network optimization. He has since worked as an educator and evangelist for neural network applications at Weights & Biases, Full Stack Deep Learning, and now Modal Labs.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/e0a4-400o400o1-PH8Virem1RtLgkA2UCeqGN.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933719",
        "Title": "What every AI engineer needs to know about GPUs",
        "Description": "Every programmer needs to know a few things about hardware, like processors, memory, and disks. Due to AI systems' extreme demand for mathematical processing power, AI engineers need to know a few things about GPUs -- the world's most popular high-throughput mathematical co-processor.\r\n\r\nIn this talk, I will explain the fundamental engineering constraints and design decisions that shape GPUs and trace those up to some counter-intuitive facts about the performance characteristics of AI systems, with actionable insights for their deployers and consumers.",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "AI in Action, Infrastructure",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "8baabfb1-58b9-4ab8-b3af-95a406e99707",
    "Name": "Taylor Jordan Smith",
    "Company": "Red Hat",
    "Company Domain": "gmail.com",
    "Company URL": "",
    "Company Website": "https://www.redhat.com/en/products/ai",
    "Title": "Senior Developer Advocate",
    "TagLine": "Senior Developer Advocate",
    "Bio": "Taylor Smith, Senior Developer Advocate at Red Hat, is an advocate of open source AI innovation and democratization. She has a background in software development, open source technologies like Kubernetes and linux, and technical partnerships. Taylor loves music, animals, and helping to solve real-world problems with technology. Based out of North Carolina.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/taylorjordansmith/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/56c7-400o400o1-QwkQZaQ3HC69a4FxSMzwBT.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915684",
        "Title": "Beyond Benchmarks: Strategies for Evaluating LLMs in Production",
        "Description": "Accuracy scores and leaderboard metrics look impressive‚Äîbut production-grade AI requires evals that reflect real-world performance, reliability, and user happiness. Traditional benchmarks rarely help you understand how your LLM will perform when embedded in complex workflows or agentic systems. How can you realistically and adequately measure reasoning quality, agent consistency, MCP integration, and user-focused outcomes?\r\n\r\nIn this practical, example-driven talk, we'll go beyond standard benchmarks and dive into tangible evaluation strategies using various open-source frameworks like GuideLLM and lm-eval-harness. You'll see concrete examples of how to create custom eval suites tailored to your use case, integrate human-in-the-loop feedback effectively, and implement agent reliability checks that reflect production conditions. Walk away with actionable insights and best practices for evaluating and improving your LLMs, ensuring they meet real-world expectations‚Äînot just leaderboard positions!",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Evals",
        "Room": "Nobhill A&B: Workshops",
        "Scheduled At": "3 Jun 2025 09:00 AM"
      }
    ]
  },
  {
    "Speaker ID": "188818c8-ec9f-49ac-a4a0-3df83a99dc69",
    "Name": "Ishan Anand",
    "Company": "Independent",
    "Company Domain": "gmail.com",
    "Company URL": "https://ishananand.com/",
    "Company Website": "https://spreadsheets-are-all-you-need.ai/",
    "Title": "Vice-President of Product Management",
    "TagLine": "AI Consultant and educator",
    "Bio": "Ishan Anand is an AI consultant and technology executive specializing in Generative AI and LLMs. He created \"Spreadsheets-are-all-you-need,\" an innovative course that demystifies large language models by implementing GPT-2 entirely in Excel. As the former CTO and co-founder of Layer0 (acquired by Edgio), and most recently Vice-President of Product Management for Edgio, he's led teams in developing cutting-edge solutions in web performance, edge computing, and AI/ML for enterprise web applications. Ishan brings deep technical expertise from his dual B.S. degrees in Mathematics and EECS from MIT, combined with a unique ability to make advanced technology accessible to broader audiences.",
    "X (Twitter)": "https://x.com/ianand",
    "LinkedIn": "https://www.linkedin.com/in/ishananand/",
    "Blog": "https://ishananand.com/",
    "Profile Picture": "https://sessionize.com/image/25c1-400o400o1-TEGfyxq7PWpsZSkNUpLrhm.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915928",
        "Title": "How LLMs work for Web Devs: GPT in 600 lines of Vanilla JS",
        "Description": "Don't be intimidated. Modern AI can feel like magic, but underneath the hood are principles that web developers can understand, even if you don't have a machine learning background. In this workshop, we'll explore a complete GPT-2 inference implementation built entirely in Vanilla JS. This JavaScript translation of the popular \"Spreadsheets-are-all-you-need\" approach will let you debug and step through a real LLM line by line without the overhead of learning a new language, framework, or even IDE.\r\n\r\nAll the major LLMs, including ChatGPT, Claude, DeepSeek, and Llama, inherit from GPT-2's architecture, making this exploration a solid foundation to understand modern AI systems and comprehend the latest research.\r\n\r\nWhile we won't have time to cover *everything*, you'll gain the essential knowledge to understand the key concepts that matter when building with LLMs, including how they:\r\n\r\n-Convert raw text into meaningful tokens\r\n- Represent semantic meaning through vector embeddings\r\n- Train neural networks through gradient descent\r\n- Generate text with sampling algorithms like top-k, top-p, and temperature\r\n\r\nThis intense but beginner-friendly workshop is designed specifically for web developers diving into ML and AI for the first time. It‚Äôs your \"missing AI degree\" in just two hours. You'll walk away with an intuitive mental model of how Transformers work that you can apply immediately to your own LLM-powered projects.",
        "Format": "Workshop",
        "Level": "Introductory and overview",
        "Scope": "Technical deep dive",
        "Tracks": "AI in Action",
        "Room": "Golden Gate Ballroom A: Workshops",
        "Scheduled At": "3 Jun 2025 09:00 AM"
      }
    ]
  },
  {
    "Speaker ID": "185f8d2f-07ad-4620-b34b-2c666d73acf2",
    "Name": "Yineng Zhang",
    "Company": "Baseten",
    "Company Domain": "zhyncs.com",
    "Company URL": "https://www.baseten.co",
    "Company Website": "https://www.baseten.co",
    "Title": "Software Engineer",
    "TagLine": "Inference lead at SGLang",
    "Bio": "Yineng Zhang is a Software Engineer at Baseten Model Performance team. He is also a core developer of the SGLang project.",
    "X (Twitter)": "https://x.com/zhyncs42",
    "LinkedIn": "https://www.linkedin.com/in/zhyncs",
    "Blog": "https://zhyncs.com",
    "Profile Picture": "https://sessionize.com/image/e95d-400o400o1-SDevFXKdezx37JYRHYKMF7.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916066",
        "Title": "Introduction to LLM serving with SGLang",
        "Description": "Do you want to learn how to serve models like DeepSeek and Qwen with SOTA speeds on launch day? SGLang is an open-source fast serving framework for LLMs and VLMs that generates trillions of tokens per day at companies like xAI, AMD, and Meituan. This workshop guides AI engineers who are familiar with serving models using frameworks like vLLM, Ollama, and TensorRT-LLM through deploying and optimizing their first model with SGLang, as well as providing guidance on when SGLang is the appropriate tool for LLM workloads.",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Infrastructure",
        "Room": "SOMA: Workshops",
        "Scheduled At": "3 Jun 2025 09:00 AM"
      }
    ]
  },
  {
    "Speaker ID": "57cf0bb0-1a05-4ec8-9887-5b31b07f9bec",
    "Name": "Unsloth AI N/A",
    "Company": "Unsloth AI",
    "Company Domain": "gmail.com",
    "Company URL": "https://unsloth.ai/",
    "Company Website": "https://unsloth.ai/",
    "Title": "Founder",
    "TagLine": "CEO",
    "Bio": "I'm building Unsloth and we're an open-source startup trying to make AI more accessible and accurate for everyone! We have 40K GitHub stars, 10M monthly downloads on Hugging Face and worked with Google, Meta, Hugging Face teams to fix bugs in open-source models like Llama, Phi & Gemma models. I was previously working at NVIDIA making TSNE 2000x faster.",
    "X (Twitter)": "https://x.com/danielhanchen",
    "LinkedIn": "https://www.linkedin.com/in/danielhanchen",
    "Blog": "https://unsloth.ai/blog",
    "Profile Picture": "https://sessionize.com/image/1172-400o400o1-TkXK9rT2EKiH4G2oS7tijf.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "929509",
        "Title": "Kernels, RL, Reasoning, Reward Functions & Quantization",
        "Description": "Discover if writing custom kernels is still worth it, explore how to do Reinforcement Learning (RL) and reward functions properly, and learn why quantization is key to local LLMs - plus tips to gain accuracy.",
        "Format": "Workshop",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Reasoning+RL",
        "Room": "Foothill C: Workshops",
        "Scheduled At": "3 Jun 2025 09:00 AM"
      }
    ]
  },
  {
    "Speaker ID": "210c2993-39c7-40d5-bf2a-73d5795d287a",
    "Name": "David Karam",
    "Company": "Pi Labs",
    "Company Domain": "withpi.ai",
    "Company URL": "",
    "Company Website": "https://withpi.ai",
    "Title": "Co-founder",
    "TagLine": "CEO",
    "Bio": "I'm David K. I love straddling the line between deep tech research and application development. I‚Äôve spent a decade at Google as Product Director working on Search‚Äôs core AI and NLU systems, helping Search‚Äôs own version of ‚ÄúAI Engineers‚Äù develop magical applications. Around a year ago I left with my cofounder to start Pi Labs where we‚Äôre trying to bring that same spirit to the rest of the industry. Outside work I love to read, cook, and spend time in nature.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/dskaram/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/ce69-400o400o1-paRtRckcMShnkTvVacSEzy.jpg",
    "Session Count": 2,
    "Sessions": [
      {
        "Session ID": "907684",
        "Title": "Scoring models beat LLM judges any day of the week",
        "Description": "Do you wish your LLM judge was highly accurate, rapid fast, data-tunable, and continuously integrated across your stack? This talk describes a new architecture for AI metrics based on foundation scoring models and a set of integrations that run above them. This architecture was inspired by decades of AI and machine learning development in Google Search, reinvented for the modern LLM stack by our team over the past year. \r\n\r\nWe will share the history of that trajectory and then dive into the technical details: the use of encoder models trained specifically for scoring to enable higher accuracy and lower latency and the deployment of auto-generated tunable metric trees that can combine a wide variety of soft and hard signals across your stack into a human-calibrated score. We‚Äôll end with various examples of how these scoring models are being deployed across the whole stack from online control flows for agents, to reward models for algorithms like RL, to rankers for inference time scaling methods like ensemble generation.\r\n",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Evals",
        "Room": "Foothill G1&2: Workshops",
        "Scheduled At": "3 Jun 2025 10:40 AM"
      },
      {
        "Session ID": "907695",
        "Title": "Layering every technique in RAG, one query at a time",
        "Description": "Start with the simplest Search - in-memory embeddings with relevance ranking. End with the most complex planet-scale Search - 70+ corpus mix of token, embeddings, and knowledge graphs, all jointly retrieved, custom ranked, joint re-ranked, and then LLM-processed, at 160,000 queries per second in under 200msec.\r\n\r\nThis talk will be a fun ‚Äúone query at a time‚Äù survey of all techniques in RAG in incremental complexity, showing the limits of each technique and what the next layered one opens up in terms of capabilities to handle ever-more complex queries in RAG. You‚Äôll learn why queries like [falafel] are notoriously hard to Search over, why chunking your documents can be disastrous, how you can sometimes can get away with a simple bm25, and how some Search problems are so hard to solve that you‚Äôre better off punting the problem to the LLM or the UX. Brought to you by the team that worked on 50+ Search products, in the context of Google.com and custom Enterprise Search.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "Golden Gate Ballroom A: Retrieval + Search",
        "Scheduled At": "5 Jun 2025 02:50 PM"
      }
    ]
  },
  {
    "Speaker ID": "25d55b0c-6e2d-4f9c-ba34-a369331901ff",
    "Name": "Kyle Penfound",
    "Company": "Dagger",
    "Company Domain": "pm.me",
    "Company URL": "",
    "Company Website": "https://dagger.io",
    "Title": "Ecosystem Team Member",
    "TagLine": "Solutions Engineer at Dagger",
    "Bio": "Kyle is part of the ecosystem team at Dagger working on the future of composable software. He has a background in DevOps and just loves giving demos!",
    "X (Twitter)": "https://twitter.com/kylepenfound",
    "LinkedIn": "https://www.linkedin.com/in/kyle-penfound-12aa6a65/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/3868-400o400o1-XcdJbVzoRjt9W7CVAcRgPD.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915961",
        "Title": "Ship Agents that Ship: A Hands-On Workshop for SWE Agent Builders",
        "Description": "Coding agents are transforming how software gets built, tested, and deployed, but engineering teams face a critical challenge: how to embrace this automation wave without sacrificing trust, control, or reliability.\r\nIn this 110-minute workshop, you‚Äôll go beyond toy demos and build production-minded AI agents using Dagger, the programmable delivery engine designed for real CI/CD and AI-native workflows. Whether you're debugging failures, triaging pull requests, generating tests, or shipping features, you'll learn how to orchestrate autonomous agents that live in and around your codebase: from your laptop to your CI platform.\r\nWe‚Äôll guide you through:\r\n\r\nBuilding real-world agents with Dagger and popular LLMs (GPT, Claude, etc.)\r\n\r\nProgramming agent environments using real languages (Go, Python, TypeScript)\r\n\r\nExecuting agent workflows locally and in GitHub Actions, so you can bring them to production\r\n\r\nUsing a composable runtime that ensures isolation, determinism, traceability, and repeatability\r\n\r\nDesigning agents that automate and enhance debugging, test generation, code review, bug fixing, and feature implementation\r\n\r\n\r\nBy the end of the workshop, you‚Äôll walk away ready to build your own army of autonomous agents, working collaboratively across your codebase, locally and in CI, accelerating development without ceding control. Let‚Äôs build agents that don‚Äôt just talk, they ship!",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "SWE Agents",
        "Room": "Nobhill A&B: Workshops",
        "Scheduled At": "3 Jun 2025 10:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "f76df644-e1f1-4fb1-8e2c-8df3806cc244",
    "Name": "Jeremy Adams",
    "Company": "Dagger",
    "Company Domain": "dagger.io",
    "Company URL": "",
    "Company Website": "https://dagger.io/",
    "Title": "Senior Leader",
    "TagLine": "Head of Ecosystem",
    "Bio": "Jeremy is a senior leader with both a technical and a strategic streak. Passionate about people and entrepreneurship, integration and automation. Through technical/business roles at Dagger, GitHub, Twistlock, and Puppet, Jeremy has both zoomed in and zoomed out a lot, acquiring an appreciation for the details and an ever-broader sense of the big architectural picture.",
    "X (Twitter)": "https://twitter.com/jpadamspdx",
    "LinkedIn": "https://www.linkedin.com/in/jeremy-adams-pdx/",
    "Blog": "https://dagger.io/blog",
    "Profile Picture": "https://sessionize.com/image/b1a3-400o400o1-szYMzkLrhuNU3jSFxHoghj.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915961",
        "Title": "Ship Agents that Ship: A Hands-On Workshop for SWE Agent Builders",
        "Description": "Coding agents are transforming how software gets built, tested, and deployed, but engineering teams face a critical challenge: how to embrace this automation wave without sacrificing trust, control, or reliability.\r\nIn this 110-minute workshop, you‚Äôll go beyond toy demos and build production-minded AI agents using Dagger, the programmable delivery engine designed for real CI/CD and AI-native workflows. Whether you're debugging failures, triaging pull requests, generating tests, or shipping features, you'll learn how to orchestrate autonomous agents that live in and around your codebase: from your laptop to your CI platform.\r\nWe‚Äôll guide you through:\r\n\r\nBuilding real-world agents with Dagger and popular LLMs (GPT, Claude, etc.)\r\n\r\nProgramming agent environments using real languages (Go, Python, TypeScript)\r\n\r\nExecuting agent workflows locally and in GitHub Actions, so you can bring them to production\r\n\r\nUsing a composable runtime that ensures isolation, determinism, traceability, and repeatability\r\n\r\nDesigning agents that automate and enhance debugging, test generation, code review, bug fixing, and feature implementation\r\n\r\n\r\nBy the end of the workshop, you‚Äôll walk away ready to build your own army of autonomous agents, working collaboratively across your codebase, locally and in CI, accelerating development without ceding control. Let‚Äôs build agents that don‚Äôt just talk, they ship!",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "SWE Agents",
        "Room": "Nobhill A&B: Workshops",
        "Scheduled At": "3 Jun 2025 10:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "c849b8ac-e452-466a-a7dd-5c163c2780e2",
    "Name": "Dan Mason",
    "Company": "Stride",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.stride.build/",
    "Company Website": "http://stride.build",
    "Title": "Principal, AI",
    "TagLine": "Principal, Head of AI",
    "Bio": "Dan Mason\r\nPrincipal, AI - Stride\r\n\r\nDan is a product and technology leader with unusually broad experience -- in 20+ years at companies like ESPN, Shutterstock, Viacom, NBCUniversal and a variety of startups and scaleups, he‚Äôs accumulated a wealth of knowledge about how digital product development works (and doesn‚Äôt), and is excited to apply those insights to reimagining teams and products in the age of LLMs. ¬† He is an engineer turned product manager with strong technical skills, and the teams he leads are highly cross-functional -- often including product, technology, design, PMO and data science. \r\n\r\nDan leads Stride‚Äôs AI/LLM practice and is focused on thought leadership, code generation, workflow automation, and shaping and leading generative AI client engagements.  He is also an active product coach and consultant, and a member of Docker‚Äôs Technical Advisory Group.  Dan lives in New Jersey with his wife and three busy teenagers, and holds a BA in Computer Science and English Literature from Williams College.\r\n",
    "X (Twitter)": "http://x.com/danmason",
    "LinkedIn": "http://www.linkedin.com/in/dnmason",
    "Blog": "http://jpsj.me",
    "Profile Picture": "https://sessionize.com/image/b32e-400o400o1-RexErF1ktkKWJAvUg7cyQc.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "907544",
        "Title": "Case Study + Deep Dive: Telemedicine Support Agents with LangGraph/MCP",
        "Description": "Workshop/walkthrough of a Stride/Avila Science partnership to build agentic telemedicine support",
        "Format": "Workshop",
        "Level": "Advanced",
        "Scope": "Case Study/War Story",
        "Tracks": "AI in Action",
        "Room": "Foothill C: Workshops",
        "Scheduled At": "3 Jun 2025 01:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "61c5d52b-517f-45fb-ac0a-ca1acdd5180d",
    "Name": "Philipp Schmid",
    "Company": "Google DeepMind",
    "Company Domain": "google.com",
    "Company URL": "https://deepmind.google/",
    "Company Website": "",
    "Title": "Senior AI Developer Relations Engineer",
    "TagLine": "AI Developer Experience",
    "Bio": "Philipp Schmid is a Senior AI Developer Relations Engineer at Google DeepMind working on Gemini, Gemma with the mission to help every developer and builder to create and benefit from AI in a responsible way. ",
    "X (Twitter)": "https://x.com/_philschmid",
    "LinkedIn": "https://www.linkedin.com/in/philipp-schmid-a6a2bb196/",
    "Blog": "https://www.philschmid.de/",
    "Profile Picture": "https://sessionize.com/image/9039-400o400o1-fAE2ViRtc5VLsug3jFkR4W.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "910732",
        "Title": "AI Engineering with the Google Gemini 2.5 Model Family",
        "Description": "Hands on Workshop on learning to use Gemini 2.5 Pro in combination with Agentic tooling and MCP Servers.",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "AI in Action",
        "Room": "SOMA: Workshops",
        "Scheduled At": "3 Jun 2025 01:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "48bba77e-6187-42e9-bfd3-10c9ae781b89",
    "Name": "Philipp Krenn",
    "Company": "Elastic",
    "Company Domain": "xeraa.net",
    "Company URL": "",
    "Company Website": "https://www.elastic.co",
    "Title": "Lead, Developer Relations",
    "TagLine": "Code and conference monkey",
    "Bio": "Philipp leads Developer Relations at Elastic ‚Äî the company behind the Elasticsearch, Kibana, Beats, and Logstash. Based in San Francisco, he lives to demo interesting technology and solve challenging problems ‚Äî all with a smile and a terminal window.",
    "X (Twitter)": "https://twitter.com/xeraa",
    "LinkedIn": "https://www.linkedin.com/in/philippkrenn/",
    "Blog": "https://xeraa.net/blog/",
    "Profile Picture": "https://sessionize.com/image/1520-400o400o1-75c94302-4b9c-4e3c-9e0a-42ee715c44a5.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916214",
        "Title": "Information Retrieval from the Ground Up",
        "Description": "Vector search is only a feature. Search engines and information retrieval have retaken their position as the foundation of RAG. This workshop takes you through decades of research, what has been working for a long time, and how it got better with Machine Learning.",
        "Format": "Workshop",
        "Level": "Introductory and overview",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "Foothill G1&2: Workshops",
        "Scheduled At": "3 Jun 2025 01:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "7f85ae75-4426-4a66-aa12-b7d8d5e91a8d",
    "Name": "Ilan Bigio",
    "Company": "OpenAI",
    "Company Domain": "gmail.com",
    "Company URL": "https://openai.com/",
    "Company Website": "",
    "Title": "Founding Member of Developer Experience Team",
    "TagLine": "Developer Experience",
    "Bio": "Ilan Bigio is a founding member of OpenAI‚Äôs Developer Experience team where he explores model capabilities, builds demos and developer tools, and shares his learnings through talks and docs.\r\n\r\nHis work includes creating the AI phone ordering demo showcased at DevDay 2024, leading technical development for Swarm, the precursor to the Agents SDK, and contributing to Codex CLI. Prior to that, he was a Solutions Architect at OpenAI, partnering with companies like Cursor, Khan Academy, and Klarna to shape their AI products. Before OpenAI, he was a full-stack Software Engineer at Google, building for YouTube at scale.\r\n\r\nIlan‚Äôs journey started as a hobby hacker, diving into operating systems and reverse engineering, before shifting to language models in 2020. He created projects like ShellAI‚Äîan open-source, AI-powered terminal assistant‚Äîand is passionate about sharing knowledge. With a multidisciplinary background spanning web development, AI/ML, and operating systems, he‚Äôs designed and taught courses at Brown and continues to share his expertise through in-depth technical OpenAI guides on topics like Function Calling, Latency Optimization, and Agent Orchestration.",
    "X (Twitter)": "https://x.com/ilanbigio",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/a694-400o400o1-NRN3Y5ytAxuCQQqhJ2SeFe.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "930540",
        "Title": "Every Way to Optimize Your Models with OpenAI",
        "Description": "Covering all forms of fine-tuning and prompt engineering, like SFT, DPO, RFT, prompt engineering / optimization, and agent scaffolding.",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "AI in Action",
        "Room": "Salons 2-6: Workshops",
        "Scheduled At": "3 Jun 2025 01:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "7ff290c4-046b-4831-8a24-0173a162957f",
    "Name": "Du‚ÄôAn Lightfoot",
    "Company": "Amazon Web Services",
    "Company Domain": "aws.amazon.com",
    "Company URL": "",
    "Company Website": "https://aws.amazon.com/?nc2=h_lg",
    "Title": "Senior Developer Advocate",
    "TagLine": "Sr. Developer Advocate",
    "Bio": "* Du'An Lightfoot is an IT leader and international speaker who serves as a Sr. Developer Advocate at AWS. His perspective on AI transformation draws from an unconventional path. From serving as a USAF veteran in Afghanistan to driving technical innovation at Cisco and Cerner. Du'An bridges the gap between cutting-edge technology and practical implementation, translating complex AI concepts into actionable insights for professionals reshaping their careers.\r\n\r\nBeyond his technical expertise, Du'An dedicates himself to mentoring others through the rapidly evolving tech landscape. Through his YouTube channel and speaking engagements across the globe, he doesn't just talk about technological change, he provides concrete strategies for embracing it. Drawing from the discipline and adaptability he developed during military service, Du'An equips his audiences with practical frameworks to become change agents within their organizations and careers.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/24b0-400o400o1-4ZnTKYQtQjx2EzH6eXeqq5.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "933607",
        "Title": "Building Agents with Amazon Nova Act and MCP",
        "Description": "In this 2-hour workshop, participants will gain practical hands-on experience building sophisticated AI agents using Amazon's agent technologies. You'll learn to build agents that can navigate the web like humans, perform complex multi-step tasks, and leverage specialized tools through natural language commands. You‚Äôll explore Amazon Nova Act for reliable web navigation, Model Context Protocol (MCP) for connecting agents to external data sources and APIs, and Amazon Bedrock Agents for orchestrating complex workflows. Through guided exercises, you'll create agents capable of retrieving information and taking action across web applications, all through natural language interactions. By the end of this workshop, you'll have the practical skills to build AI agents that can browse websites, interact with web interfaces, and solve multi-step problems by combining these powerful Amazon technologies.",
        "Format": "Workshop",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "AI Architects, Model Context Protocol (MCP), AI in Action, Computer-Using Agents (CUA)",
        "Room": "Golden Gate Ballroom B: Workshops",
        "Scheduled At": "3 Jun 2025 01:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "b3866d58-4534-4446-905b-6fc6fcc780dd",
    "Name": "Dominik Kundel",
    "Company": "OpenAI",
    "Company Domain": "openai.com",
    "Company URL": "https://openai.com/",
    "Company Website": "",
    "Title": "Developer Experience & SDKs",
    "TagLine": "Developer Experience ",
    "Bio": "Dominik is a developer and product leader with a passion for Developer Experience and Generative AI. He's currently working on Developer Experience & SDKs at OpenAI. Previously he lead Product & Design for Twilio's Emerging Tech & Innovation organization where his team worked on customer-aware AI agents. Dominik loves tinkering with anything that can run JavaScript, from front-end servers to CLIs and coffee machines. You can find him tweeting @dkundel and in his spare time he's working on cocktails, food and photography.",
    "X (Twitter)": "https://twitter.com/dkundel",
    "LinkedIn": "https://linkedin.com/in/dkundel",
    "Blog": "https://dkundel.com",
    "Profile Picture": "https://sessionize.com/image/a94f-400o400o1-KHnAdgMpikgEpDLJB3QNzU.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914537",
        "Title": "Building voice agents with OpenAI",
        "Description": "We'll walk through the differences between chained and speech-to-speech powered voice agents, how to approach them, best practices and transform a text-based agent into our first voice-enabled agent",
        "Format": "Workshop",
        "Level": "Introductory and overview",
        "Scope": "Technical deep dive",
        "Tracks": "Voice",
        "Room": "Foothill C: Workshops",
        "Scheduled At": "3 Jun 2025 03:30 PM"
      }
    ]
  },
  {
    "Speaker ID": "fa7aeb1e-2489-4c86-a0f3-13697cb4d20b",
    "Name": "Sarah Guo",
    "Company": "Conviction",
    "Company Domain": "conviction.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "Keynote Speaker",
    "TagLine": "",
    "Bio": "",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "927324",
        "Title": "Conviction Session",
        "Description": "Please Fill in",
        "Format": "Keynote",
        "Level": "Intermediate",
        "Scope": "",
        "Tracks": "",
        "Room": "Keynote/General Session (Yerba Buena 7&8)",
        "Scheduled At": "4 Jun 2025 09:00 AM"
      }
    ]
  },
  {
    "Speaker ID": "4b95a47c-6ec3-4b44-ba84-c158e802fc89",
    "Name": "Danielle Perszyk",
    "Company": "Amazon",
    "Company Domain": "gmail.com",
    "Company URL": "https://labs.amazon.science/",
    "Company Website": "https://labs.amazon.science/",
    "Title": "Cognitive Scientist",
    "TagLine": "Cognitive Scientist, PhD",
    "Bio": "Danielle is a cognitive scientist at the new Amazon AGI SF Lab. She received her PhD from Northwestern, where she studied the evolution and development of language. Previously, she was at Google and Adept. ",
    "X (Twitter)": "https://x.com/drperszyk",
    "LinkedIn": "https://www.linkedin.com/in/danielleoscillations/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/b67c-400o400o1-BFXHNVeqAK4D8jNpezM9ZJ.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "929790",
        "Title": "Useful General Intelligence",
        "Description": "We‚Äôre all hearing that AI agents will enable AGI, but they can‚Äôt yet reliably perform even basic computer tasks. It turns out that getting AI to click, type, and scroll is more challenging than getting it to generate code. How can we build general-purpose agents that can do anything we can do on a computer? \r\n\r\nThis is our goal at the Amazon AGI SF Lab. In this talk, I‚Äôll propose a new approach to agents that we call Useful General Intelligence. After describing how we‚Äôre solving the biggest challenges in computer use while enabling developers to access our tech in it‚Äôs earliest developmental stages, I‚Äôll show real workflows that developers have built with Nova Act, our agentic model and SDK. ",
        "Format": "Keynote",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "AI in Action",
        "Room": "Keynote/General Session (Yerba Buena 7&8)",
        "Scheduled At": "4 Jun 2025 09:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "527dd628-aaa1-4248-a232-5d92803d426a",
    "Name": "Joel Hron",
    "Company": "Thomson Reuters",
    "Company Domain": "thomsonreuters.com",
    "Company URL": "https://www.thomsonreuters.com/en",
    "Company Website": "https://www.thomsonreuters.com/en",
    "Title": "Chief Technology Officer",
    "TagLine": "CTO",
    "Bio": "Joel Hron is a passionate innovator driving the future of product technology and AI at Thomson Reuters. As Chief Technology Officer, he leads Product Engineering and AI Research & Development, pushing the boundaries of what‚Äôs possible in Legal, Tax, Audit, Trade, Compliance, and Risk solutions.\r\n\r\nJoel joined Thomson Reuters in 2022 through the acquisition of ThoughtTrace, where he served as CTO. Previously, he led AI and TR Labs, launching seven groundbreaking GenAI products in just 18 months, transforming legal research, tax analysis, and contract drafting.\r\n\r\nHis approach is centered on rethinking processes through technology, building teams rooted in trust, transparency, and customer-centric innovation. Joel envisions AI not as a replacement for human expertise, but as a force that enhances professional decision-making, making expert information more accessible and impactful.\r\n\r\nA New Orleans native, Joel‚Äôs global career spans work in London and Africa, and he now calls Zug, Switzerland home. He holds a Master‚Äôs in Mechanical Engineering from the University of Texas at Austin and a Bachelor‚Äôs in Engineering from Texas Christian University.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/joel-hron-90a3421a/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/d150-400o400o1-GySHFV3G8UNoTbUdavrqVa.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "903524",
        "Title": "From Copilot to Colleague: Building Trustworthy Productivity Agents for High-Stakes Work",
        "Description": "This keynote will explore what it takes to move from basic generative assistants to fully agentic AI‚Äîsystems that don‚Äôt just suggest but plan, act, and adapt‚Äîall within the structured, high-trust environments where professionals actually work.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Product launch",
        "Tracks": "Leadership: Fortune 500",
        "Room": "Golden Gate Ballroom C: AI in the Fortune 500",
        "Scheduled At": "4 Jun 2025 11:15 AM"
      }
    ]
  },
  {
    "Speaker ID": "8f80de08-076f-46c5-b824-9c28441cb56f",
    "Name": "Sean DuBois",
    "Company": "OpenAI",
    "Company Domain": "openai.com",
    "Company URL": "https://openai.com/",
    "Company Website": "http://openai.com/",
    "Title": "WebRTC and Realtime API Developer",
    "TagLine": "WebRTC and Realtime API",
    "Bio": "Sean works on WebRTC and the Realtime API at OpenAI. He built 1-800-CHATGPT. He is the founder of Pion, the most widely used open source WebRTC project. He has previously worked at AWS, LiveKit, Apple, and Etsy.",
    "X (Twitter)": "https://x.com/_pion",
    "LinkedIn": "https://linkedin.com/in/sean-dubois",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/5861-400o400o1-wTc662414LPKiqmxWnCYdk.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915028",
        "Title": "[Voice Keynote] Your realtime AI is ngmi",
        "Description": "Sean DuBois of OpenAI and Pion, and Kwindla Hultman Kramer of Daily and Pipecat, will talk about why you have to design realtime AI systems from the network layer up.\r\n\r\nMost people who build realtime AI apps and frameworks get it wrong. They build from either the model out or the app layer down. But unless you start with the network layer and build up, you'll never be able to deliver realtime audio and video streams reliably. And perhaps even worse, you'll get core primitives wrong: interruption handling, conversation state management, asynchronous function calling.\r\n\r\nSean and Kwin agree on most things: old-school realtime systems people against the rest of the world. But they disagree on some important things, too, and will argue about those things live on stage. Do you need to give developers \"thick\" client-side realtime SDKs? Can you build truly great vendor neutral APIs? (You'll be surprised which of them argues which side, on that topic.)",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "Voice",
        "Room": "Foothill E: Voice",
        "Scheduled At": "4 Jun 2025 11:15 AM"
      }
    ]
  },
  {
    "Speaker ID": "c447f01b-42fd-4c76-a8f3-3ed2f73731b3",
    "Name": "Tanmai Gopal",
    "Company": "Hasura",
    "Company Domain": "hasura.io",
    "Company URL": "https://hasura.io/",
    "Company Website": "https://hasura.io",
    "Title": "Co-founder and CEO",
    "TagLine": "CEO, Co-founder",
    "Bio": "Tanmai Gopal is the co-founder and CEO of Hasura, where he has been at the forefront of rethinking how organizations access and work with data. \r\n\r\nA passionate product builder, Tanmai first led the creation of the Hasura GraphQL Engine, transforming how developers interact with data to build modern applications. Hasura has since expanded beyond developers to the enterprise level, driving the adoption of Data Delivery Network (DDN) and PromptQL‚Äîtechnologies that CXOs are now choosing to drive mission-critical AI transformation in their organizations.\r\n\r\nBefore Hasura, Tanmai worked with large enterprises to modernize their technology stacks, moving from monoliths to cloud-native architectures. A full-stack engineer at heart, he is passionate about building technology that increases individual agency. He also created and taught one of the largest MOOCs on modern application development at the time, reaching over 250,000 students.",
    "X (Twitter)": "https://twitter.com/tanmaigo",
    "LinkedIn": "https://www.linkedin.com/in/tanmaig/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/8ff1-400o400o1-Db44ofg5z3GckqARUUGNet.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916117",
        "Title": "[Reliability Keynote] AI Automation that actually works: $100M, messy data, zero surprises",
        "Description": "We will review the different kinds of automation use-cases, and the approach we used, that will drive over a $100M of expected annual impact by deploying AI for business critical initiatives. \r\n\r\nWe will discuss what kinds of automation initiatives become possible because of Gen AI. These were not tenable before because of the amount of customization required per customer or per scenario, and the kind of data involved in these workflows. Previously, these workflows were driven manually which were both error prone and required expensive training. \r\n\r\nTo replace or augment these manual business critical processes, automation _has_ to cross a very high bar of reliability. \r\n\r\nWe will share how we addressed the inherent non-determinism of Gen AI to create a predictable system that doesn‚Äôt have any surprising failure modes. We‚Äôll also discuss how we worked with our existing data that was spread across various systems without an expensive centralisation and clean up effort. ",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Agent Reliability",
        "Room": "Foothill C: Agent Reliability",
        "Scheduled At": "4 Jun 2025 11:15 AM"
      }
    ]
  },
  {
    "Speaker ID": "179d0b1c-fa38-4d18-87bd-f280a52c95bd",
    "Name": "Alison Cossette",
    "Company": "Neo4j ",
    "Company Domain": "claritrace.com",
    "Company URL": "www.neo4.com",
    "Company Website": "https://www.patrun.ai",
    "Title": "Developer Advocate",
    "TagLine": "Data Science Strategist, Advocate, Educator",
    "Bio": "Alison Cossette is a dynamic Data Science Strategist, Educator, and Podcast Host. As a Developer Advocate at Neo4j specializing in Graph Data Science, she brings a wealth of expertise to the field. With her strong technical background and exceptional communication skills, Alison bridges the gap between complex data science concepts and practical applications. Alison‚Äôs passion for responsible AI shines through in her work. She actively promotes ethical and transparent AI practices and believes in the transformative potential of responsible AI for industries and society. Through her engagements with industry professionals, policymakers, and the public, she advocates for the responsible development and deployment of AI technologies. She is currently a Volunteer Member of the US Department of Commerce - National Institute of Standards and Technology's Generative AI Public Working Group Alison‚Äôs academic journey includes Masters of Science in Data Science studies, specializing in Artificial Intelligence, at Northwestern University and research with Stanford University Human-Computer Interaction Crowd Research Collective. Alison combines academic knowledge with real-world experience. She leverages this expertise to educate and empower individuals and organizations in the field of data science. Overall, Alison Cossette‚Äôs multifaceted background, commitment to responsible AI, and expertise in data science make her a respected figure in the field. Through her role as a Developer Advocate at Neo4j and her podcast, she continues to drive innovation, education, and responsible practices in the exciting realm of data science and AI.",
    "X (Twitter)": "https://twitter.com/i/flow/login?redirect_after_login=%2Falison_cossette",
    "LinkedIn": "https://www.linkedin.com/in/alison-cossette-7115857/",
    "Blog": "https://medium.com/@alison_cossette",
    "Profile Picture": "https://sessionize.com/image/4c5e-400o400o1-NBTnUuFrxX22XutvVhrvGP.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "921229",
        "Title": "Graph Intelligence: Enhance Reasoning and Retrieval Using Graph Analytics",
        "Description": "Advanced GraphRAG techniques apply graph ML and algorithms, wrapped into tidy notebooks.",
        "Format": "Workshop",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "GraphRAG",
        "Room": "Golden Gate Ballroom B: GraphRAG",
        "Scheduled At": "4 Jun 2025 11:15 AM"
      }
    ]
  },
  {
    "Speaker ID": "262b6964-1097-4c41-9117-4fbf9aefb088",
    "Name": "Andreas Kollegger",
    "Company": "Neo4j",
    "Company Domain": "neo4j.com",
    "Company URL": "https://neo4j.com/",
    "Company Website": "https://neo4j.com",
    "Title": "Technological Humanist",
    "TagLine": "GenAI Lead",
    "Bio": "Andreas is a technological humanist. Starting at NASA, Andreas designed systems from scratch to support science missions. Then in Zambia, he built medical informatics systems to apply technology for social good. Now with Neo4j, he is democratizing graph databases to validate and extend our intuitions about how the world works. Everything is connected. ",
    "X (Twitter)": "https://twitter.com/akollegger",
    "LinkedIn": "https://www.linkedin.com/in/akollegger/",
    "Blog": "https://neo4j.com/blog/developer/",
    "Profile Picture": "https://sessionize.com/image/9be1-400o400o1-3z1SkCUTLZX6NamTinAsif.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "921229",
        "Title": "Graph Intelligence: Enhance Reasoning and Retrieval Using Graph Analytics",
        "Description": "Advanced GraphRAG techniques apply graph ML and algorithms, wrapped into tidy notebooks.",
        "Format": "Workshop",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "GraphRAG",
        "Room": "Golden Gate Ballroom B: GraphRAG",
        "Scheduled At": "4 Jun 2025 11:15 AM"
      }
    ]
  },
  {
    "Speaker ID": "d2b57aa6-3078-480f-9bd9-c695ca74ede4",
    "Name": "Raiza Martin",
    "Company": "Huxe",
    "Company Domain": "gmail.com",
    "Company URL": "huxe.com",
    "Company Website": "",
    "Title": "Founder",
    "TagLine": "CEO & Co-Founder Huxe || Previously NotebookLM",
    "Bio": "A product leader with a unique lens on AI's user experience challenges, Raiza brings insights from both big tech and startup trenches. \r\n\r\nMost recently leading Google's NotebookLM team, she has shaped how millions of users interact with generative AI. Now, as a founder, she is reimagining these experiences from first principles. \r\n\r\nWith years of hands-on PM experience guiding technical teams through the practical realities of shipping AI products, Raiza offers a rare combination of enterprise-scale perspective and startup-speed execution.",
    "X (Twitter)": "https://x.com/raizamrtn",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/4455-400o400o1-wqpaVc41zMJrRTRDbX6dtU.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "925337",
        "Title": "[PM Keynote] Everything is ugly so go build something that isn't",
        "Description": "We're in an awkward adolescent phase of AI product (design). But what if this chaotic moment is actually our greatest opportunity? Enter the rebuilding revolution.\r\n\r\nIn this talk, we'll explore how the current state of AI interfaces offers a once-in-a-career chance to rethink fundamental UX patterns, with practical guidance on avoiding common pitfalls that plague first-generation AI products. \r\n\r\nLearn how to balance technical constraints with user needs, identify which conventional wisdom to keep versus discard, and ship AI experiences that actually delight users rather than frustrate them.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "AI Product Management",
        "Room": "Foothill G 1&2: Product Management",
        "Scheduled At": "4 Jun 2025 11:15 AM"
      }
    ]
  },
  {
    "Speaker ID": "7e0cf113-19cc-478a-83f3-b42f3b6a3cba",
    "Name": "Dylan Patel",
    "Company": "SemiAnalysis",
    "Company Domain": "semianalysis.com",
    "Company URL": "https://semianalysis.com/",
    "Company Website": "https://semianalysis.com/",
    "Title": "Founder, CEO, and Chief Analyst",
    "TagLine": "Chief Analyst",
    "Bio": "Dylan is the founder, CEO, and Chief Analyst for SemiAnalysis, the preeminent authority on all things AI and semiconductors. Through Dylan‚Äôs unwavering commitment to excellence, he has built the firm from the ground up as the thought leader from the semiconductor supply chain to the cloud ecosystem, machine learning models, and all things in between. Since 2020, SemiAnalysis has transformed its business from a solo venture into a cohesive and focused team to provide breaking news and in-depth analysis for the most strategic, complex, and escalating challenges in the semiconductor industry.",
    "X (Twitter)": "https://x.com/dylan522p/",
    "LinkedIn": "https://www.linkedin.com/in/dylanpatelsa/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/8d6c-400o400o1-QXo3uGnhLToerahLdP43w1.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "928676",
        "Title": "[Infra Keynote] Geopolitics of AI Infrastructure",
        "Description": "As AI reshapes the global balance of power, the infrastructure behind it‚Äîchips, data centers, power, and supply chains‚Äîhas become a new arena for geopolitical competition. This talk explores how nations are racing to secure critical AI hardware, control compute capacity, and assert influence over the technologies and talent that define the future.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Infrastructure",
        "Room": "Foothill F: Infrastructure",
        "Scheduled At": "4 Jun 2025 11:15 AM"
      }
    ]
  },
  {
    "Speaker ID": "5b8bacad-9e6b-4a65-9f31-c1c8c89e9097",
    "Name": "Eugene Yan",
    "Company": "Amazon",
    "Company Domain": "eugeneyan.com",
    "Company URL": "http://amazon.com",
    "Company Website": "",
    "Title": "Principal Applied Scientist",
    "TagLine": "Principal Applied Scientist",
    "Bio": "Eugene Yan is a Principal Applied Scientist at Amazon building recommendation systems and AI-powered products that serve customers at scale. He's led ML/AI teams at Alibaba, Lazada, and a Healthtech Series A. He writes about RecSys, LLMs, and engineering at eugeneyan.com.",
    "X (Twitter)": "https://x.com/eugeneyan",
    "LinkedIn": "https://www.linkedin.com/in/eugeneyan/",
    "Blog": "https://eugeneyan.com",
    "Profile Picture": "https://sessionize.com/image/1514-400o400o1-VFpaprWDmENszopRm9xeX6.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "929337",
        "Title": "Recsys Keynote: Improving Recommendation Systems & Search in the Age of LLMs",
        "Description": "Recommendation systems and search have long adopted advances in language modeling, from early adoption of Word2vec for embedding-based retrieval to the transformative impact of GRUs, Transformers, and BERT on predicting user interactions. Now, the rise of large language models (LLMs) is inspiring innovations in model architecture, scalable system designs, and richer customer experiences.\r\n\r\nIn this keynote, we'll dive into cutting-edge industry applications of LLMs in recommendation and search systems, exploring real-world implementations and measurable outcomes. Join us for an look at current trends and an exciting vision of how LLM-driven techniques will shape the future of content discovery and intelligent search.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "RecSys",
        "Room": "Golden Gate Ballroom A: LLM RecSys",
        "Scheduled At": "4 Jun 2025 11:15 AM"
      }
    ]
  },
  {
    "Speaker ID": "41650cf7-bce8-486c-bff9-1283aa976cbe",
    "Name": "Vaibhav Page",
    "Company": "BlackRock",
    "Company Domain": "blackrock.com",
    "Company URL": "https://www.blackrock.com/corporate",
    "Company Website": "",
    "Title": "Principal Engineer",
    "TagLine": "Principal Engineer ",
    "Bio": "Vaibhav is a Principal Engineer at BlackRock, where he leads the development of the Data Science and AI platform powering \r\ninvestment research and automation across the firm. Vaibhav is also the author of Argo-Events, a CNCF-graduated project widely used for event-driven automation in cloud-native environments.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/vaibhav-page-b0621741",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/7460-400o400o1-Sp7vVBU4Ue9iXMPDyNJPPm.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "904722",
        "Title": "Accelerating Investment Operations: How BlackRock Builds Custom Knowledge Apps at Scale.",
        "Description": "Investment Operations teams are the backbone of asset and investment management firms. Their day-to-day work not only enables portfolio managers to respond swiftly to market events but also ensures that complex, unstructured data flows seamlessly across the organization.\r\nIn this talk, we introduce a modular, Kubernetes-native AI framework purpose-built to scale custom Knowledge Apps across the enterprise. Designed with speed, flexibility, and compliance in mind, the framework empowers teams to launch production-grade document extraction applications in minutes instead of months, unlocking new levels of automation and efficiency for investment management workflows.\r\nWe‚Äôll also share how this framework has helped BlackRock streamline document extraction processes, generate investment signals, reduce operational overhead, and accelerate the delivery of high-impact business use cases‚Äîall while maintaining the robustness and control required in a regulated industry.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Fortune 500",
        "Room": "Golden Gate Ballroom C: AI in the Fortune 500",
        "Scheduled At": "4 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "45160f46-e17e-4801-9395-eaaa9549e70b",
    "Name": "Infant Vasanth",
    "Company": "BlackRock",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.blackrock.com/corporate",
    "Company Website": "",
    "Title": "Engineering Team Lead, Studio Compute Platform",
    "TagLine": "Senior Director of Engineering",
    "Bio": "Infant Vasanth leads the engineering team responsible for the Studio Compute Platform, BlackRock's analytics and automation platform that enables our users to conduct research & analysis, run automations and distribute research at scale.\r\nIn addition, Infant is also leading the Data & AI Acceleration team focusing on efforts to enhance Aladdin Studio's AI capabilities along side the Operational AI capabilities(prospectus analyzer, operational agents etc.)",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/irosariov/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/c520-400o400o1-JnUBivkDWXsKDLfHtbyEQw.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "904722",
        "Title": "Accelerating Investment Operations: How BlackRock Builds Custom Knowledge Apps at Scale.",
        "Description": "Investment Operations teams are the backbone of asset and investment management firms. Their day-to-day work not only enables portfolio managers to respond swiftly to market events but also ensures that complex, unstructured data flows seamlessly across the organization.\r\nIn this talk, we introduce a modular, Kubernetes-native AI framework purpose-built to scale custom Knowledge Apps across the enterprise. Designed with speed, flexibility, and compliance in mind, the framework empowers teams to launch production-grade document extraction applications in minutes instead of months, unlocking new levels of automation and efficiency for investment management workflows.\r\nWe‚Äôll also share how this framework has helped BlackRock streamline document extraction processes, generate investment signals, reduce operational overhead, and accelerate the delivery of high-impact business use cases‚Äîall while maintaining the robustness and control required in a regulated industry.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Fortune 500",
        "Room": "Golden Gate Ballroom C: AI in the Fortune 500",
        "Scheduled At": "4 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "1f442afe-45ef-48c0-9782-5a5267729d06",
    "Name": "Dr. Jasper Zhang, PhD",
    "Company": "Hyperbolic",
    "Company Domain": "hyperbolic.io",
    "Company URL": "",
    "Company Website": "https://hyperbolic.xyz/",
    "Title": "CEO and Co-founder",
    "TagLine": "CEO",
    "Bio": "Dr. Jasper Zhang is the CEO and Co-founder of Hyperbolic. A mathematical prodigy, he completed his Ph.D. in Mathematics at UC Berkeley in just two years. He is a Gold Medalist in both the Alibaba Global Math Competition and the Chinese Mathematical Olympiad. Before founding Hyperbolic, he held roles at Ava Labs and Citadel Securities, bringing deep expertise in quantitative finance and AI.",
    "X (Twitter)": "https://x.com/zjasper666",
    "LinkedIn": "https://www.linkedin.com/in/yuezhang95/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/dd71-400o400o1-fJG88PsUEVX7XTXyfoHZ7b.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "905305",
        "Title": "Building Hyperbolic: The On-Demand AI Cloud for GPUs, Inference, and AI Services",
        "Description": "AI moves fast. Legacy cloud can‚Äôt keep up. This session breaks down how Hyperbolic is redefining what developers should expect from AI infrastructure. We‚Äôll cover how to instantly spin up low-cost GPUs, serve cutting-edge models with serverless inference, and deploy AI services at scale without the DevOps, rate limits, or pricing surprises. Whether you're training, fine-tuning, or just shipping fast, this is the new standard for building with AI.",
        "Format": "Talk",
        "Level": "Expert",
        "Scope": "Technical deep dive",
        "Tracks": "Infrastructure",
        "Room": "Foothill F: Infrastructure",
        "Scheduled At": "4 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "155070cc-ad6b-4382-9085-2a872555c9bb",
    "Name": "Devansh Tandon",
    "Company": "Google",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.google.com/",
    "Company Website": "",
    "Title": "Principal Product Manager",
    "TagLine": "Principal Product Manager ",
    "Bio": "Devansh Tandon is a Principal Product Manager at Google, leading YouTube‚Äôs discovery system and GenAI efforts. At YouTube, Devansh leads a team of research scientists and ML engineers to develop the recommendation engine, which powers 70%+ of YouTube watchtime for 2B+ daily active users. \r\n\r\nHe led Google DeepMind & YouTube partnerships, and has launched GenAI products including video summaries & AI dubbing for YouTube. At DeepMind, Devansh led the development of a new generative recommendation system ‚Äì adapting Gemini to power YouTube recommendations ‚Äì from research to scaled consumer launch for 200m+ DAU. \r\n\r\nPreviously, Devansh has led AI teams in Google Search, Google News and Google Ads. He graduated Magna Cum Laude from Yale University, with a BS in Computer Science and Economics.  ",
    "X (Twitter)": "https://x.com/devanshtandon_",
    "LinkedIn": "https://www.linkedin.com/in/devanshtandon/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/6bb5-400o400o1-VTEFgfQNYAUbPERTbzh4yr.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "906567",
        "Title": "Teaching Gemini to Speak YouTube: Adapting LLMs for Video Recommendations to 2B+ DAU",
        "Description": "YouTube recommendations drive nearly two-thirds of the platform's staggering 5 billion daily watch hours for 2 billion+ DAU. Traditionally powered by large embedding models (LEMs), we're undertaking a fundamental shift: rebuilding our recommendation stack using foundation models like Gemini. This talk dives into our engineering journey adapting general-purpose LLMs (Gemini) for the highly specialized, dynamic, and massive-scale task of YouTube recommendations.\r\n\r\nWe'll start with a critical first step: creating a \"language\" for YouTube videos. Learn how we developed 'SemanticID', a novel tokenization scheme that distills multimodal video features (text, audio, frames) into discrete tokens representable by an LLM. Our paper (Better Generalization with Semantic IDs: A Case Study in Ranking for Recommendations) is a landmark work in this space.  \r\n\r\nWe then adapt the base Gemini checkpoint to understand sequences of these video tokens alongside natural language, effectively teaching it the grammar of user watch behavior. A key insight: unlike static LLM training, YouTube's corpus evolves so rapidly (millions of new videos daily) that daily retraining is non-negotiable to maintain recommendation quality.\r\n\r\nNow we can prompt LRM with user history and context to generate personalized candidate recommendations, achieving the biggest engagement wins on YouTube in the last ~decade. \r\n\r\nThere‚Äôs a lot of attention on the LLM-led transformation of Search (with AI Overviews, Perplexity, ChatGPT-Search etc). However, across large consumer apps, it‚Äôs the recommendation systems & feeds that drive most consumer engagement, not just search (eg. YouTube recs drive 67% of WatchTime). This talk is about the LLM-led transformation of recommendations & feeds ‚Äì building a recommendation engine on top of Gemini.\r\n",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "RecSys",
        "Room": "Golden Gate Ballroom A: LLM RecSys",
        "Scheduled At": "4 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "5c1894f2-b91e-48f1-a1f2-b67c8effc3d0",
    "Name": "Michael Albada",
    "Company": "Microsoft Research",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.microsoft.com/en-us/research/video/ai-and-security/?msockid=043945adec02666a0fcc5073ed8a6700",
    "Company Website": "https://michaelalbada.com",
    "Title": "Machine Learning Engineer and Applied AI Researcher",
    "TagLine": "Principal Applied Scientist",
    "Bio": "Michael Albada is a machine learning engineer and applied AI researcher focused on building agentic systems that bridge research and real-world impact. At Microsoft, he leads initiatives applying generative AI to cybersecurity, helping protect organizations and individuals through intelligent automation.\r\n\r\nMichael has previously developed large-scale ML systems for geospatial intelligence at Uber and natural language understanding at ServiceNow. His work spans consumer products, enterprise SaaS, and applied research, with deep expertise in foundation models, recommender systems, NLP, and scalable ML infrastructure, and he holds a B.A. from Stanford, MPhil from Cambridge, and an MS in computer science from Georgia Tech.\r\n\r\nHe is the author of the upcoming O‚ÄôReilly book Building Applications with AI Agents, a practical guide to designing and deploying single- and multi-agent systems with foundation models. As a speaker, Michael brings a passion for turning complex research into actionable insights‚Äîand for equipping engineers to build the next generation of AI-powered applications. ",
    "X (Twitter)": "https://x.com/michaelalbada",
    "LinkedIn": "https://www.linkedin.com/in/albada/",
    "Blog": "https://theneuralnexus.substack.com/",
    "Profile Picture": "https://sessionize.com/image/86a0-400o400o1-GVeeLaHhznoN9xHFcdKA6W.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "907834",
        "Title": "Building Applications with AI Agents",
        "Description": "Generative AI has dramatically shortened the distance between ideas and implementation, enabling faster prototyping and deployment than ever before. But while language models can streamline individual tasks, true transformation comes from combining these capabilities into intelligent, autonomous systems‚ÄîAI agents.\r\n\r\nThis talk explores how to build and deploy foundation model-enabled agent systems that go beyond simple prompt chaining or chatbots. Drawing from real-world implementations and the latest research, it offers a clear and practical path to designing both single-agent and multi-agent systems capable of handling complex workflows with minimal oversight.\r\n\r\nAttendees will gain a deeper understanding of the core design principles behind agentic systems, the architectural trade-offs involved in orchestrating multiple agents, and the strategies required to develop tailored solutions that enhance efficiency and innovation. Whether just beginning or scaling up, participants will leave with actionable insights to navigate the rapidly evolving world of AI autonomy.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Leadership: Architects",
        "Room": "SOMA: AI Architects",
        "Scheduled At": "4 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "5ed85946-1d55-415e-b2af-5e4feb00cf02",
    "Name": "Sharon Zhou",
    "Company": "Lamini",
    "Company Domain": "lamini.ai",
    "Company URL": "https://www.lamini.ai/",
    "Company Website": "https://lamini.ai",
    "Title": "Co-founder and CEO",
    "TagLine": "CEO",
    "Bio": "Dr. Sharon Zhou is the co-founder and CEO of Lamini, which has won this year‚Äôs VentureBeat Gen AI Startup Award and has been recognized as a Forbes Cloud 100 Rising Star. As a former faculty member at Stanford, she led a 50+ person Generative AI research group and published award-winning papers in generative AI. Sharon teaches some of the most popular AI courses on Coursera, including Fine-tuning LLMs, reaching millions of professionals. She earned her PhD in AI from Stanford, where she was advised by Dr. Andrew Ng. Before her PhD, she worked as an AI product manager at Google. She received her bachelor's degree in computer science and Classics from Harvard. Additionally, Sharon has served as an AI advisor in Washington, D.C., and has been featured in MIT Technology Review‚Äôs 35 Under 35 list.",
    "X (Twitter)": "https://x.com/realSharonZhou/",
    "LinkedIn": "https://www.linkedin.com/in/zhousharon/",
    "Blog": "https://lamini.ai/blog",
    "Profile Picture": "https://sessionize.com/image/e748-400o400o1-VL15xTuayZHeuqkmaPhLAj.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "911270",
        "Title": "Want reliable agents? Generate better (synthetic) data.",
        "Description": "You don‚Äôt need a bigger model. You need better synthetic data.\r\n\r\nIn this talk, we‚Äôll demonstrate how you can build reliable, domain-specific agents, without manually labeling thousands of samples. \r\n\r\nUsing agentic data pipelines, you can finally achieve 9s of accuracy‚Äîe.g., 95%+ accuracy on domain-specific tasks like Text-to-SQL. We'll show how, with just a handful of high-quality examples, you can generate, validate, and iteratively expand your dataset. \r\n\r\nThis workflow keeps humans in the loop where they add the most value (spotting inconsistencies, defining edge cases, etc.) while letting LLMs do what they do best (finding patterns, generating diverse examples, enforcing structure, etc.). The result is faster iteration and higher-quality training data‚Äîwithout tedious and expensive manual labeling.\r\n\r\nBuilding reliable agents also requires good evaluation data sets. Evaluations are critical for measuring alignment with your training objectives. Again, using agentic pipelines, you can continuously assess model performance, identify failure modes, and generate more synthetic data to further improve your model. \r\n\r\nWith this proven approach, you can train smaller models to be experts in your domain with a small amount of data in a relatively short amount of time. \r\n\r\n",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Agent Reliability",
        "Room": "Foothill C: Agent Reliability",
        "Scheduled At": "4 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "3f1fc718-d686-4c68-9a90-3127e4d56977",
    "Name": "Sam Julien",
    "Company": "Writer",
    "Company Domain": "writer.com",
    "Company URL": "https://writer.com/",
    "Company Website": "http://www.writer.com",
    "Title": "Director of Developer Relations",
    "TagLine": "Director of Developer Relations ",
    "Bio": "Sam Julien is the Director of Developer Relations at Writer and is passionate about helping engineers improve their effectiveness and advance their careers. He loves spending time outside with his family in the Pacific Northwest. You can find more of Sam's work at samjulien.com.",
    "X (Twitter)": "https://twitter.com/samjulien",
    "LinkedIn": "https://www.linkedin.com/in/samjulien/",
    "Blog": "http://www.samjulien.com/",
    "Profile Picture": "https://sessionize.com/image/d8ef-400o400o1-shSzxoCEXpouBFY9r148f5.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "912811",
        "Title": "When Vectors Break Down: Graph-Based RAG for Dense Enterprise Knowledge",
        "Description": "Enterprise knowledge bases are filled with \"dense mapping,\" thousands of documents where similar terms appear repeatedly, causing traditional vector retrieval to return the wrong version or irrelevant information. When our customers kept hitting this wall with their RAG systems, we knew we needed a fundamentally different approach.\r\n\r\nIn this talk, I'll share Writer's journey developing a graph-based RAG architecture that achieved 86.31% accuracy on the RobustQA benchmark while maintaining sub-second response times, significantly outperforming vector approaches.\r\n\r\nI'll survey the key techniques behind this performance leap and why graph-based approaches excel with complex enterprise information structures like product documentation, financial documents, and technical specifications that challenge traditional RAG systems. You'll learn about using specialized LLMs to build semantic relationships, how compression techniques efficiently handle concentrated enterprise data patterns, and how infusing key data points in the memory layer of the LLM lowers hallucination.\r\n\r\nThe presentation will provide practical insights into identifying when graph-based approaches make sense for your organization's specific data challenges, helping you make informed architectural decisions for your next enterprise RAG system.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "GraphRAG",
        "Room": "Golden Gate Ballroom B: GraphRAG",
        "Scheduled At": "4 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "de9c3919-7e80-4455-9778-b1fdb30ddac6",
    "Name": "Sid Bendre",
    "Company": "Oleve",
    "Company Domain": "oleve.co",
    "Company URL": "https://www.oleve.co/",
    "Company Website": "https://www.oleve.co/",
    "Title": "Co-founder and Head of Platform Team",
    "TagLine": "Co-Founder",
    "Bio": "Sid Bendre is the co-founder of Oleve, a company building a portfolio of iconic consumer software across multiple verticals. With a lean team, Oleve has already launched two virally successful consumer AI products that have amassed over 250 million views across social media platforms. One of their products reached #4 on the App Store's Education charts in 2024 and #5 in 2025, competing alongside giants like Photomath (Google) and Duolingo. Backed by Neo, Cal Henderson (co-founder of Slack), Russell Kaplan (President of Cognition), and Maria Zhang (ex-CTO of Tinder), Oleve is building the AI infrastructure to run a $1B portfolio of consumer software over the next decade. At Oleve, Sid leads technical and AI efforts, running the ‚ÄúPlatform‚Äù team responsible for the underlying AI infrastructure that powers their lean scaling approach. Before Oleve, Sid led AI experimentation efforts at a startup hedge fund and worked at Slack, Zendesk, and Microsoft.",
    "X (Twitter)": "https://x.com/SidBendre",
    "LinkedIn": "https://www.linkedin.com/in/sidbendre/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/0d00-400o400o1-BQmZLpsEnnPaQ4Ynw4eQqm.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914550",
        "Title": "The New Lean Startup",
        "Description": "In this session, I will be presenting a case study of Oleve's journey, revealing how we've scaled a profitable multi-product portfolio with a tiny team. I'll walk you through the emergence of \"tiny teams,\" our two-track engineering methodology that has become our blueprint, as well as an inside look at our technical alpha ‚Äì specifically how we've engineered deterministic AI agents to deliver magical and reliable consumer experiences to millions. You'll learn how we've built internal tools to grow leanly and created operating playbooks to scale operations without traditional headcount requirements. I'll also share our approach to scrappy infrastructure innovation and how our investment in internal tooling has served as a critical force multiplier. Finally, I'll give an overview of parts of the profitable portfolio playbook that keeps us lean, adaptable, and profitable across multiple product lines.\r\n\r\nStructure of talk:\r\n- the tiny teams revolution\r\n- the two-track engineering approach\r\n- technical alpha: deterministic ai agents at scale\r\n- scrappy infrastructure innovation\r\n- internal tooling as a multiplier\r\n- the profitable portfolio playbook",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Case Study/War Story",
        "Tracks": "Tiny Teams",
        "Room": "Yerba Buena Ballroom Salons 2-6: Tiny Teams",
        "Scheduled At": "4 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "4fdfdeca-1862-4955-a306-59cf77a9f79b",
    "Name": "James Lowe",
    "Company": "Incubator for AI ",
    "Company Domain": "cabinetoffice.gov.uk",
    "Company URL": "https://ai.gov.uk/",
    "Company Website": "https://ai.gov.uk/",
    "Title": "Head of AI Engineering",
    "TagLine": "Head of AI Engineering",
    "Bio": "James Lowe has been a data scientist in public sector for 6 years, including working at 10 Downing Street. He is now the Head of AI Engineering for the Incubator for AI, a small team of experts in the centre of the UK Government building AI products that are delivering public good.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/james-lowe-98011292/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/f5e7-400o400o1-U33Y72yYrp7tVXZgEpLXAL.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914842",
        "Title": "Why your product needs an AI product manager, and why it should be you",
        "Description": "So you've built another cool demo. Now what? You have hype, but not impact. You have kudos but no users. Ultimately you have a demo, but not a product.\r\n\r\nThe unique uncertainty of AI technology demands a new approach ‚Äì beyond traditional product management. You need an AI Product Manager. This talk explains why this role is essential for building real AI products, using real case studies from the incubator for Artificial Intelligence in the UK Government.\r\n\r\nMore importantly, it reveals why your technical depth makes you uniquely suited to step into this critical leadership gap. Discover why could be the ideal candidate to be the AI Product Manager your product needs, and how to step into that role.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "AI Product Management",
        "Room": "Foothill G 1&2: Product Management",
        "Scheduled At": "4 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "6f7997a2-1fef-42ef-947e-9c80e4648c0f",
    "Name": "Hassan El Mghari",
    "Company": "Together AI",
    "Company Domain": "together.ai",
    "Company URL": "https://www.together.ai/",
    "Company Website": "https://www.together.ai/",
    "Title": "Lead, Developer Relations",
    "TagLine": "DevRel lead ",
    "Bio": "Hassan El Mghari is a software engineer based in New York specializing in building full-stack AI applications. His AI applications have a combined user base of over 3 million. He currently leads the developer relations team at Together.ai, where his work includes building example AI apps, creating content, and educating developers on AI development.",
    "X (Twitter)": "https://twitter.com/nutlope",
    "LinkedIn": "https://www.linkedin.com/in/nutlope/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/2767-400o400o1-MnFYxtNJ6podCsRVudboUA.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "911846",
        "Title": "Using OSS models to build AI apps with millions of users",
        "Description": "In this talk, Hassan will go over how he builds open source AI apps that get millions of users like roomGPT.io (2.9 million users), restorePhotos.io (1.1 million users), Blinkshot.io (1 million visitors), and LlamaCoder.io (1.4 million visitors). He'll go over his journey in AI, demo some of the apps that he's built, and dig into his tech stack and code to explain how he builds these apps from scratch. He‚Äôll also go over how to market them and go over his top tips and tricks for building great full-stack AI applications quickly and efficiently.\r\n\r\nThis talk will start from first principles and give you a glimpse into Hassan‚Äôs workflow of idea -> working app -> many users. Attendees should come out of this session equipped with the resources to build impressive AI applications and understand some of the behind the scenes of how they‚Äôre built and marketed. This will hopefully serve as an educational and inspirational talk that encourages builders to go build cool things.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Tiny Teams",
        "Room": "Yerba Buena Ballroom Salons 2-6: Tiny Teams",
        "Scheduled At": "4 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "b08fa907-c722-40c1-a87f-70cdd1b1abeb",
    "Name": "Dexter Horthy",
    "Company": "HumanLayer",
    "Company Domain": "humanlayer.dev",
    "Company URL": "https://www.humanlayer.dev/",
    "Company Website": "https://humanlayer.dev",
    "Title": "AI Agent Developer",
    "TagLine": "Founder",
    "Bio": "Hey - I'm Dex, and I'm hacking on safer more reliable agents at HumanLayer. HumanLayer helps AI builders create agents that feel more like real coworkers - taking them out of ChatGPT-style interfaces and deploying them into slack, email, or wherever their users already are. Before this I was working on AI Agents that managed SQL warehouses, and did a long stint at replicated.com helping the worlds best software teams deliver Kubernetes apps into customer environments. I've been coding since 17, when I built tools for NASA researchers to navigate the south pole of the moon. Enjoyer of tacos and burpees (not necessarily in that order)",
    "X (Twitter)": "https://twitter.com/dexhorthy",
    "LinkedIn": "https://www.linkedin.com/in/dexterihorthy",
    "Blog": "https://theouterloop.substack.com",
    "Profile Picture": "https://sessionize.com/image/ae9e-400o400o1-MiCnM3v6KqD2jb5Rwr3cCv.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914080",
        "Title": "12 Factor Agents - Principles of Reliable LLM Applications",
        "Description": "Hi, I'm Dex. I've been hacking on AI agents for a while.\r\n\r\nI've tried every agent framework out there, from the plug-and-play crew/langchains to the \"minimalist\" smolagents of the world to the \"production grade\" langraph, griptape, etc.\r\n\r\nI've talked to a lot of really strong founders who are all building really impressive things with AI. Most of them are rolling the stack themselves. I don't see a lot of frameworks in production customer-facing agents.\r\n\r\nI've been surprised to find that most of the products out there billing themselves as \"AI Agents\" are not all that agentic. A lot of them are mostly deterministic code, with LLM steps sprinkled in at just the right points to make the experience truly magical.\r\n\r\nAgents, at least the good ones, don't follow the \"here's your prompt, here's a bag of tools, loop until you hit the goal\" pattern. Rather, they are comprised of mostly just software.\r\n\r\nSo, I set out to answer:\r\n\r\nWhat are the principles we can use to build LLM-powered software that is actually good enough to put in the hands of production customers?\r\n",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Agent Reliability",
        "Room": "Foothill C: Agent Reliability",
        "Scheduled At": "4 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "337aa731-b47d-43b7-87e3-d33e19f2fb89",
    "Name": "Chin Keong Lam",
    "Company": "Patho.ai",
    "Company Domain": "gmail.com",
    "Company URL": "http://www.patho.ai/",
    "Company Website": "https://www.patho.ai",
    "Title": "unknown",
    "TagLine": "AI Engineer & Co-Founder ",
    "Bio": "https://www.linkedin.com/in/cklam12345/",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/cklam12345/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/975d-400o400o1-KzGdm6FGGNSBRkgBXex9ky.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914548",
        "Title": "Wisdom Discovery at Scale: Code Less KAG with n8n MultiAI Agents",
        "Description": "\"Wisdom Discovery at Scale: Code Less KAG with n8n MultiAI Agents\"",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "GraphRAG",
        "Room": "Golden Gate Ballroom B: GraphRAG",
        "Scheduled At": "4 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "9e1f15f4-830e-4239-82ed-7e65bd50ff19",
    "Name": "Paul Klein IV",
    "Company": "Browserbase",
    "Company Domain": "browserbase.com",
    "Company URL": "",
    "Company Website": "https://browserbase.com/",
    "Title": "Founder",
    "TagLine": "Founder",
    "Bio": "Paul¬†Klein¬†IV is a San‚ÄëFrancisco‚Äëbased serial entrepreneur and engineer. After honing his chops at Twilio during it's IPO and founding Stream¬†Club‚Äîa live‚Äëstreaming platform acquired by Mux in¬†2021¬†he launched Browserbase in¬†2024 to give developers and AI agents fast, reliable, multi‚Äëregion headless‚Äëbrowser infrastructure. In its first 12¬†months, Klein raised $27.5¬†million (a $6.5¬†M seed and a $21¬†M Series¬†A led by CRV and Kleiner¬†Perkins with Okta¬†Ventures)¬†. He views Browserbase as the ‚Äúlast‚Äëmile‚Äù interface between large language models and the web, enabling end‚Äëto‚Äëend workflow automation far beyond traditional scraping¬†",
    "X (Twitter)": "https://x.com/pk_iv",
    "LinkedIn": "https://www.linkedin.com/in/paulkleiniv/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/4dc8-400o400o1-HaQv5txvpZSab2mk35AZNR.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914934",
        "Title": "The Web Browser Is All You Need",
        "Description": "(PLACEHOLDER) With the rise of MCP servers, A2A, and our trusty friend, OpenAPI, it turns our the web browser may be the default MCP server for the rest of the internet.\r\n\r\nIn this talk, we'll walk through how a web browsing tool is probably the only tool you'll need to enable production AI Agents. ",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Infrastructure",
        "Room": "Foothill F: Infrastructure",
        "Scheduled At": "4 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "45295eea-039a-4a9e-bbf0-3b5b42d31eee",
    "Name": "Brian Balfour",
    "Company": "Reforge",
    "Company Domain": "reforge.com",
    "Company URL": "https://www.reforge.com/",
    "Company Website": "",
    "Title": "Founder/CEO",
    "TagLine": "Founder & CEO, Reforge",
    "Bio": "Brian Balfour, Founder/CEO of Reforge, previously VP Growth @ HubSpot. Prior to Reforge, he has started multiple VC backed companies, and grown user bases to millions of daily active users. ",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/2bc4-400o400o1-n8ygxvYwRQdaNFyaG9Y5zE.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914975",
        "Title": "PMs Are Great. But Have You Tried AI?",
        "Description": "If you‚Äôve ever been blocked by vague specs, shifting goals, or chasing ‚Äúvibes,‚Äù things have only gotten messier in the age of AI.\r\n\r\nWhat if the PM were an AI‚Äîand it understood the product, the customers, the market, the design, and, most importantly, you?\r\n\r\nAt Reforge, we built AI agents that analyze user feedback at scale, perform real-time market analysis, write aspects, model feature impact, and run continuous user research -- pushing us to rethink what \"product work‚Äù actually looks like.\r\n\r\nIn this talk, we‚Äôll explore what happens when engineers collaborate with AI PMs instead of humans: evaluation-driven backlogs grounded in real user data, ruthless and precise feature scoping, and product decisions that iterate as fast as the models powering them.\r\n\r\nYou‚Äôll learn the user behaviors and engineering patterns behind feedback analysis, synthetic users, AI-native surveys, and the metrics we use to measure impact before a feature ships‚Äîalong with the cultural shifts teams need to embrace to make this future a reality.\r\n\r\nIn this new era, the teams who win won‚Äôt just adopt AI‚Äîthey‚Äôll architect workflows where human intuition and machine intelligence ship product side by side.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "AI Product Management",
        "Room": "Foothill G 1&2: Product Management",
        "Scheduled At": "4 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "15df4e7f-12d8-4868-9e5d-339da4c9332b",
    "Name": "Brian Balfour",
    "Company": "Reforge",
    "Company Domain": "reforge.com",
    "Company URL": "https://www.reforge.com/",
    "Company Website": "https://reforge.com",
    "Title": "Founder/CEO",
    "TagLine": "Founder & CEO, Reforge",
    "Bio": "Brian Balfour, Founder/CEO of Reforge, previously VP Growth @ HubSpot. Prior to Reforge, he has started multiple VC backed companies, and grown user bases to millions of daily active users. ",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/bbalfour/",
    "Blog": "https://brianbalfour.com",
    "Profile Picture": "https://sessionize.com/image/a307-400o400o1-U9Yid9B1rqbUe3SRku67BV.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914975",
        "Title": "PMs Are Great. But Have You Tried AI?",
        "Description": "If you‚Äôve ever been blocked by vague specs, shifting goals, or chasing ‚Äúvibes,‚Äù things have only gotten messier in the age of AI.\r\n\r\nWhat if the PM were an AI‚Äîand it understood the product, the customers, the market, the design, and, most importantly, you?\r\n\r\nAt Reforge, we built AI agents that analyze user feedback at scale, perform real-time market analysis, write aspects, model feature impact, and run continuous user research -- pushing us to rethink what \"product work‚Äù actually looks like.\r\n\r\nIn this talk, we‚Äôll explore what happens when engineers collaborate with AI PMs instead of humans: evaluation-driven backlogs grounded in real user data, ruthless and precise feature scoping, and product decisions that iterate as fast as the models powering them.\r\n\r\nYou‚Äôll learn the user behaviors and engineering patterns behind feedback analysis, synthetic users, AI-native surveys, and the metrics we use to measure impact before a feature ships‚Äîalong with the cultural shifts teams need to embrace to make this future a reality.\r\n\r\nIn this new era, the teams who win won‚Äôt just adopt AI‚Äîthey‚Äôll architect workflows where human intuition and machine intelligence ship product side by side.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "AI Product Management",
        "Room": "Foothill G 1&2: Product Management",
        "Scheduled At": "4 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "e0e7e5a4-c730-471e-afa3-fcfe5251b3ad",
    "Name": "Brooke Hopkins",
    "Company": "Coval",
    "Company Domain": "coval.dev",
    "Company URL": "https://www.coval.dev/",
    "Company Website": "https://www.coval.dev/",
    "Title": "Founder",
    "TagLine": "Founder ",
    "Bio": "Brooke Hopkins is the Founder at Coval, where her team builds the enterprise-grade reliability infrastructure for conversational AI. Previously, she built evaluation systems at Waymo that helped enable safe autonomous driving. With experience spanning both physical and digital AI domains, Brooke brings unique insights into creating robust testing frameworks that can scale with AI's rapid development.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/bnhop/",
    "Blog": "https://app.coval.dev/the-ultimate-voice-ai-stack",
    "Profile Picture": "https://sessionize.com/image/b34b-400o400o1-95iv2vfdt4j1yxRzZ2afQh.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915031",
        "Title": "What we can learn from self driving in autonomous voice agents",
        "Description": "The reliability challenges facing voice & chat AI deployment today mirror those that the autonomous vehicle industry confronted years ago. This talk explores how evaluation methodologies developed for self-driving cars can be transferred to create autonomous, self-improving evaluation systems for conversational AI. Drawing from my experience building evaluation infrastructure at Waymo and now developing Coval, an enterprise-grade reliability platform for conversational agents, I'll demonstrate how systematic testing infrastructure is not just a technical requirement but a competitive advantage in the rapidly evolving AI landscape.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Introductory (landscape)",
        "Tracks": "Voice",
        "Room": "Foothill E: Voice",
        "Scheduled At": "4 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "2cd31242-f8a9-46fd-8090-6965d08643c5",
    "Name": "Matthew Hertz",
    "Company": "Man Group",
    "Company Domain": "mehertz.com",
    "Company URL": "https://man.com/",
    "Company Website": "https://man.com",
    "Title": "Head of Machine Learning Technology",
    "TagLine": "Head of Machine Learning Technology",
    "Bio": "https://www.man.com/matthew-hertz\r\n\r\n(See speaker pitch for more info as well)\r\n\r\nMatthew Hertz leads the Machine Learning Technology team at Man Group. This team is responsible for the integration of generative AI throughout the firm and the development and maintenance of the front office machine learning platform.\r\n\r\nPrior to this, Matthew was the Head of Engineering for ArcticDB, a high-performance data-frame database optimised for time-series data. Matthew has been building data-driven technology platforms within firms in the financial services industry since 2015.\r\n\r\nMatthew holds a master‚Äôs degree in computer science from the University of Southampton.\r\n\r\n",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/matthew-hertz-2aba0aa4/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/160a-400o400o1-3ba3cWjqyueeHxpX17pu1k.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915273",
        "Title": "Quantitative Research in the era of Agentic AI",
        "Description": "Agents and vibe coding have already disrupted software engineering, but what about domains such as systematic quant trading? Can we build an agent to help find alpha - and ultimately to predict the future of financial markets?\r\n\r\nIn this talk, we'll walk you through the journey of creating and deploying the Alpha Assistant - a semi-autonomous research coding agent (\"outer loop\") specifically designed for Man Group's Quantitative Research teams.\r\n\r\nLearn about what goes into building a domain-specific coding agent in a niche, technical, and scientific domain. We'll touch on key themes such as agentic interface design (and why we moved *away* from a Claude Code-esque CLI interface), what we've learnt applying the \"bitter lesson for agents\", and what full autonomy for quant research might look like. ",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Fortune 500",
        "Room": "Golden Gate Ballroom C: AI in the Fortune 500",
        "Scheduled At": "4 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "217586b5-d1f3-4c69-8f8f-774e76a06602",
    "Name": "Amir Haghighat",
    "Company": "Baseten",
    "Company Domain": "baseten.co",
    "Company URL": "https://www.baseten.co/",
    "Company Website": "https://www.baseten.co/",
    "Title": "Co-founder and CTO",
    "TagLine": "CTO",
    "Bio": "Amir Haghighat is the co-founder and CTO at Baseten, an AI infrastructure company specializing in inference. Before Baseten, Amir led engineering teams at Clover Health and Gumroad. A graduate of UC Irvine, Amir lives in San Francisco and enjoys biking and time with his family.",
    "X (Twitter)": "http://twitter.com/amiruci",
    "LinkedIn": "https://www.linkedin.com/in/amirhaghighat/",
    "Blog": "https://www.baseten.co/blog/",
    "Profile Picture": "https://sessionize.com/image/a46b-400o400o1-DtmYnkCjJuxXsiTRqX4hi4.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915990",
        "Title": "The Rise of Open Models in the Enterprise",
        "Description": "This year kicked off with the DeepSeek-R1 news cycle breaking out of our AI Engineering bubble into the mainstream tech and business world. Leaders at the highest levels of the largest enterprises started asking how open source models could enhance and accelerate their AI strategy.\r\n\r\nOpen source models promise increased ownership of AI systems: control over performance and price, improved uptime and reliability, better compliance, and flexible hosting options. How are these promises playing out after months of implementation? In this talk, I‚Äôll draw on hundreds of conversations with AI leaders at enterprise companies to discuss what has ‚Äî and hasn‚Äôt ‚Äî changed about enterprise AI strategy in a world where open-source models compete on the frontier of intelligence.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Leadership: Fortune 500",
        "Room": "SOMA: AI Architects",
        "Scheduled At": "4 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "0bfc23a2-2561-42b7-a0c5-8a992dca6bc4",
    "Name": "Preeti Somal",
    "Company": "Temporal",
    "Company Domain": "moxiegrouppr.com",
    "Company URL": "https://temporal.io/",
    "Company Website": "https://temporal.io/",
    "Title": "Senior Vice President of Engineering",
    "TagLine": "SVP Engineering",
    "Bio": "Preeti is Senior Vice President of Engineering at Temporal. Preeti is passionate about building great products, growing world class organizations and solving complex problems. Prior to Temporal, Preeti led the Platform, Security and IT engineering organizations at HashiCorp. Her extensive career includes engineering leadership roles at Yahoo!, VMware and Oracle. While at Yahoo! Preeti was VP of Cloud Services in the Platform organization delivering highly scalable services used by engineers across Yahoo to build and operate applications with improved agility, reliability and security. These services power Yahoo!‚Äôs consumer and advertising business.\r\n",
    "X (Twitter)": "https://x.com/psomal",
    "LinkedIn": "https://www.linkedin.com/in/preeti-somal-131890/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/3776-400o400o1-77P8PG7wuNAKdjxiCsQNDp.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "913755",
        "Title": "Scaling AI agents without breaking reliability",
        "Description": "As AI agents move from prototypes to production, developers are running into new challenges with orchestration, failure handling, and infrastructure. This session will unpack lessons from teams already building real-world systems and share how to design for reliability from the start.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Agent Reliability",
        "Room": "Foothill F: Infrastructure",
        "Scheduled At": "4 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "c76d65c1-a932-4649-b699-b67f0646072c",
    "Name": "Chau Tran",
    "Company": "Glean",
    "Company Domain": "gmail.com",
    "Company URL": "",
    "Company Website": "https://www.glean.com/",
    "Title": "Software Engineer",
    "TagLine": "Technical Lead",
    "Bio": "Chau Tran is a Software Engineer at Glean, currently leading the technical work on Glean Assistant and semantic search. They have been with Glean for over 3 years and have a history of impactful contributions in engineering teams. Previously, Chau worked as a Research Engineer at FAIR within Meta and held technical roles at Quora. They graduated from Brown University with a Bachelor's degree in Computer Science.",
    "X (Twitter)": "https://x.com/mr_cheu",
    "LinkedIn": "https://www.linkedin.com/in/chau-tran-ba9a5727/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/02cb-400o400o1-YcnXGLU8Boj3XwrtuAVZpX.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915338",
        "Title": "How to build Enterprise-aware agents",
        "Description": "While LLMs demonstrated impressive reasoning capabilities, their out-of-the-box reasoning is akin to hiring a brilliant but brand-new employee who doesn‚Äôt have the enterprise context of ‚Äúhow things are done at this company‚Äù. In this talk, I'll introduce ‚ÄúWorkflow Search‚Äù as a paradigm to build enterprise-aware agents that can balance predictability on common tasks, and flexibility on unforeseen tasks.\r\n",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "Foothill C: Agent Reliability",
        "Scheduled At": "4 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "d28ab6c9-b76f-4f91-9a2f-d54805cbc871",
    "Name": "Chau Tran",
    "Company": "Glean",
    "Company Domain": "gmail.com",
    "Company URL": "Glean.com",
    "Company Website": "",
    "Title": "Technical Lead on AI/Agents",
    "TagLine": "AI engineer at Glean",
    "Bio": "Technical lead on AI/Agents at Glean",
    "X (Twitter)": "https://x.com/mr_cheu?s=21&t=0OWQAmiVMjKckUN9A42N2A",
    "LinkedIn": "https://www.linkedin.com/in/chau-tran-ba9a5727?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=ios_app",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/1491-400o400o1-GzkGdeXf3JQxSjEuqz9mbu.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915338",
        "Title": "How to build Enterprise-aware agents",
        "Description": "While LLMs demonstrated impressive reasoning capabilities, their out-of-the-box reasoning is akin to hiring a brilliant but brand-new employee who doesn‚Äôt have the enterprise context of ‚Äúhow things are done at this company‚Äù. In this talk, I'll introduce ‚ÄúWorkflow Search‚Äù as a paradigm to build enterprise-aware agents that can balance predictability on common tasks, and flexibility on unforeseen tasks.\r\n",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "Foothill C: Agent Reliability",
        "Scheduled At": "4 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "2b6fdff3-b2d4-4765-bd3a-f6146379b99c",
    "Name": "Ben Stein",
    "Company": "Teammates",
    "Company Domain": "teammates.work",
    "Company URL": "https://www.teammates.work/",
    "Company Website": "https://www.teammates.work",
    "Title": "Founder and CEO",
    "TagLine": "CEO",
    "Bio": "Ben is a customer-obsessed technology executive and product leader who seamlessly bridges the worlds of business, product, and technology. He has repeated success leading cross-functional teams at multiple lifecycle stages, from 3x startup founder, to scaling through hypergrowth, to managing mature lines of business.\r\n\r\nIn 7 years at Twilio, Ben was GM of multiple business units (Developer Experience, Enterprise), Product Director for text messaging, and Head of R&D for Twilio.org. As CPTO at Arcadia (climate tech unicorn), he led a global team building APIs to decentralize and decarbonize the electrical grid. He cofounded multiple startups including Mobile Commons (acquired by $UPLD), an early platform for SMS marketing; and QuitCarbon, an AI platform to transition 100M homes off fossil fuels. \r\n\r\nHe is currently building Teammates, a platform for designing and managing a virtual workforce of truly autonomous virtual colleagues.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/benjaminstein/",
    "Blog": "https://www.teammates.work/blog",
    "Profile Picture": "https://sessionize.com/image/75c9-400o400o1-GdKVdseJ6n3ZLeZKRBX92L.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915648",
        "Title": "Shipping Products When You Don‚Äôt Know What they Can Do",
        "Description": "A customer recently asked me: ‚ÄúHey, can I tag your AI agent in a Google Doc comment?‚Äù\r\n\r\nThe honest answer: I have no idea! We never designed our agents to handle Google Doc comments, but we tried it anyway‚Ä¶ and it worked! The agent performed beautifully, the customer was thrilled, and I was left bewildered.\r\n\r\nWelcome to Product Management for AI agents, where roadmaps are fuzzy and we only learn the boundaries of our products after they‚Äôre released. When a product doesn‚Äôt follow predefined requirements but instead learns and improvises at runtime, PMs must give up control and lean into uncertainty, curiosity, experimentation, and fast feedback loops.\r\n\r\nThis talk is a field guide for Product/Engineering teams navigating this new reality. We‚Äôll cover how to write specs for affordances instead of features, how to use AI evals as a product development tool, and how to perform User Acceptance Testing on undocumented emergent behavior. Most importantly, we‚Äôll explore how to build trust with customers even when the answer is, truthfully, ‚ÄúI don‚Äôt know.‚Äù\r\n\r\nIf you‚Äôre managing AI-native products in 2025 the same way you managed web apps in 2020, you might find yourself A/B testing an agent that decided to go off and do C, D, and E all by themselves!\r\n",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "AI Product Management",
        "Room": "Foothill G 1&2: Product Management",
        "Scheduled At": "4 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "a035c1ab-f6b9-40d7-b626-5b2da7f43e92",
    "Name": "Michael Hunger",
    "Company": "Neo4j",
    "Company Domain": "neotechnology.com",
    "Company URL": "https://neo4j.com/developer/",
    "Company Website": "https://neo4j.com/developer",
    "Title": "Head of Product Innovation and GenAI",
    "TagLine": "VP of Product Innovation",
    "Bio": "Michael Hunger has been passionate about software development for more than 30 years.\r\n\r\nFor the last 15 years, he has been working on the open source Neo4j graph database filling many roles, most recently heading product innovation and GenAI.\r\n\r\nAs a developer Michael enjoys many aspects of software development and architecture, learning new things every day, participating in exciting and ambitious open source projects and contributing and writing software related books and articles. Michael spoke at numerous conferences and helped organize others.\r\n\r\nMichael helps kids to learn to program by running weekly girls-only coding classes at local schools.",
    "X (Twitter)": "https://twitter.com/mesirii",
    "LinkedIn": "https://www.linkedin.com/in/jexpde/",
    "Blog": "https://medium.com/@mesirii",
    "Profile Picture": "https://sessionize.com/image/9f3e-400o400o1-LUKT2k8UpemDTxay2r5BxY.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915740",
        "Title": "Practical GraphRAG - Making LLMs smarter with Knowledge Graphs",
        "Description": "RAG has become one standard architecture component for GenAI applications to address hallucinations and integrate factual knowledge. While vector search over text is common, knowledge graphs represent a proven advancement by leveraging advanced RAG patterns to access and integrate interconnected factual information, complementing the language skills of LLMs. This talk explores GraphRAG challenges, implementation patterns, and real-world agentic examples with Google's ADK, demonstrating how this approach delivers more trustworthy and explainable GenAI solutions with enhanced reasoning capabilities.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "GraphRAG",
        "Room": "Golden Gate Ballroom B: GraphRAG",
        "Scheduled At": "4 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "874892d4-9a6d-4f7b-8b43-3a73b507f586",
    "Name": "Jes√∫s Barrasa",
    "Company": "Neo4j",
    "Company Domain": "neo4j.com",
    "Company URL": "https://neo4j.com/",
    "Company Website": "https://neo4j.com/",
    "Title": "AI Field CTO",
    "TagLine": "AI Field CTO",
    "Bio": "Dr. Jes√∫s Barrasa is the AI Field CTO at Neo4j, where he works with organisations combining the power of GenAI with Knowledge Graphs. He co-authored \"Building Knowledge Graphs\" (O'Reilly 2023) and is cohost of the monthly Going Meta live webcast (https://goingmeta.live/) since 2022.\r\nJes√∫s holds a Ph.D. in Artificial Intelligence/Knowledge Representation and is an active thought leader in the KG and AI space",
    "X (Twitter)": "https://x.com/BarrasaDV",
    "LinkedIn": "https://www.linkedin.com/in/jbarrasa/",
    "Blog": "https://goingmeta.live/",
    "Profile Picture": "https://sessionize.com/image/7ff8-400o400o1-PNdKVMwQUpiXioSFyPbLaw.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915740",
        "Title": "Practical GraphRAG - Making LLMs smarter with Knowledge Graphs",
        "Description": "RAG has become one standard architecture component for GenAI applications to address hallucinations and integrate factual knowledge. While vector search over text is common, knowledge graphs represent a proven advancement by leveraging advanced RAG patterns to access and integrate interconnected factual information, complementing the language skills of LLMs. This talk explores GraphRAG challenges, implementation patterns, and real-world agentic examples with Google's ADK, demonstrating how this approach delivers more trustworthy and explainable GenAI solutions with enhanced reasoning capabilities.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "GraphRAG",
        "Room": "Golden Gate Ballroom B: GraphRAG",
        "Scheduled At": "4 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "0793b99f-1282-4674-9d21-f88e30c8232e",
    "Name": "Stephen Chin",
    "Company": "Neo4j",
    "Company Domain": "steve.chin.social",
    "Company URL": "https://neo4j.com/",
    "Company Website": "https://neo4j.com/",
    "Title": "VP of Developer Relations",
    "TagLine": "VP of Developer Relations",
    "Bio": "Stephen Chin is VP of Developer Relations at Neo4j, conference chair of the LF AI & Data Foundation, and author of numerous titles including the upcoming GraphRAG: The Definitive Guide for O'Reilly. He has given keynotes and main stage talks at numerous conferences around the world including AI Engineer Summit, AI DevSummit, Devoxx, DevNexus, JNation, JavaOne, Shift, Joker, swampUP, and GIDS. Stephen is an avid motorcyclist who has done evangelism tours in Europe, Japan, and Brazil, interviewing developers in their natural habitat. When he is not traveling, he enjoys teaching kids how to do AI, embedded, and robot programming together with his daughters.",
    "X (Twitter)": "https://twitter.com/steveonjava",
    "LinkedIn": "https://www.linkedin.com/in/steveonjava/",
    "Blog": "http://steveonjava.com/",
    "Profile Picture": "https://sessionize.com/image/67c7-400o400o1-94UgqvdxnaQUpj38o9TkBX.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915740",
        "Title": "Practical GraphRAG - Making LLMs smarter with Knowledge Graphs",
        "Description": "RAG has become one standard architecture component for GenAI applications to address hallucinations and integrate factual knowledge. While vector search over text is common, knowledge graphs represent a proven advancement by leveraging advanced RAG patterns to access and integrate interconnected factual information, complementing the language skills of LLMs. This talk explores GraphRAG challenges, implementation patterns, and real-world agentic examples with Google's ADK, demonstrating how this approach delivers more trustworthy and explainable GenAI solutions with enhanced reasoning capabilities.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "GraphRAG",
        "Room": "Golden Gate Ballroom B: GraphRAG",
        "Scheduled At": "4 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "75caaf38-093d-4f2f-b4b2-8ce5aeb4bea4",
    "Name": "Nathan Wan",
    "Company": "Ensemble Health Partners",
    "Company Domain": "ensemblehp.com",
    "Company URL": "https://www.ensemblehp.com/",
    "Company Website": "",
    "Title": "Machine Learning and Engineering Leader",
    "TagLine": "Head of AI",
    "Bio": "Nathan Wan is a machine learning and engineering leader who has built production AI systems across multiple domains before healthcare. After building speech recognition and language models and leading operational teams at Google, he led scaled platforms and teams applying AI to cancer detection and drug discovery in biotech. At Ensemble Health Partners, Nathan is leading efforts to transform RCM into a tech-driven performance engine.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/nwan1/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/c9a8-400o400o1-RyRmUSQEcH7GZDx9rw5zAE.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916157",
        "Title": "AI That Pays: Lessons from Revenue Cycle",
        "Description": "While much of the AI innovation in healthcare has centered on clinical and patient-facing applications, Revenue Cycle Management (RCM) remains an underexplored yet critical domain. Given the growing financial pressures facing providers, rethinking how healthcare gets paid is essential to ensuring access and sustainability. The combination of which makes RCM an opportune area for AI disruption.\r\n\r\nThis session explores how the combination of vast structured and unstructured data, often rule-based workflows, and direct financial opportunity to drive meaningful outcomes. We‚Äôll also share practical lessons from our journey evolving a traditional machine learning mindset to incorporate the latest advances in Generative AI, and how that shift is reshaping what's possible in healthcare operations.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Leadership: Architects",
        "Room": "SOMA: AI Architects",
        "Scheduled At": "4 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "b51b2de9-bffc-4fca-ab1c-ecfd3932e0de",
    "Name": "Grant Lee",
    "Company": "Gamma",
    "Company Domain": "gamma.app",
    "Company URL": "https://gamma.app/",
    "Company Website": "https://gamma.app/",
    "Title": "Founder",
    "TagLine": "CEO",
    "Bio": "Grant has spent the past 10+ years building tech startups and has a background in finance and operations. He was interim CFO at Optimizely and the COO of Clearbrain, two YC startups. He grew up in the bay area and studied at Stanford, where he received his B.S. and M.S. in mechanical engineering. He is currently building Gamma, an AI-powered platform to create presentations, websites, and more.",
    "X (Twitter)": "https://x.com/thisisgrantlee",
    "LinkedIn": "https://www.linkedin.com/in/grantslee/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/a75a-400o400o1-BszmV4DtgcRQUsqSxSd7QT.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "923914",
        "Title": "Tiny Teams",
        "Description": "Sean reached out on X, happy to do a talk on how to build a tiny team",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Tiny Teams",
        "Room": "Yerba Buena Ballroom Salons 2-6: Tiny Teams",
        "Scheduled At": "4 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "5aaeac52-c97c-4c71-badd-6502e40699d2",
    "Name": "Ben Kus",
    "Company": "Box",
    "Company Domain": "box.com",
    "Company URL": "box.com/home",
    "Company Website": "",
    "Title": "Chief Technology Officer",
    "TagLine": "CTO",
    "Bio": "Ben Kus is the Chief Technology Officer at Box and is responsible for developing Box‚Äôs technology vision and strategy and ensuring that technological resources are aligned with the company's business needs. Previously Ben was the VP of Product Management at Box. Before joining Box, Ben was the Co-Founder and CTO of Subspace, Inc., an enterprise security solution that was acquired by Box. Ben has held various leadership positions, including the role of Chief Architect for IBM, and Senior Director of Technology for BigFix, Inc. Ben studied Computer Science at the University of California, Berkeley.",
    "X (Twitter)": "",
    "LinkedIn": "https://linkedin.com/in/benkus",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/aa3c-400o400o1-UzPs5VdRqRQaqwXZFXnpxn.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "932429",
        "Title": "Building an Agentic Platform",
        "Description": "Explore the technical evolution of metadata extraction at Box and how it shaped the foundation of our AI platform. We‚Äôll walk through our transition to an agentic-first design‚Äîwhy it was necessary, how we approached the rebuild, challenges we encountered along the way, and the advantages it unlocked.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "GraphRAG, Infrastructure, AI in Fortune 500",
        "Room": "Golden Gate Ballroom C: AI in the Fortune 500",
        "Scheduled At": "4 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "b739c7b1-589c-4479-857b-7bbf1fca41b8",
    "Name": "Denys Linkov",
    "Company": "Wisedocs",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.wisedocs.ai/",
    "Company Website": "",
    "Title": "Head of ML",
    "TagLine": "Head of ML",
    "Bio": "Denys is the Head of ML at Wisedocs, Startup Advisor and a Sessional Lecturer at the University of Toronto. He's worked with 50+ enterprises in their AI journey in the AI automation and Medical document spaces. He's worked across the AI product stack, being hands-on building key ML systems, managing product delivery teams, and working directly with customers on best practices. ",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/denyslinkov/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/e241-400o400o1-TAaqdSME9z1qd3rGUw2jw.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "904822",
        "Title": "Structuring a modern AI team",
        "Description": "You've been given an AI mandate but don't have additional headcount, what next? Re-skilling, up-skilling and team augmentation become essential to delivering on a new mandate. In this talk we'll cover strategies to structure cross functional AI teams with domain experts, software engineers and ML engineers. We'll cover key skills and milestones that each traditional role can contribute to in unique ways.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Leadership: Architects",
        "Room": "SOMA: AI Architects",
        "Scheduled At": "4 Jun 2025 02:25 PM"
      }
    ]
  },
  {
    "Speaker ID": "8d28dd81-4424-49b9-b16c-507e07ca5dea",
    "Name": "Sam Bhagwat",
    "Company": "Mastra",
    "Company Domain": "gmail.com",
    "Company URL": "https://mastra.ai/",
    "Company Website": "http://mastra.ai/",
    "Title": "Co-founder and CEO",
    "TagLine": "Co-founder",
    "Bio": "Sam is the co-founder and CEO of Mastra and the author of Principles of AI Agents. Previously, Sam was the co-founder of Gatsby.js, the popular web framework.",
    "X (Twitter)": "http://twitter.com/calcsam",
    "LinkedIn": "https://www.linkedin.com/in/sambhagwat/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/f75d-400o400o1-E9ZPVLaCAtZtRZ11JFZFGX.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914015",
        "Title": "Agents vs Workflows: Why Not Both?",
        "Description": "One current hot debate is should you make your top-level abstraction a ReAct type agent running in a loop? or should you make it a structured workflow graph?\r\n\r\nOpenAI is launching their new framework and throwing shade on workflow graph approaches\r\n\r\nTBH we think this whole debate is kinda dumb. \r\n\r\nWe've seen a lot of folks be able to structure the problem in a way that a workflow graph makes a lot of sense. \r\n\r\nWe also see a ton of agents where you need to run the core bit in a loop for a long time.\r\n\r\nYou can also give your agents structured workflow graphs as a tool. You can use structured workflow graphs as a handoff mechanism between agents. What we've seen from the community is frankly that folks need to tinker with multiple approaches and combine primitives in interesting ways\r\n\r\nWe'll share a couple stories where teams ended up with workflow graph based approaches, a couple where teams ended up with agent based approaches, and a couple where a blended approach made sense.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Agent Reliability",
        "Room": "Foothill C: Agent Reliability",
        "Scheduled At": "4 Jun 2025 02:25 PM"
      }
    ]
  },
  {
    "Speaker ID": "18eabb2b-c250-49a1-b522-ed04bf90ca10",
    "Name": "Yogendra Miraje",
    "Company": "FactSet Research Systems Inc",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.factset.com/",
    "Company Website": "https://www.factset.com/",
    "Title": "AI Engineer",
    "TagLine": "Lead AI Engineer",
    "Bio": "I'm a backend engineer turned ML engineer turned AI engineer, with 16 years of experience building intelligent systems. I hold a Master‚Äôs degree in Computer Science from Northeastern University in Boston, and I currently work as an AI Engineer in FactSet.\r\n\r\nI'm also the host of AI Blindspot, a podcast where we explore the frontiers of artificial intelligence‚Äîand the blind spots we often overlook in its development and deployment.\r\n\r\nWith a strong foundation in Machine Learning and software Engineering and a product-minded approach, I focus on aligning autonomous agents with real-world user goals, emphasizing safety, control, and robust evaluation techniques.\r\n\r\nI'm passionate about building AI that‚Äôs not just powerful, but grounded, aligned, and truly useful in practice.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/mirajey/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/d02c-400o400o1-Vc48gw6Vdd4CCqVdpWCx3j.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914049",
        "Title": "How to Build Planning Agents without losing control",
        "Description": "Planning agents help solve complex tasks by breaking them into steps. They work across enterprise systems where data lives in many places. These agents are powerful but can be hard to control. This session shows how to use blueprints as guardrails for these agents. I will explain techniques to ensure agents follow the right plan. I will cover evaluation methods to verify agents stay aligned with user goals.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Leadership: Fortune 500",
        "Room": "Golden Gate Ballroom C: AI in the Fortune 500",
        "Scheduled At": "4 Jun 2025 02:25 PM"
      }
    ]
  },
  {
    "Speaker ID": "546b389a-0e78-4373-8181-ad897715e90f",
    "Name": "Kyle Kranen US",
    "Company": "NVIDIA",
    "Company Domain": "nvidia.com",
    "Company URL": "https://www.nvidia.com/en-us/",
    "Company Website": "https://www.nvidia.com/en-us/",
    "Title": "Engineering Leader",
    "TagLine": "Engineering Manager - Deep Learning Algorithms ",
    "Bio": "Kyle Kranen is an engineering leader at NVIDIA, chartered on accelerating datacenter-scale LLM performance. His work bridges engineering and research, covering topics like speculation, disaggregation, and datacenter-scale scheduling.",
    "X (Twitter)": "https://x.com/kranenkyle",
    "LinkedIn": "https://www.linkedin.com/in/kyle-kranen/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/2cb8-400o400o1-K9s17jFAKYvdpuBPwednNN.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915471",
        "Title": "Hacking the Inference Pareto Frontier for Cheaper and Faster Tokens Without Breaking SLAs",
        "Description": "Your model works! It aces the evals! It even passes the vibe check! All that‚Äôs required is inference, right? Oops, you‚Äôve just stepped into a minefield:\r\n\r\n-Not low-latency enough? Choppy experience. Users churn from your app. \r\n-Not cheap enough? You‚Äôre losing money on every query.\r\n-Not high enough output quality? Your system can‚Äôt be used for that application.\r\n\r\nA model and the inference system around it form a ‚Äútoken factory‚Äù associated with a Pareto frontier‚Äî a curve representing the best possible trade-offs between cost, throughput, latency and quality, outside of which your LLM system cannot be applied successfully. \r\n\r\nOutside of the Pareto frontier? You‚Äôre back to square one.\r\nThat is, unless you‚Äôre able to change the shape of the Pareto frontier.\r\n\r\nIn this session, we‚Äôll introduce NVIDIA Dynamo, a datacenter-scale distributed inference framework as well as the bleeding-edge techniques it enables to hack the Pareto frontier of your inference systems, including:\r\n\r\n-Disaggregation - separating phases of LLM generation to make them more efficient\r\n-Speculation - predicting multiple tokens per cycle\r\n-KV routing, storage, and manipulation - ensuring that we don‚Äôt redo work that has already been done\r\n-Pipelining improvements for agents - accelerating our workflows using information about the agent\r\n\r\nBy the end of the talk, we‚Äôll understand how the Pareto frontier limits where models can be applied, the intuition behind how inference techniques can be used to modify it, as well as the mechanics of how these techniques work.\r\n",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "Infrastructure",
        "Room": "Foothill F: Infrastructure",
        "Scheduled At": "4 Jun 2025 02:25 PM"
      }
    ]
  },
  {
    "Speaker ID": "800d4109-c399-4c21-b169-f138bfaf6087",
    "Name": "Christopher Lovejoy",
    "Company": "Anterior ",
    "Company Domain": "anterior.com",
    "Company URL": "https://www.anterior.com/",
    "Company Website": "https://www.anterior.com/",
    "Title": "Head of Clinical AI",
    "TagLine": "Head of Clinical AI ",
    "Bio": "Dr Chris Lovejoy is the Head of Clinical AI at Anterior, the AI company built by clinicians to transform healthcare administration. Chris studied Medicine at the University of Cambridge and worked as a doctor in the UK's NHS before spending the last 7 years in the world of AI start-ups, as a founder, an ML engineer and an AI consultant.",
    "X (Twitter)": "https://x.com/chrislovejoy_",
    "LinkedIn": "https://www.linkedin.com/in/dr-christopher-lovejoy/",
    "Blog": "https://chrislovejoy.me/",
    "Profile Picture": "https://sessionize.com/image/2c90-400o400o1-9zfJM31RVFL4xbuBei1o46.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915738",
        "Title": "Make your LLM app a Domain Expert: How to Build an LLM-Native Expert System",
        "Description": "Vertical AI is a multi-trillion-dollar opportunity. But you can't build a domain-expert application simply by grabbing the latest LLMs off-the-shelf: you need a system for codifying latent insights from domain experts and using that to drive development of your application.\r\n\r\nIn this talk, we'll describe the system we've built at Anterior which has enabled us to achieve SOTA clinical reasoning and serve health insurance providers covering 50 million American lives. We'll share:\r\n- how and why to encode domain-specific failure modes as an ontology\r\n- a practical system for converting domain expertise into quantifiable eval metrics\r\n- how we structure work and collaboration between our clinicians, engineer and PMs\r\n- our eval-driven AI iteration process and how this can be adapted to any industry",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Leadership: Fortune 500",
        "Room": "Foothill G 1&2: Product Management",
        "Scheduled At": "4 Jun 2025 02:25 PM"
      }
    ]
  },
  {
    "Speaker ID": "fe4a5f0e-b102-41a2-8825-bef1760970c2",
    "Name": "Mitesh Patel",
    "Company": "NVIDIA",
    "Company Domain": "nvidia.com",
    "Company URL": "https://www.nvidia.com/location-selector/",
    "Company Website": "https://www.nvidia.com",
    "Title": "Developer Advocate Manager",
    "TagLine": "Developer Advocate Manager",
    "Bio": "Mitesh Patel is a developer advocate manager at NVIDIA. His team is responsible for creating workflows to showcase how developers can harness GPU acceleration in their workflows using tools and frameworks popular in the developer community. Before NVIDIA, he was a senior research scientist at Fuji Xerox Palo Alto Laboratory Inc. (a research subsidiary of Fuji Xerox), where he worked on developing indoor localization technologies for applications such as asset tracking in hospitals and delivery cart tracking in manufacturing facilities. Mitesh received his Ph.D. in Robotics from the Center of Autonomous Systems (CAS) at the University of Technology Sydney, Australia in 2014.",
    "X (Twitter)": "https://x.com/m_i_t_e_s_h_p",
    "LinkedIn": "https://www.linkedin.com/in/patelmiteshn/",
    "Blog": "https://developer.nvidia.com/blog/author/miteshp/",
    "Profile Picture": "https://sessionize.com/image/03bc-400o400o1-Rdpv3jcCTJeLjskuwLjyVB.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915992",
        "Title": "HybridRAG: A Fusion of Graph and Vector Retrieval to Enhance Data Interpretation",
        "Description": "Interpreting complex information from unstructured text data poses significant challenges to Large Language Models (LLM), with difficulties often arising from specialized terminology and the multifaceted relationships between entities in document architectures. Conventional Retrieval Augmented Generation (RAG) methods face limitations in capturing these nuanced interactions, leading to suboptimal performance. In our talk, we introduce a novel approach integrating Knowledge Graph-based RAG (GraphRAG) with VectorRAG, designed to refine question-answering (Q&A) systems for more effective information extraction from complex texts. Our approach employs a dual retrieval strategy that harnesses both knowledge graphs and vector databases, enabling the generation of precise and contextually appropriate answers, thereby setting a new standard for LLMs in processing sophisticated data.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "GraphRAG",
        "Room": "Golden Gate Ballroom B: GraphRAG",
        "Scheduled At": "4 Jun 2025 02:25 PM"
      }
    ]
  },
  {
    "Speaker ID": "4d8f9ca5-846a-4577-a858-944d5047f16d",
    "Name": "Jordan Dearsley",
    "Company": "Vapi",
    "Company Domain": "vapi.com",
    "Company URL": "https://vapi.ai/",
    "Company Website": "https://vapi.ai/",
    "Title": "Co-founder and CEO",
    "TagLine": "CEO",
    "Bio": "Jordan Dearsley is the Co-founder and CEO of Vapi, the leading developer platform for deploying voice AI agents. Previously, he was the cofounder of Superpowered, an AI notetaker for meetings. He‚Äôs a YC and AI Grant founder, a University of Waterloo dropout, and a software engineer. ",
    "X (Twitter)": "https://x.com/jordan_dearsley?",
    "LinkedIn": "https://www.linkedin.com/in/jordandearsley/",
    "Blog": "https://vapi.ai/blog",
    "Profile Picture": "https://sessionize.com/image/5431-400o400o1-EgcdABn7zzY9jFyZbH9eop.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916079",
        "Title": "Building the Voice-First Future: Omnipresent Agents that Listen, Talk and Act",
        "Description": "We‚Äôre entering a world where talking to machines feels as natural as talking to people. Voice is about to become the dominant interface for technology - ambient, always-on, and human by default. To get there, we need infrastructure that can orchestrate voice, tools, memory, real-time reasoning and telephony. This talk explores the vision for voice and how we're making it work at scale. ",
        "Format": "Talk",
        "Level": "Expert",
        "Scope": "Introductory (landscape)",
        "Tracks": "Voice",
        "Room": "Foothill E: Voice",
        "Scheduled At": "4 Jun 2025 02:25 PM"
      }
    ]
  },
  {
    "Speaker ID": "cae85c3f-0367-49a5-94e7-68841319651e",
    "Name": "Robert  Wachen",
    "Company": "Etched",
    "Company Domain": "etched.ai",
    "Company URL": "",
    "Company Website": "https://www.etched.com/",
    "Title": "Co-founder and COO",
    "TagLine": "Co-founder of Etched ",
    "Bio": "Robert is the co-founder and COO of Etched, the AI chip company behind the first transformer ASIC.",
    "X (Twitter)": "https://x.com/robertwachen?lang=en",
    "LinkedIn": "https://www.linkedin.com/in/robertwachen",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/1c04-400o400o1-SmUEgWUJhoT4ifwzYfQ5ro.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "912986",
        "Title": "Flipping the Inference Stack: Why GPUs Bottleneck Real-Time AI at Scale",
        "Description": "AI inference today is stuck in a loop: throw more GPUs at the problem, scale horizontally, rinse and repeat. But that playbook is hitting a wall. Latency, cost, and energy grids are all suffering, and the capability for real-time AI at scale looks further and further away. In this talk, AI hardware expert and founder Gavin Uberti will break down why the current approach to inference is masking deep inefficiencies, and how rethinking the hardware stack from the ground up (starting with inference-first chips) is the only way to unlock real-time AI at scale. ",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Infrastructure",
        "Room": "Foothill F: Infrastructure",
        "Scheduled At": "4 Jun 2025 02:50 PM"
      }
    ]
  },
  {
    "Speaker ID": "4b7f0686-5bfb-43da-980d-0449511b062d",
    "Name": "Anoop Kotha",
    "Company": "OpenAI",
    "Company Domain": "openai.com",
    "Company URL": "https://openai.com/",
    "Company Website": "",
    "Title": "Customer Solutions Engineer",
    "TagLine": "Applied AI",
    "Bio": "I'm Anoop Kotha, a member of the OpenAI team that works with our customers to create novel LLM experiences. Previously I was an engineer at Retool. ",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/0f76-400o400o1-hX5wxCLt85iJnmvPhg8DNe.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915067",
        "Title": "Building Effective Voice Agents",
        "Description": "How to build production voice applications and learnings from working with customers along the way",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Leadership: Architects",
        "Room": "SOMA: AI Architects",
        "Scheduled At": "4 Jun 2025 02:50 PM"
      }
    ]
  },
  {
    "Speaker ID": "a610fd51-d488-4ee7-be82-52ba1422c6f6",
    "Name": "Jeremy Silva",
    "Company": "Freeplay",
    "Company Domain": "freeplay.ai",
    "Company URL": "https://freeplay.ai/",
    "Company Website": "https://freeplay.ai",
    "Title": "Product Lead",
    "TagLine": "Product Lead ",
    "Bio": "A seasoned ML engineer with extensive experience building and deploying language models in the healthcare sector, Jeremy currently serves as Product Lead at Freeplay. At Freeplay, he oversees an enterprise-ready platform that empowers teams to run experiments, create evaluations, monitor production systems, and label data‚Äîall within a unified environment.\r\nDrawing from hands-on collaboration with Freeplay's enterprise customers, Jeremy brings valuable \"in-the-trenches\" experience building LLM systems at scale. This direct customer engagement has also positioned him as a trusted advisor, helping organizations shape and refine their AI product roadmaps for maximum impact.\r\nJeremy‚Äôs unique perspective spans technical implementation and product development making him well-positioned to share insights on effectively bridging the gap between AI capabilities and real-world product outcomes.\r\n",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/jeremyevansilva/",
    "Blog": "https://freeplay.ai/blog",
    "Profile Picture": "https://sessionize.com/image/e41a-400o400o1-aH5xPKEYWGw2f9V1SVJTuG.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915770",
        "Title": "From Hunch to Handoff: How AI PMs Can Help Turn Ideas Into Shippable Features Quickly",
        "Description": "\"We should add AI to this!\" Great, but how do you know if your idea will actually work? The gap between AI concept and engineering reality is where most promising features die.\r\nIn this talk, we will reveal a rapid validation framework developed through working with dozens of product teams‚Äîincluding within Workday's AI product efforts. We'll share a three-step process that starts with lightweight prototyping, builds a relevant evaluation suite, and creates the right artifacts for successful engineering handoffs. You'll see how leading teams use this approach to explore what's possible, establish practical quality benchmarks, and align cross-functional stakeholders before writing a single line of production code.\r\nEliza Cabrera (Principal PM, Workday) and Jeremy Silva (Product Lead, Freeplay) will share the playbook they use to turn ‚Äúwe should add AI here‚Äù hunches into AI features customers actually use and trust.\r\nAttendees will leave with a field‚Äëtested framework, real examples from enterprise teams, and ready‚Äëto‚Äëuse templates that let AI PMs guide ideas from first spark to successful release‚Äîcheaply, quickly, and with confidence.\r\n",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "AI Product Management",
        "Room": "Golden Gate Ballroom C: AI in the Fortune 500",
        "Scheduled At": "4 Jun 2025 02:50 PM"
      }
    ]
  },
  {
    "Speaker ID": "ca09219a-1c43-4b4f-a8ba-ede90dada77f",
    "Name": "Eliza Cabrera",
    "Company": "Workday",
    "Company Domain": "airockies.com",
    "Company URL": "Workday.com",
    "Company Website": "",
    "Title": "Principal PM",
    "TagLine": "Principal AI Product Manager @ Workday",
    "Bio": "Building and scaling 0-1 products in the enterprise.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/2bfe-400o400o1-BQXHfd3WjQqbDjQoGJsZat.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915770",
        "Title": "From Hunch to Handoff: How AI PMs Can Help Turn Ideas Into Shippable Features Quickly",
        "Description": "\"We should add AI to this!\" Great, but how do you know if your idea will actually work? The gap between AI concept and engineering reality is where most promising features die.\r\nIn this talk, we will reveal a rapid validation framework developed through working with dozens of product teams‚Äîincluding within Workday's AI product efforts. We'll share a three-step process that starts with lightweight prototyping, builds a relevant evaluation suite, and creates the right artifacts for successful engineering handoffs. You'll see how leading teams use this approach to explore what's possible, establish practical quality benchmarks, and align cross-functional stakeholders before writing a single line of production code.\r\nEliza Cabrera (Principal PM, Workday) and Jeremy Silva (Product Lead, Freeplay) will share the playbook they use to turn ‚Äúwe should add AI here‚Äù hunches into AI features customers actually use and trust.\r\nAttendees will leave with a field‚Äëtested framework, real examples from enterprise teams, and ready‚Äëto‚Äëuse templates that let AI PMs guide ideas from first spark to successful release‚Äîcheaply, quickly, and with confidence.\r\n",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "AI Product Management",
        "Room": "Golden Gate Ballroom C: AI in the Fortune 500",
        "Scheduled At": "4 Jun 2025 02:50 PM"
      }
    ]
  },
  {
    "Speaker ID": "8da471a2-9c10-4d17-b140-5e139bb30908",
    "Name": "Ola  Mabadeje",
    "Company": "Cisco",
    "Company Domain": "cisco.com",
    "Company URL": "https://www.cisco.com/",
    "Company Website": "",
    "Title": "Leader, Generative AI Incubation",
    "TagLine": "Product Leader",
    "Bio": "With decades of experience in the tech industry, Ola is an accomplished speaker and leader in product management, specializing in the creation and scaling of ventures within emerging and disruptive domains. As a current leader in the Generative AI Incubation group at Cisco, Ola drives cutting-edge Generative AI ideas from concept to scalable and profitable businesses at startup velocity.\r\nOla's mission is to harness his cross-functional expertise and wealth of experience to drive innovation and growth in enterprise AI, Generative AI, computer vision, edge computing, and other transformative technologies that are shaping the future.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/029e-400o400o1-nd3ixD6rytghYCjpQzHfH2.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916063",
        "Title": "Leveraging Multi-Agent AI and Network Knowledge Graphs for Change Management and Network Testing",
        "Description": "Traditional ticketing and testing workflows for change management and network operations often operate independently and lack critical real-world context and adaptive decision-making capabilities. This fragmented approach results in delayed resolutions, repeated incidents, escalations, and dissatisfied stakeholders.\r\n\r\nThis session explores an innovative solution leveraging the synergy of natural language processing from IT Service Management (ITSM) systems, sophisticated Multi-agent reasoning, and dynamic context derived from live knowledge network graphs. Attendees will gain insights into an end-to-end architecture where natural language intents from ITSM tickets seamlessly integrate with AI agents specifically trained for complex workflow tasks, supported by continuous network knowledge-graph ingestion pipelines.\r\n\r\nThrough a detailed production case study, we will demonstrate how AI-powered reasoning combined with dynamic network knowledge graph contexts significantly improves critical validation and workflow interactions. The showcased results will highlight dramatic improvements in ticket resolution efficiency, accuracy of network testing, and overall execution quality, delivering tangible value to both technical teams and business stakeholders.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "GraphRAG",
        "Room": "Golden Gate Ballroom B: GraphRAG",
        "Scheduled At": "4 Jun 2025 02:50 PM"
      }
    ]
  },
  {
    "Speaker ID": "a79d82d4-2979-4421-bdf6-25090ac5a051",
    "Name": "Itamar Friedman",
    "Company": "Qodo",
    "Company Domain": "qodo.ai",
    "Company URL": "https://www.qodo.ai/",
    "Company Website": "https://www.qodo.ai/",
    "Title": "CEO and Co-founder",
    "TagLine": "CEO",
    "Bio": " Itamar Friedman is the CEO and co-founder of Qodo (fka CodiumAI), the leader in the emerging code integrity space.\r\nPrior to that, Itamar was the co-founder and CTO of Visualead, which Alibaba Group acquired. As a director at Alibaba, he led teams to create innovative ML-based B2C and B2D applications and tools used by millions.\r\nItamar holds a BSc & MSc in Electrical Engineering (Summa Cum Laude) from the Technion, majoring in Machine Learning and Computer Vision.\r\n\r\n",
    "X (Twitter)": "https://x.com/itamar_mar",
    "LinkedIn": "https://www.linkedin.com/in/itamarf/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/1d5e-400o400o1-NPcEvVbuqLb2gDi2dSpNsr.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916115",
        "Title": "Vibe Coding, with Confidence",
        "Description": "Everyone wants to do Vibe Code, even large Enterprises. But how can we ensure that the generated code is well-grounded with the dev team's code and software development standards? In this talk, Itamar will present how to use various tools and agents, including MCP and A2A, to achieve precisely that.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Product launch",
        "Tracks": "SWE Agents",
        "Room": "Foothill C: Agent Reliability",
        "Scheduled At": "4 Jun 2025 02:50 PM"
      }
    ]
  },
  {
    "Speaker ID": "41cbc412-cbc2-46dd-bdf5-4cf662ac194a",
    "Name": "Tejaswi Tenneti",
    "Company": "Instacart",
    "Company Domain": "instacart.com",
    "Company URL": "https://www.instacart.com/",
    "Company Website": "",
    "Title": "Director of Machine Learning",
    "TagLine": "Director of Machine Learning",
    "Bio": "Tejaswi Tenneti is currently a Director of Machine Learning at Instacart, the north american leader in online grocery. Prior to Instacart, Tejaswi was a tech lead in machine learning teams at Apple and Oracle where he worked on various applications related to Search and Recommendations for local maps data and Enterprise. Tejaswi holds a BS from IIIT, Allahabad and an MS from Stanford University specializing in AI",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/tejaswi-tenneti-78a66116/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/a739-400o400o1-D4TD5BDMibNSP5tLAxLBNQ.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "929231",
        "Title": "Instacart‚Äôs LLM-driven approach to Search and Discovery",
        "Description": "",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "RecSys",
        "Room": "Golden Gate Ballroom A: LLM RecSys",
        "Scheduled At": "4 Jun 2025 02:50 PM"
      }
    ]
  },
  {
    "Speaker ID": "7410679b-1a11-4fa2-81ee-d2ac0845a303",
    "Name": "Vinesh Gudla",
    "Company": "Instacart",
    "Company Domain": "instacart.com",
    "Company URL": "https://instacart.com/",
    "Company Website": "https://instacart.com/",
    "Title": "Staff Machine Learning Engineer",
    "TagLine": "Staff Machine Learning Engineer, Instacart",
    "Bio": "Vinesh is a Staff Machine Learning Engineer at Instacart on the search and discovery team. He has previously worked on balancing multiple objectives in search in a marketplace and has authored numerous well-received blogposts and articles about his work. He is currently working on bringing Generative AI to production at ecommerce scale at Instacart.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/vinesh-gudla-0803219/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/cc1a-400o400o1-fwmctecQds9tmdivtxex6G.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "929231",
        "Title": "Instacart‚Äôs LLM-driven approach to Search and Discovery",
        "Description": "",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "RecSys",
        "Room": "Golden Gate Ballroom A: LLM RecSys",
        "Scheduled At": "4 Jun 2025 02:50 PM"
      }
    ]
  },
  {
    "Speaker ID": "1782748e-538e-4943-9d97-46a90338691c",
    "Name": "Logan Kilpatrick",
    "Company": "Google",
    "Company Domain": "gmail.com",
    "Company URL": "deepmind.com",
    "Company Website": "",
    "Title": "Product Lead for Google AI Studio",
    "TagLine": "Product, Google Deepmind",
    "Bio": "Logan leads product for Google AI Studio and works on the Gemini API. Before Google, Logan led developer relations at OpenAI.",
    "X (Twitter)": "https://twitter.com/OfficialLoganK",
    "LinkedIn": "https://linkedin.com/in/logankilpatrick",
    "Blog": "https://medium.com/logankilpatrick",
    "Profile Picture": "https://sessionize.com/image/b3fe-400o400o1-YvVCjjJygwbpghKHu1AYK.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "935461",
        "Title": "A year of Gemini progress + what comes next",
        "Description": "Over the last year, Google and Gemini models have shown rapid progress across all dimensions (model, product, etc). Let's highlight all the work that has happened, how we got the worlds best models, and where we are going next (across both the model landscape and out AI products).",
        "Format": "Keynote",
        "Level": "Introductory and overview",
        "Scope": "Case Study/War Story",
        "Tracks": "Anything Else/Open Category",
        "Room": "Keynote/General Session (Yerba Buena 7&8)",
        "Scheduled At": "5 Jun 2025 09:00 AM"
      }
    ]
  },
  {
    "Speaker ID": "9df96da4-7b00-4165-8012-072770a6618b",
    "Name": "Solomon Hykes",
    "Company": "Dagger",
    "Company Domain": "dagger.io",
    "Company URL": "https://dagger.io/",
    "Company Website": "https://dagger.io",
    "Title": "Founder and CEO",
    "TagLine": "CEO || Creator of Docker",
    "Bio": "Solomon Hykes is best known as the creator of Docker, the open-source platform that revolutionized software development and deployment through containerization. His work fundamentally changed how applications are built, shipped, and run by standardizing their execution environments. Drawing on his deep experience tackling complexity at the infrastructure level, Solomon is now Founder and CEO of Dagger, focusing on the foundational challenges of building and operating reliable, scalable AI agent systems. He is passionate about applying platform engineering principles to the emerging AI landscape, helping engineers navigate this technological shift and build more dependable systems.",
    "X (Twitter)": "https://x.com/solomonstre",
    "LinkedIn": "https://www.linkedin.com/in/solomonhykes/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/151f-400o400o1-K24Fa4JzDNJJBc5xKnFiZ2.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916116",
        "Title": "Containing Agent Chaos",
        "Description": "AI agents promise breakthroughs but often deliver operational chaos. Building reliable, deployable systems with unpredictable LLMs feels like wrestling fog ‚Äì testing outputs alone is insufficient when the underlying workflow is opaque and flaky. How do we move beyond fragile prototypes?\r\n\r\nThis talk, from the creator of Docker, argues the solution lies *outside* the model: engineering **reproducible execution workflows** built on rigorous architectural discipline. Learn how **containerization**, applied not just to deployment but to *each individual step* of an agent's workflow, provides the essential **isolation and environmental consistency** needed.\r\n\r\nDiscover how combining this granular container approach with patterns like immutable state management allows us to **contain agent chaos**, unlock effective testing, simplify debugging, and bring essential control and predictability back to building powerful AI agents you can actually ship with confidence.",
        "Format": "Keynote",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Infrastructure",
        "Room": "Keynote/General Session (Yerba Buena 7&8)",
        "Scheduled At": "5 Jun 2025 09:50 AM"
      }
    ]
  },
  {
    "Speaker ID": "4e01104b-7d8e-4552-9224-6b7bd4f697fa",
    "Name": "Jesse Han",
    "Company": "Morph Labs",
    "Company Domain": "morph.so",
    "Company URL": "https://morph.so/",
    "Company Website": "https://morph.so",
    "Title": "Founder and CEO",
    "TagLine": "Founder",
    "Bio": "Jesse Han is the Founder and CEO of Morph Labs, a company building the infrastructure for the singularity. Morph is the creator of Infinibranch, a breakthrough in cloud technology that enables scaling train-time and test-time search for agentic reasoning models. Jesse began his career as a pure mathematician and research scientist at OpenAI working on test-time compute scaling, GPT-4, and reasoning.",
    "X (Twitter)": "https://twitter.com/jessemhan",
    "LinkedIn": "https://linkedin.com/in/jesse-michael-han",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/8a20-400o400o1-hXqkB3J73tudpxqaiDoWtB.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916189",
        "Title": "The infrastructure for the singularity",
        "Description": "We're at an inflection point where AI agents are transitioning from experimental tools to practical coworkers. This new world will demand new infrastructure for RL training, test-time scaling, and deployment. This is why Morph Labs developed Infinibranch last year, and we are excited to finally unveil what's next.",
        "Format": "Keynote",
        "Level": "Intermediate",
        "Scope": "Product launch",
        "Tracks": "Infrastructure, Reasoning+RL",
        "Room": "Keynote/General Session (Yerba Buena 7&8)",
        "Scheduled At": "5 Jun 2025 10:10 AM"
      }
    ]
  },
  {
    "Speaker ID": "cfff00f5-73e9-4881-bb4a-b9e34b98b26e",
    "Name": "Gorkem Yurtseven",
    "Company": "fal",
    "Company Domain": "fal.ai",
    "Company URL": "https://fal.ai/",
    "Company Website": "",
    "Title": "Co-founder and CTO",
    "TagLine": "CTO ",
    "Bio": "Gorkem Yurtseven is the co-founder and CTO of fal, a generative media platform empowering developers to build with cutting-edge AI models. Previously, he was a Senior Software Engineer at AWS and holds a degree in Computer Engineering from the University of Pennsylvania.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/gorkemy/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/0248-400o400o1-S1h1zJfr2zCBnGvaWQN9j.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "910158",
        "Title": "The State of Generative Media Today",
        "Description": "Generative AI is reshaping the creative landscape, enabling the production of images, audio, and video with unprecedented speed and sophistication. This session offers an in-depth exploration of the current state of generative media, highlighting cutting-edge models, platforms, and tools that are transforming the industry. ",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Technical deep dive",
        "Tracks": "Generative Media",
        "Room": "Foothill F: Generative Media",
        "Scheduled At": "5 Jun 2025 11:15 AM"
      }
    ]
  },
  {
    "Speaker ID": "3c85e31c-c243-4811-8ce4-30f89896ef7c",
    "Name": "Alvaro Morales",
    "Company": "Orb",
    "Company Domain": "aircoverpr.com",
    "Company URL": "https://www.withorb.com/",
    "Company Website": "https://www.withorb.com/",
    "Title": "CEO and co-founder",
    "TagLine": "CEO",
    "Bio": "Alvaro Morales is the co-founder and CEO of Orb, a leading billing and monetization platform enabling SaaS and GenAI companies to adopt flexible, usage-based, and outcome-driven pricing models. Since founding Orb in 2021, he has helped businesses transition from traditional seat-based pricing to dynamic, data-driven monetization strategies that scale with customer value. Previously, he led growth engineering at Asana, optimizing pricing and revenue strategies. Morales holds Master‚Äôs and Bachelor‚Äôs degrees in Computer Science from MIT and has worked at Palantir, Yahoo!, and MIT‚Äôs CSAIL. A fintech innovator, he is shaping the future of AI monetization in a usage-based economy.",
    "X (Twitter)": "https://x.com/alvaromorales",
    "LinkedIn": "https://www.linkedin.com/in/alvaro-morales/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/6c39-400o400o1-JBNFJeGFzwhuctMDmcV6j5.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "912033",
        "Title": "Monetizing AI: From Zero to Profit",
        "Description": "As AI continues to transform industries, companies are faced with the critical challenge of effectively monetizing AI-driven products in a way that captures value, ensures customer adoption, and scales revenue sustainably. Unlike traditional SaaS models, AI-powered products have unique complexities - such as fluctuating usage patterns, variable compute costs, and evolving customer demands, making conventional pricing strategies unhelpful to the growth of an AI product-led startup.\r\n\r\nIn this session, Alvaro Morales, CEO and co-founder of Orb, will explore why the often overlooked monetization aspect of AI is critical for businesses. He‚Äôll share real-world examples and data to demonstrate how adaptive pricing models can drive cost savings, enhance customer experience, and reduce operational bottlenecks.\r\n\r\nAlvaro will lead a live demo, showcasing how engineers can simulate AI pricing strategies and subsequently integrate them with a simple plug-and-play solution. He‚Äôll also share how real-world revenue simulations enable companies to test and refine pricing before implementing ‚Äî reducing risk, boosting adoption, and unlocking new revenue streams. As a quick example, cloud software development platform Replit was looking to adopt a usage-based pricing model for a new product, but their existing billing system couldn't support the new model, and building a new billing system would delay the launch timeline. In order to get things done, they turned to Orb, which enabled them to make pricing changes up to the last minute. After the launch, Orb became the single source of truth for both Replit and its customers - providing usage alerts to notify Replit when users hit cost thresholds and provide insights into user spend and payment methods.\r\n\r\nKey takeaways: \r\nThe challenge of AI monetization ‚Äì Why traditional subscription-based SaaS pricing models don‚Äôt work for AI-powered products.\r\nPrecision pricing ‚Äì Exploring how usage-based, tiered, and hybrid pricing models can maximize revenue potential. \r\nRevenue simulation for AI pricing ‚Äì Leveraging real-time data to test, adjust and optimize pricing strategies.\r\nAvoiding common pricing pitfalls ‚Äì Identifying mistakes that can lead to revenue leakage and customer churn.\r\n\r\nThis session is designed for AI executives, product leaders, and engineering teams looking for actionable strategies to build adaptive, scalable pricing models that drive long-term growth and profitability.\r\n\r\n",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "Leadership: Architects",
        "Room": "SOMA: AI Architects",
        "Scheduled At": "5 Jun 2025 11:15 AM"
      }
    ]
  },
  {
    "Speaker ID": "a9f28f8a-f80a-4b02-91db-8ef8b0d1fd98",
    "Name": "Victor Dibia",
    "Company": "Microsoft Research",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.microsoft.com/en-us/research/",
    "Company Website": "https://victordibia.com/",
    "Title": "Principal Research Software Engineer",
    "TagLine": "Principal Research Engineer",
    "Bio": "Victor Dibia is a Principal Research Software Engineer at Microsoft Research where his current work is focused on the design of multi-agent systems powered by Generative AI models. Victor is a core contributor to AutoGen - a leading python open source library for building multi-agent applications and the creator of AutoGen Studio, a low code interface for authoring, testing and debugging multi-agent workflows. ",
    "X (Twitter)": "https://x.com/vykthur",
    "LinkedIn": "https://www.linkedin.com/in/dibiavictor/",
    "Blog": "https://newsletter.victordibia.com/",
    "Profile Picture": "https://sessionize.com/image/27ba-400o400o1-hiaSDw7CaydL52YybJTVH7.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914027",
        "Title": "UX Design Principles for (Semi) Autonomous Multi-Agent Systems",
        "Description": "Autonomous or semi-autonomous multi-agent systems (MAS) involve exponentially complex configurations (system config, agent configs, task management and delegation, etc.). These present unique interface design challenges for both developer tooling and end-user experiences.\r\nIn this session, I'll explore UX design principles for multi-agent systems, addressing critical questions: What is the true configuration space for autonomous MAS? How can users arrive at the correct mental model of an MAS's capabilities, if at all? How can we improve trust and safety through techniques like cost-aware action delegation? What makes agent actions observable? How do we enable seamless interruptibility? Attendees will gain actionable insights to create more transparent, trustworthy, and user-centered multi-agent applications, illustrated through real-world implementations in AutoGen Studio - a low code developer tool built on AutoGen (44k stars on GitHub, MIT license) and similar tools.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Design Engineering",
        "Room": "Foothill G 1&2: Design Engineering",
        "Scheduled At": "5 Jun 2025 11:15 AM"
      }
    ]
  },
  {
    "Speaker ID": "290c81c8-f994-4e84-8667-ca8b6ffd95e4",
    "Name": "Rossella Blatt Vital",
    "Company": "Sprout Social",
    "Company Domain": "gmail.com",
    "Company URL": "",
    "Company Website": "https://sproutsocial.com",
    "Title": "VP of AI, Data, and Data Science",
    "TagLine": "VP of Engineering - AI",
    "Bio": "Rossella Blatt Vital is a passionate AI leader with nearly 20 years of experience turning data into business value‚Äîfrom hands-on research and model-building to strategic executive leadership. She began her journey with a PhD in machine learning, focusing on brain-computer interfaces and cancer detection, and spent years writing code, building models, and shipping AI-powered products before stepping into leadership roles across startups, academia, and Fortune 100 companies.\r\n\r\nAs VP of AI, Data, and Data Science at Sprout Social, Rossella leads the company‚Äôs AI transformation‚Äîdriving strategy across engineering, applied science, and analytics. Her team is building AI-first capabilities across product experiences, platform infrastructure, and foundational data systems.\r\n\r\nShe‚Äôs passionate about building meaningful technology‚Äîand the teams that power it‚Äîwith the belief that AI, when led with vision and integrity, can help shape a more thoughtful and human-centered future.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/rossellablatt/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/5f23-400o400o1-9RohnfFYvyXR6djmr53QcA.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914401",
        "Title": "From Hype to Habit: How We‚Äôre Building an AI-First SaaS Company‚ÄîWhile Still Shipping the Roadmap",
        "Description": "What does it really take to move a modern SaaS company from AI experimentation to becoming truly AI-first?\r\n\r\nAt Sprout Social, we‚Äôre in the midst of that transformation‚Äîrearchitecting strategy, systems, teams, and incentives to put AI at the heart of how we think, build, and deliver value. This is a story in motion: a behind-the-scenes look at how we‚Äôre evolving from isolated AI feature experiments to an AI-native operating model.\r\n\r\nI‚Äôll share what we‚Äôre learning as we navigate the innovation dilemma‚Äîintegrating disruptive AI capabilities without breaking what already works or our roadmap. That includes rethinking how we define success, how we hire, reward, grow talent, and how we handle legal and ethical complexity without slowing down. We‚Äôll explore the real-world tensions between rapid innovation, value delivery, making progress on Responsible AI, all while elevating internal AI fluency, and engaging with the broader AI ecosystem to stay at the edge. \r\n\r\nThis isn‚Äôt a playbook from the finish line‚Äîit‚Äôs a candid reflection from deep inside the journey.\r\n\r\nMy goal is to help other leaders chart their own AI path with greater clarity, confidence, and care.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Introductory (landscape)",
        "Tracks": "Leadership: Architects",
        "Room": "Golden Gate Ballroom C: AI in the Fortune 500",
        "Scheduled At": "5 Jun 2025 11:15 AM"
      }
    ]
  },
  {
    "Speaker ID": "ddc817a7-676a-4963-a7eb-c22465dcb65f",
    "Name": "Deepsha Menghani",
    "Company": "Sprout Social",
    "Company Domain": "sproutsocial.com",
    "Company URL": "https://sproutsocial.com",
    "Company Website": "",
    "Title": "Director of Engineering ‚Äì AI",
    "TagLine": "Director of Engineering ‚Äì AI",
    "Bio": "Deepsha Menghani is a passionate AI leader with over a decade of experience translating data and machine learning into meaningful business impact‚Äîfrom predictive modeling and customer analytics to large language model applications. Her career spans hands-on data science, applied AI, and strategic leadership across global tech organizations. As Director of Engineering ‚Äì AI at Sprout Social, her team is responsible for embedding AI into core product experiences and delivering insights that accelerate growth, improve customer understanding, and inform business strategy across the company.\r\n\r\nShe‚Äôs especially passionate about building AI that is not only technically robust, but also responsible, human-centered, and aligned with real-world decision-making.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/deepshamenghani",
    "Blog": "https://medium.com/@menghani.deepsha",
    "Profile Picture": "https://sessionize.com/image/d6f0-400o400o1-MhucsppjbCGGDEzCdQLdtn.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914401",
        "Title": "From Hype to Habit: How We‚Äôre Building an AI-First SaaS Company‚ÄîWhile Still Shipping the Roadmap",
        "Description": "What does it really take to move a modern SaaS company from AI experimentation to becoming truly AI-first?\r\n\r\nAt Sprout Social, we‚Äôre in the midst of that transformation‚Äîrearchitecting strategy, systems, teams, and incentives to put AI at the heart of how we think, build, and deliver value. This is a story in motion: a behind-the-scenes look at how we‚Äôre evolving from isolated AI feature experiments to an AI-native operating model.\r\n\r\nI‚Äôll share what we‚Äôre learning as we navigate the innovation dilemma‚Äîintegrating disruptive AI capabilities without breaking what already works or our roadmap. That includes rethinking how we define success, how we hire, reward, grow talent, and how we handle legal and ethical complexity without slowing down. We‚Äôll explore the real-world tensions between rapid innovation, value delivery, making progress on Responsible AI, all while elevating internal AI fluency, and engaging with the broader AI ecosystem to stay at the edge. \r\n\r\nThis isn‚Äôt a playbook from the finish line‚Äîit‚Äôs a candid reflection from deep inside the journey.\r\n\r\nMy goal is to help other leaders chart their own AI path with greater clarity, confidence, and care.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Introductory (landscape)",
        "Tracks": "Leadership: Architects",
        "Room": "Golden Gate Ballroom C: AI in the Fortune 500",
        "Scheduled At": "5 Jun 2025 11:15 AM"
      }
    ]
  },
  {
    "Speaker ID": "e344968a-0c7a-45c8-8cd1-27a77ead36ce",
    "Name": "Will Brown",
    "Company": "Prime Intellect",
    "Company Domain": "columbia.edu",
    "Company URL": "https://www.primeintellect.ai/",
    "Company Website": "https://primeintellect.ai",
    "Title": "Research Engineering Lead",
    "TagLine": "Research Engineering Lead",
    "Bio": "Will Brown is a Research Engineering Lead at Prime Intellect, focusing on RL for reasoning and agents. He previously held research roles at Morgan Stanley and AWS, and completed his PhD in Computer Science at Columbia University. ",
    "X (Twitter)": "https://x.com/willccbb",
    "LinkedIn": "https://www.linkedin.com/in/willcb",
    "Blog": "https://willcb.com",
    "Profile Picture": "https://sessionize.com/image/5808-400o400o1-Jhwoe2fQGyjgKKsxXWZke5.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914856",
        "Title": "Training Agentic Reasoners",
        "Description": "This talk will be a technical deep dive into RL for agentic reasoning via multi-turn tool calling, similar to OpenAI's o3 and Deep Research. In particular, we'll cover:\r\n- When, why, and how\r\n- GRPO vs PPO vs etc\r\n- Designing environments and rewards\r\n- Survey of recent research highlights\r\n- Results on example tasks\r\n- Overview of open-source ecosystem (libraries, compute requirements, tradeoffs, etc.)",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Reasoning+RL",
        "Room": "Yerba Buena Ballroom 2-6: Reasoning + RL",
        "Scheduled At": "5 Jun 2025 11:15 AM"
      }
    ]
  },
  {
    "Speaker ID": "d990444a-bbaa-439f-bc81-3ef5e8caac69",
    "Name": "Jyh-Jing Hwang",
    "Company": "Waymo ",
    "Company Domain": "google.com",
    "Company URL": "https://waymo.com/",
    "Company Website": "",
    "Title": "Research Scientist and TLM",
    "TagLine": "Research Scientist & TLM ",
    "Bio": "Jyh-Jing is currently a Research Scientist and TLM at Waymo Research. He also taught machine learning and computer vision as a lecturer at UPenn MCIT Online in 2022 and 2023. Before joining Waymo in 2020, Jyh-Jing received his Ph.D. degree in Computer and Information Science from University of Pennsylvania, advised by Prof. Jianbo Shi and Prof. Stella Yu at UC Berkeley / ICSI. Before coming to the U.S., he received the B.S. and M.S. degrees from National Taiwan University and worked with Dr. Tyng-Luh Liu at Academia Sinica. His research interests are broadly in artificial intelligence, computer vision, and machine learning. Particularly, he's interested in end-to-end autonomous driving, large multimodal models, general image/video structures, and sensor fusion for robust perception.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/7ba6-400o400o1-EQPfTaj5r2ipiSnm9DjrFR.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915934",
        "Title": "Teaching Cars to Think: Language Models and Autonomous Vehicles",
        "Description": "This session explores Waymo's latest research on the End-to-End Multimodal Model for Autonomous Driving (EMMA) and advanced sensor simulation techniques. Jyh-Jing Hwang will demonstrate how multimodal large language models like Gemini could improve autonomous driving through unified end-to-end architectures that process raw sensor data directly into driving decisions. \r\n\r\nThe presentation will showcase EMMA's state-of-the-art performance in trajectory planning, 3D object detection, and road graph understanding, as well as another Drive&Gen research approach to sensor simulation for evaluating an end-to-end motion planning model. Attendees will gain insights into the benefits of co-training across multiple autonomous driving tasks and the potential of controlled video generation for testing under various environmental conditions.\r\n\r\nMore on EMMA here: https://waymo.com/blog/2024/10/introducing-emma\r\n",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Autonomy+Robotics",
        "Room": "Foothill E: Autonomy + Robotics",
        "Scheduled At": "5 Jun 2025 11:15 AM"
      }
    ]
  },
  {
    "Speaker ID": "0526d7d4-e6b6-4fae-a9bc-38f96ba75bd3",
    "Name": "Chang She",
    "Company": "LanceDB",
    "Company Domain": "lancedb.com",
    "Company URL": "https://www.lancedb.com/",
    "Company Website": "https://www.lancedb.com",
    "Title": "Co-founder",
    "TagLine": "CEO",
    "Bio": "Two decades of building data tools for ML/AI. Pandas co-author. Building LanceDB, the database for multimodal AI.",
    "X (Twitter)": "https://x.com/changhiskhan",
    "LinkedIn": "https://www.linkedin.com/in/changshe/",
    "Blog": "https://blog.lancedb.com",
    "Profile Picture": "https://sessionize.com/image/7a07-400o400o1-MuSbRRkcoMr4jC4RVdNg4t.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "903966",
        "Title": "Scaling Enterprise-Grade RAG Systems: Lessons from the Legal Frontier",
        "Description": "In domains like law, compliance, and tax, building enterprise-grade RAG means very large scale, spikey workloads, a focus on accuracy, and non-negotiable privacy.\r\nIn this talk, we'll share war stories and battle scars of how Harvey has built the world's most advanced AI agents for the legal profession on top of a highly optimized retrieval architecture. We'll cover how to get better retrieval via both sparse and dense retrieval methods, why domain-specific reranking is essential, and how to handle ambiguity in real-world queries.\r\nWe'll also touch on how LanceDB's search engine enables this architecture by delivering low-latency, high-throughput retrieval across millions of documents of varying sizes without compromising privacy. This solid foundation enables Harvey to build a product that brings highly accurate answers to hundreds of law firms and professional services firms across 45 countries.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Retrieval+Search",
        "Room": "Golden Gate Ballroom A: Retrieval + Search",
        "Scheduled At": "5 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "f3bfd5b7-b22f-48b4-a577-002c5856346e",
    "Name": "Aman Kishore",
    "Company": "Harvey AI",
    "Company Domain": "harvey.ai",
    "Company URL": "https://www.harvey.ai/",
    "Company Website": "https://harvey.ai",
    "Title": "Former Founder",
    "TagLine": "Former Founder",
    "Bio": "Former Founder",
    "X (Twitter)": "https://x.com/_amankishore",
    "LinkedIn": "https://www.linkedin.com/in/aman-kishore/",
    "Blog": "https://amanml.com",
    "Profile Picture": "https://sessionize.com/image/9222-400o400o1-aRYyy3aGCPXsRcR1usvcme.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "903966",
        "Title": "Scaling Enterprise-Grade RAG Systems: Lessons from the Legal Frontier",
        "Description": "In domains like law, compliance, and tax, building enterprise-grade RAG means very large scale, spikey workloads, a focus on accuracy, and non-negotiable privacy.\r\nIn this talk, we'll share war stories and battle scars of how Harvey has built the world's most advanced AI agents for the legal profession on top of a highly optimized retrieval architecture. We'll cover how to get better retrieval via both sparse and dense retrieval methods, why domain-specific reranking is essential, and how to handle ambiguity in real-world queries.\r\nWe'll also touch on how LanceDB's search engine enables this architecture by delivering low-latency, high-throughput retrieval across millions of documents of varying sizes without compromising privacy. This solid foundation enables Harvey to build a product that brings highly accurate answers to hundreds of law firms and professional services firms across 45 countries.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Retrieval+Search",
        "Room": "Golden Gate Ballroom A: Retrieval + Search",
        "Scheduled At": "5 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "8704af51-8a94-4a8b-adc1-3322925e7274",
    "Name": "Calvin Qi",
    "Company": "Harvey AI",
    "Company Domain": "harvey.ai",
    "Company URL": "https://www.harvey.ai/",
    "Company Website": "",
    "Title": "Retrieval Augmented Generation Specialist",
    "TagLine": "Tech Lead Manager",
    "Bio": "Calvin works on Retrieval Augmented Generation at Harvey for expert use cases in Legal, Tax, and more.",
    "X (Twitter)": "https://x.com/calvincongelado",
    "LinkedIn": "https://www.linkedin.com/in/calvinqi/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/1cfe-400o400o1-ngjKE6r3bZUEwDRvW2QE3o.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "903966",
        "Title": "Scaling Enterprise-Grade RAG Systems: Lessons from the Legal Frontier",
        "Description": "In domains like law, compliance, and tax, building enterprise-grade RAG means very large scale, spikey workloads, a focus on accuracy, and non-negotiable privacy.\r\nIn this talk, we'll share war stories and battle scars of how Harvey has built the world's most advanced AI agents for the legal profession on top of a highly optimized retrieval architecture. We'll cover how to get better retrieval via both sparse and dense retrieval methods, why domain-specific reranking is essential, and how to handle ambiguity in real-world queries.\r\nWe'll also touch on how LanceDB's search engine enables this architecture by delivering low-latency, high-throughput retrieval across millions of documents of varying sizes without compromising privacy. This solid foundation enables Harvey to build a product that brings highly accurate answers to hundreds of law firms and professional services firms across 45 countries.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Retrieval+Search",
        "Room": "Golden Gate Ballroom A: Retrieval + Search",
        "Scheduled At": "5 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "b6c36208-886a-4ea6-a91a-12adba06960c",
    "Name": "Eno Reyes",
    "Company": "Factory",
    "Company Domain": "factory.ai",
    "Company URL": "https://www.factory.ai/",
    "Company Website": "https://www.factory.ai/",
    "Title": "Cofounder and CTO",
    "TagLine": "CTO",
    "Bio": "Eno Reyes is cofounder and CTO of Factory, a platform that accelerates enterprise software development with autonomous AI agents and unified context from across your engineering tools. Enterprises are using Factory to accelerate everything from bug-fixing and coding to PRD creation, release automation, migrations, and more.\r\n\r\nPrior to Factory, he was an ML engineer at Hugging Face working on enterprise LLMs.",
    "X (Twitter)": "https://x.com/EnoReyes",
    "LinkedIn": "https://www.linkedin.com/in/enoreyes/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/0ead-400o400o1-PswjrSTdxdyg7Jhq9EfQgq.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "904751",
        "Title": "Ship Production Software in Minutes, Not Months",
        "Description": "Planning, coding, testing, monitoring‚Äîthe endless cycle that spans 10+ tools that fragment our focus and slows delivery to a crawl. Vibe coding doesn't work when you've got 10TB of code. If you just sighed, you're one of many professional software engineers trapped in the traditional software development lifecycle (SDLC) that was designed before AI could parallelize your entire workflow.\r\n\r\nBut what if you could orchestrate multiple AI agents on tasks beyond just generating code, while you focus on the creative decisions that matter?\r\n\r\nIn this talk, I'll demonstrate how real enterprise organizations are changing their entire SDLC‚Äîgoing from understanding, planning, coding, and testing all the way to incident response‚Äîusing AI agents. You'll witness the next evolution of software engineering‚Äîwhere AI doesn't just generate code, but orchestrates the entire development lifecycle.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Product launch",
        "Tracks": "SWE Agents",
        "Room": "Yerba Buena Ballroom 7&8: SWE Agents",
        "Scheduled At": "5 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "3a74e448-594e-4322-9578-c04d843724b7",
    "Name": "Jonathan Mortensen",
    "Company": "Confident Security",
    "Company Domain": "confidentsecurity.com",
    "Company URL": "https://confident.security/",
    "Company Website": "https://confident.security",
    "Title": "CEO",
    "TagLine": "CEO",
    "Bio": "Jonathan Mortensen is a technology executive and founder with expertise spanning AI, data infrastructure, and cybersecurity. Currently serving as CEO of a stealth AI startup and Founder Fellow at South Park Commons, Jonathan previously founded bit.io, a multi-cloud serverless PostgreSQL platform acquired by Databricks. As bit.io's CTO, he built innovative database technology that handled hundreds of thousands of databases securely across multiple cloud providers. Prior to founding bit.io, Jonathan led data science and engineering teams at BlueVoyant, where he designed high-volume data pipelines processing 50 million events per second. He holds a PhD in Biomedical Informatics from Stanford University and combines technical depth with leadership experience across engineering, revenue, and operations.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/jonathanmortensen/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/e696-400o400o1-WVBy6tYtCrRMBBsykwHt4T.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "909905",
        "Title": "The Unofficial Guide to Apple‚Äôs Private Cloud Compute",
        "Description": "In October 2024, Apple released a new private AI technology onto millions of devices called ‚ÄúPrivate Cloud Compute‚Äù. It brings the same level of privacy and security a local device offers but on an ‚Äúuntrusted\" remote server. This talk discusses how Private Cloud Compute represents a paradigm shift in confidential computing and explores the core advancements that made it possible to become mainstream. We‚Äôll explore its novel architecture that allows developers to run sensitive, multi-tenant workloads with cryptographically-provably privacy guarantees at scale and at reasonable cost. Attendees will leave with an understanding of how to leverage this technology for data and AI applications where privacy and security is paramount.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Security",
        "Room": "Foothill C: Security",
        "Scheduled At": "5 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "fff30ce6-b9f4-4043-b85c-0d1bee36eb22",
    "Name": "Kelvin Ma",
    "Company": "Google Photos",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.google.com/intl/en_us/photos/about/",
    "Company Website": "https://www.google.com/intl/en_us/photos/about/",
    "Title": "Product Engineer",
    "TagLine": "Software Engineer ",
    "Bio": "I'm Kelvin Ma. A product engineer with 15 years of experience working across innovative consumer applications that is used by millions of consumers. I'm passionate about using technology to build tools that improves users lives by allowing greater expression, building skills, and fostering communication.  ",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/kelvin-ma-6512bb12/",
    "Blog": "https://blog.kelvin.ma/posts/",
    "Profile Picture": "https://sessionize.com/image/1f56-400o400o1-UcpJeF5xe2NCAhuBgnJLk2.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "910197",
        "Title": "Magic Editor Under the Hood: Weaving Generative AI into a Billion-User App",
        "Description": "Go behind the scenes of Google Photos' Magic Editor. Explore the engineering feats required to integrate complex CV and cutting-edge generative AI models into a seamless mobile experience. We'll discuss optimizing massive models for latency/size, the crucial interplay with graphics rendering (OpenGL/Halide), and the practicalities of turning research concepts into polished features people actually use.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Generative Media",
        "Room": "Foothill F: Generative Media",
        "Scheduled At": "5 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "3424ead2-2223-4bf6-9ef0-254a8540f68c",
    "Name": "Greg Kamradt",
    "Company": "ARC Prize Foundation",
    "Company Domain": "arcprize.org",
    "Company URL": "https://arcprize.org/",
    "Company Website": "https://arcprize.org/",
    "Title": "President",
    "TagLine": "President",
    "Bio": "Greg Kamradt is President of the ARC¬†Prize Foundation, the ARC‚ÄëAGI benchmark series that challenges frontier AI models on out‚Äëof‚Äëdistribution reasoning tasks.",
    "X (Twitter)": "https://x.com/GregKamradt",
    "LinkedIn": "https://www.linkedin.com/in/gregkamradt/",
    "Blog": "https://gregkamradt.com/",
    "Profile Picture": "https://sessionize.com/image/9fcf-400o400o1-TmRC2WfLNcXZ13UTXGicuB.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914786",
        "Title": "Inside ARC Prize, Scaling Reasoning, and Dynamic Evals",
        "Description": "ARC Prize Foundation is building the North Star for AGI‚Äîrigorous, open benchmarks that track reasoning progress in modern AI. We'll cover how we've evaluated frontier models since GPT-3.5 and share a preview of ARC-AGI-3: a dynamic, game-like benchmark launching next year to test general intelligence.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "Reasoning+RL",
        "Room": "Yerba Buena Ballroom 2-6: Reasoning + RL",
        "Scheduled At": "5 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "57f7b222-9000-49c5-be6f-401f5ed85729",
    "Name": "John Pham",
    "Company": "The San Francisco Compute Company",
    "Company Domain": "gmail.com",
    "Company URL": "https://sfcompute.com/",
    "Company Website": "https://sfcompute.com",
    "Title": "Engineer and Designer",
    "TagLine": "Head of Design ",
    "Bio": "I'm John Pham, an engineer and a self-taught designer. I seek the dopamine hits of building delightful experiences for others. I've worked at Vercel, Microsoft and NASA doing just that.",
    "X (Twitter)": "https://twitter.com/johnphamous",
    "LinkedIn": "https://www.linkedin.com/in/johnphamous/",
    "Blog": "https://pham.codes",
    "Profile Picture": "https://sessionize.com/image/3d96-400o400o1-ckJzaLGR1pNqpqzGEBgRR.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914845",
        "Title": "Good design hasn‚Äôt changed with AI",
        "Description": "Bad designs are still bad. AI doesn‚Äôt make it good. The novelty of AI makes the bad things tolerable, for a short time. Building great designs and experiences with AI have the same first principles pre-AI. When people use software, they want it to feel responsive, safe, accessible and delightful. We‚Äôll go over the big and small details that goes into software that people want to use, not forced to use.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Design Engineering",
        "Room": "Foothill G 1&2: Design Engineering",
        "Scheduled At": "5 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "34a27f5f-368a-4f4a-8c7b-b0413323e035",
    "Name": "Alex Duffy",
    "Company": "Every Inc.",
    "Company Domain": "every.to",
    "Company URL": "https://every.to/",
    "Company Website": "https://every.to/",
    "Title": "Head of AI Strategy",
    "TagLine": "Head of AI",
    "Bio": "I‚Äôm Alex Duffy. I lead AI strategy at Every Inc., helping teams across industries put AI into practice. Previously, I co-founded AI Camp, teaching thousands of students to build their own AI projects, and launched Salt AI, creating tools to help researchers, designers, and creators bring ideas to life. I‚Äôm passionate about building teams and tools to empower people with AI. I really believe in creating technology that works for us, not that is work for us. ",
    "X (Twitter)": "https://x.com/alxai_",
    "LinkedIn": "https://www.linkedin.com/in/alex-d/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/6e93-400o400o1-UDESThkaig3MRZVhYqL9r9.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915974",
        "Title": "Benchmarks Are Memes: How What We Measure Shapes AI‚Äîand Us",
        "Description": "Benchmarks shape more than just AI models‚Äîthey shape our future. The things we choose to measure become self-fulfilling prophecies, guiding AI toward specific abilities and, ultimately, defining humanity‚Äôs evolving role in the AI era. Today‚Äôs benchmarks have propelled incredible progress, but now we have an exciting opportunity: thoughtfully designing benchmarks around what genuinely matters to us‚Äîcooperation, creativity, education, and meaningful human experiences.\r\n\r\nIn this talk, we‚Äôll explore how benchmarks function as powerful cultural memes, influencing not only technical outcomes but societal direction. Drawing on practical examples we have seen at Every consulting in industries like finance, journalism, education, and even personally making AI play diplomacy. We‚Äôll uncover what makes a benchmark impactful, approachable, and inspiring. You‚Äôll see our engaging new AI Diplomacy benchmark demo, illustrating vividly how thoughtful evaluation design can excite both engineers and the wider community.\r\n\r\nYou‚Äôll hopefully walk away inspired and equipped to define benchmarks intentionally, helping steer AI toward outcomes that truly matter.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Architects",
        "Room": "SOMA: AI Architects",
        "Scheduled At": "5 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "ccc0c352-c059-46b2-86a0-c664d12cbb97",
    "Name": "Stefania Druga",
    "Company": "Google",
    "Company Domain": "hackidemia.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "Research Scientist, Google Gemini",
    "TagLine": "AI Research Scientist ",
    "Bio": "Hi! I am Stef. I am currently a Research Scientist in Google Gemini working on novel multimodal AI applications. Previously I was a Principal Researcher in the Center of Applied AI Research at the University of Chicago. I graduated with a Ph.D. in Creative AI Literacies üéì at the University of Washington Information School.\r\n\r\nMy research focuses on Large Language Models and the design of Multimodal AI tools and resources üñåÔ∏è and during grad school I built the first open-source platform for K12 AI Education - Cognimates. When I am not coding & writing papers üë©üèΩ",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/2f6a-400o400o1-BS9irYXsTStZjVqcRAwREZ.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916140",
        "Title": "Real-time Experiments with an AI Co-Scientist",
        "Description": "The sheer volume of data and complexity of modern scientific challenges necessitate tools that go beyond mere analysis. The vision of an \"AI Co-scientist\" ‚Äì a true collaborative partner in the lab ‚Äì requires sophisticated engineering to bridge the gap between powerful AI reasoning and the dynamic reality of physical experiments. This talk dives into the engineering required to build robust AI Co-scientists for hands-on research. We will explore scalable architectures, such as multi-agent systems leveraging foundation models like Gemini for complex reasoning, hypothesis refinement (inspired by the \"generate, debate, evolve\" paradigm described in recent AI Co-scientist research), and intelligent tool use. The core focus will be on the engineering challenges and solutions for integrating diverse, real-time empirical data streams ‚Äì visual data from cameras, quantitative readings from sensors, positional feedback from actuators, and instrument outputs ‚Äì directly into the AI's reasoning loop. I will illustrate this with concrete, technically detailed examples in chemistry (adaptive reaction monitoring), robotics (vision-guided assembly with SO Arm 100 and LeRobot library), and synthetic biology (real-time bacterial growth monitoring & interpretation). We'll discuss engineering strategies for handling data heterogeneity, latency, noise, and enabling the AI to interpret, correlate, and act upon live experimental feedback. Finally, we will touch upon how thoughtful engineering of these AI Co-scientists can contribute to democratizing access to advanced scientific capabilities.\r\n",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Autonomy+Robotics",
        "Room": "Foothill E: Autonomy + Robotics",
        "Scheduled At": "5 Jun 2025 11:40 AM"
      }
    ]
  },
  {
    "Speaker ID": "43c3c635-137d-4ed2-bdad-b8767f9d3e08",
    "Name": "Julia Neagu",
    "Company": "Quotient AI",
    "Company Domain": "quotientai.co",
    "Company URL": "https://www.quotientai.co/",
    "Company Website": "https://www.quotientai.co",
    "Title": "Co-founder and CEO",
    "TagLine": "CEO",
    "Bio": "Julia is the co-founder and CEO of Quotient AI, which provides intelligent observability for AI apps by automatically detecting failures, uncovering root causes, and recommending improvements. Before Quotient, she was the Director of Data for Copilot, GitHub's AI pair programmer, where her team built the systems evaluating the large language models behind Copilot. Previously, she was the Director of Analytics at Tamr and led end-to-end quantitative modeling at Aon's Intellectual Property Solutions group. Julia has a PhD and MA in Physics from Harvard, an AB in Physics from Princeton.",
    "X (Twitter)": "https://x.com/JuliaANeagu",
    "LinkedIn": "https://www.linkedin.com/in/julianeagu/",
    "Blog": "https://blog.quotientai.co",
    "Profile Picture": "https://sessionize.com/image/8209-400o400o1-4YzMawHbhpq483ah1puTk5.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "913839",
        "Title": "Evaluating AI Search: A Practical Framework for Augmented AI Systems",
        "Description": "AI search is becoming the front door to information, whether through Retrieval-Augmented Generation (RAG), Search-Augmented Generation (SAG), or custom agents that synthesize answers on top of indexed content. As users rely more heavily on these systems, evaluating their quality becomes mission-critical. But traditional metrics like precision and recall don‚Äôt capture the full picture.\r\n\r\nIn this talk, we introduce a practical evaluation framework for AI-powered search, across three dimensions:\r\n- Are the retrieved sources relevant to the query?\r\n- And is the final answer complete?\r\n- Are the sources faithfully used in the generated answer?\r\n\r\nWe‚Äôll share lessons from working with search companies and present early findings from a new benchmark evaluating popular augmented AI systems across these dimensions. Rather than ranking winners and losers, we explore where different systems excel or break down, and how these tradeoffs inform product decisions.\r\n\r\nThis talk is for AI engineers and product teams who want to build trusted, high-quality AI search experiences, and need a way to measure if it‚Äôs actually working.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "Golden Gate Ballroom A: Retrieval + Search",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "854869f9-a386-4aab-b82d-18cae7cb2edb",
    "Name": "Deanna Emery",
    "Company": "Quotient AI",
    "Company Domain": "quotientai.co",
    "Company URL": "https://www.quotientai.co/",
    "Company Website": "https://www.quotientai.co/",
    "Title": "Founding AI Researcher",
    "TagLine": "Founding AI Researcher",
    "Bio": "Deanna is the Founding AI Researcher at Quotient AI, where she is leading research on evaluation of Large Language Models in real-world products and applications. Before Quotient, Deanna was a Principal Data Scientist at Aon, where she led the team building language models for valuation of intellectual property assets. She began her career as a researcher at Harvard-Smithsonian Center for Astrophysics and Caltech LIGO. Deanna has a MS in Machine Learning from UC Berkeley and BA in Physics from Harvard University. She is passionate about diversity and inclusion in STEM; she has conducted research on diversity in named patent inventors, working with companies to measure and address diversity gaps, and she is an active board member at a STEM education non-profit.",
    "X (Twitter)": "https://x.com/DeannaLEmery",
    "LinkedIn": "https://www.linkedin.com/in/deanna-emery/",
    "Blog": "https://blog.quotientai.co/",
    "Profile Picture": "https://sessionize.com/image/2da3-400o400o1-G2BZr4Vp16J2uGz7DrPhBj.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "913839",
        "Title": "Evaluating AI Search: A Practical Framework for Augmented AI Systems",
        "Description": "AI search is becoming the front door to information, whether through Retrieval-Augmented Generation (RAG), Search-Augmented Generation (SAG), or custom agents that synthesize answers on top of indexed content. As users rely more heavily on these systems, evaluating their quality becomes mission-critical. But traditional metrics like precision and recall don‚Äôt capture the full picture.\r\n\r\nIn this talk, we introduce a practical evaluation framework for AI-powered search, across three dimensions:\r\n- Are the retrieved sources relevant to the query?\r\n- And is the final answer complete?\r\n- Are the sources faithfully used in the generated answer?\r\n\r\nWe‚Äôll share lessons from working with search companies and present early findings from a new benchmark evaluating popular augmented AI systems across these dimensions. Rather than ranking winners and losers, we explore where different systems excel or break down, and how these tradeoffs inform product decisions.\r\n\r\nThis talk is for AI engineers and product teams who want to build trusted, high-quality AI search experiences, and need a way to measure if it‚Äôs actually working.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "Golden Gate Ballroom A: Retrieval + Search",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "9380b4fb-a3cf-4e21-86fe-27432cf4a426",
    "Name": "Maitar Asher",
    "Company": "Tavily",
    "Company Domain": "tavily.com",
    "Company URL": "https://tavily.com",
    "Company Website": "",
    "Title": "Head of Engineering",
    "TagLine": "Head of Engineering",
    "Bio": "Maitar Asher is a founding member and Head of Engineering at Tavily, a New York‚Äìbased startup developing a web infrastructure layer for AI agents. \r\n\r\nShe leads the technology build and has architected core systems‚Äîincluding Tavily‚Äôs intelligent caching layer and enhanced search retrieval‚Äîto power the industry‚Äôs premier search engine for large language models.\r\n\r\nPrior to Tavily, she developed deep learning tools for PET/CT image segmentation as a Machine Learning Research Engineer at Stanford University. She holds a B.S. in Computer Science (Machine Learning) from Columbia University.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/maitar-a-b48197218/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/b38d-400o400o1-XQqMy4CnJxWLTBpFJgw8yY.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "913839",
        "Title": "Evaluating AI Search: A Practical Framework for Augmented AI Systems",
        "Description": "AI search is becoming the front door to information, whether through Retrieval-Augmented Generation (RAG), Search-Augmented Generation (SAG), or custom agents that synthesize answers on top of indexed content. As users rely more heavily on these systems, evaluating their quality becomes mission-critical. But traditional metrics like precision and recall don‚Äôt capture the full picture.\r\n\r\nIn this talk, we introduce a practical evaluation framework for AI-powered search, across three dimensions:\r\n- Are the retrieved sources relevant to the query?\r\n- And is the final answer complete?\r\n- Are the sources faithfully used in the generated answer?\r\n\r\nWe‚Äôll share lessons from working with search companies and present early findings from a new benchmark evaluating popular augmented AI systems across these dimensions. Rather than ranking winners and losers, we explore where different systems excel or break down, and how these tradeoffs inform product decisions.\r\n\r\nThis talk is for AI engineers and product teams who want to build trusted, high-quality AI search experiences, and need a way to measure if it‚Äôs actually working.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "Golden Gate Ballroom A: Retrieval + Search",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "219b4939-2990-4c4e-9c88-75228cd526df",
    "Name": "Shafik Quoraishee",
    "Company": "New York Times",
    "Company Domain": "nytimes.com",
    "Company URL": "https://www.nytimes.com/",
    "Company Website": "https://www.nytimes.com/",
    "Title": "Senior Android Games Engineer",
    "TagLine": "AI Game Engineer",
    "Bio": "I'm currently a Senior Android Games Engineer that works on the New York Times Games Team, working on the integration of games such as Wordle, Connections and the NYT Crossword, into the NYT Games Android App.\r\n\r\nI am also an A.I. enthusiast and practitioner with multiple years experience in the field and published research that has been deployed across  real world systems with both civilian to government applications.\r\n\r\nLinked In: https://www.linkedin.com/in/shafik-quoraishee/",
    "X (Twitter)": "https://x.com/SQuoraishee",
    "LinkedIn": "https://www.linkedin.com/in/shafik-quoraishee/",
    "Blog": "https://squoraishee.medium.com/",
    "Profile Picture": "https://sessionize.com/image/2b7d-400o400o1-RDsnvc2VDuvTZ43uXaXrhN.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914361",
        "Title": "AI and Game Theory: A Case Study on NYT's Connections",
        "Description": "This session will examine the interplay between human intuition and artificial intelligence in puzzle-solving, using the popular New York Times Connections game as a practical case study. \r\n\r\nWe'll investigate how gameplay can be systematically evaluated through AI algorithms, exploring machine learning strategies such as clustering, semantic mapping, and natural language processing. \r\n\r\nAttendees will gain insights into building AI-driven puzzle solvers, learn methods for quantitatively assessing gameplay complexity, and discuss the potential impacts of AI on puzzle game design and player engagement.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Design Engineering",
        "Room": "Foothill G 1&2: Design Engineering",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "b200b3d5-c4a6-4a23-a09c-669b6f6f805a",
    "Name": "Yegor Denisov-Blanch",
    "Company": "Stanford University",
    "Company Domain": "stanford.edu",
    "Company URL": "",
    "Company Website": "https://yegordb.com/",
    "Title": "Researcher",
    "TagLine": "Developer Productivity Researcher at Stanford University",
    "Bio": "Researcher at Stanford University researching all things developer productivity",
    "X (Twitter)": "https://x.com/elonmusk/status/1859481348466942061",
    "LinkedIn": "https://www.linkedin.com/in/ydenisov/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/46bb-400o400o1-Xi3CX4ELMLBFpP6ijXhxub.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914912",
        "Title": "Does AI Actually Boost Developer Productivity? (Stanford / 100k Devs Study)",
        "Description": "Forget vendor hype: Is AI actually boosting developer productivity, or just shifting bottlenecks? Stop guessing.\r\n\r\nOur study at Stanford cuts through the noise, analyzing real-world productivity data from nearly 100,000 developers across hundreds of companies. We reveal the hard numbers: while the average productivity boost is significant (~20%), the reality is complex ‚Äì some teams even see productivity decrease with AI adoption.\r\n\r\nThe crucial insights lie in why this variance occurs. Discover which company types, industries, and tech stacks achieve dramatic gains versus minimal impact (or worse). Leave with the objective, data-driven evidence needed to build a winning AI strategy tailored to your context, not just follow the trend.\r\n",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Leadership: Architects",
        "Room": "SOMA: AI Architects",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "9dc819a3-58dc-4487-82a6-e178f36d9cec",
    "Name": "Simon Obstbaum",
    "Company": "YOPESO",
    "Company Domain": "obstbaum.eu",
    "Company URL": "",
    "Company Website": "",
    "Title": "Founder",
    "TagLine": "Researcher, former CTO @ Crunchyroll",
    "Bio": "Since 2020 I‚Äôve turned to my passion: researching software engineering productivity. \r\n\r\nBefore this, I served as CTO at Crunchyroll, where I led the engineering team through rapid subscriber and team growth, transitioning from a data center monolith to a microservice-based cloud architecture. Crunchyroll itself was acquired by AT&T/WarnerMedia and later by Sony in a $1.2 billion deal.\r\n\r\nOriginally founded YOPESO in 2005, growing it to hundreds of engineers across the US, Europe, and Asia. ",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/simonobstbaum/",
    "Blog": "https://obstbaum.eu",
    "Profile Picture": "https://sessionize.com/image/a6b0-400o400o1-WcbRBA54BanaXhuFz1HJgf.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914912",
        "Title": "Does AI Actually Boost Developer Productivity? (Stanford / 100k Devs Study)",
        "Description": "Forget vendor hype: Is AI actually boosting developer productivity, or just shifting bottlenecks? Stop guessing.\r\n\r\nOur study at Stanford cuts through the noise, analyzing real-world productivity data from nearly 100,000 developers across hundreds of companies. We reveal the hard numbers: while the average productivity boost is significant (~20%), the reality is complex ‚Äì some teams even see productivity decrease with AI adoption.\r\n\r\nThe crucial insights lie in why this variance occurs. Discover which company types, industries, and tech stacks achieve dramatic gains versus minimal impact (or worse). Leave with the objective, data-driven evidence needed to build a winning AI strategy tailored to your context, not just follow the trend.\r\n",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Leadership: Architects",
        "Room": "SOMA: AI Architects",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "5154a162-47d1-4c47-9cd7-f185140e7cf5",
    "Name": "Anish Agarwal",
    "Company": "Traversal",
    "Company Domain": "traversal.com",
    "Company URL": "https://traversal.com/",
    "Company Website": "https://www.traversal.com",
    "Title": "CEO and Co-founder",
    "TagLine": "CEO and Co-founder",
    "Bio": "Anish Agrawal is the CEO and Co-founder of Traversal, where he and his team are revolutionizing observability and troubleshooting with AI Agents. A Professor of Computer Science and Operations Research at Columbia University, Anish earned his PhD in Computer Science from MIT, specializing in causal machine learning‚Äîteaching AI to understand cause and effect from data. Despite achieving his goal of becoming a professor,  Anish pivoted from academia, recognizing a once-in-a-lifetime opportunity to apply his AI research to tackle the industry‚Äôs toughest challenges, with autonomous troubleshooting at the forefront. His career also includes roles as a management consultant at BCG and research scientist at Amazon and Microsoft Research.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/anish-agarwal-io/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/f403-400o400o1-aztUHtnrKs7FM8kqdhLAX5.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915312",
        "Title": "Production software keeps breaking and it will only get worse.  Here‚Äôs how Traversal is fixing it.",
        "Description": "Software is eating the world. AI is eating software. AI-powered SWE means a whole lot more software is going to be written that powers mission critical systems in the coming years, with hardly any of it written by humans. Hence, when these software systems inevitably break, it‚Äôs going to be next to impossible to troubleshoot them. Towards addressing this issue, we‚Äôll do a product launch of Traversal‚Äôs AI, a significant step towards self-healing software systems. We will showcase how it is already used to autonomously troubleshoot production incidents in some of the most complex enterprise environments.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Product launch",
        "Tracks": "SWE Agents",
        "Room": "Yerba Buena Ballroom 7&8: SWE Agents",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "57c7e83f-4c1b-46ee-9f5a-f231d7eddd90",
    "Name": "Matthew Schoenbauer",
    "Company": "Traversal",
    "Company Domain": "traversal.com",
    "Company URL": "https://traversal.com/",
    "Company Website": "",
    "Title": "Founding Engineer",
    "TagLine": "Founding Engineer",
    "Bio": "Matt Schoenbauer is a founding engineer at Traversal, where he and his team are redefining observability and troubleshooting with AI agents. Previously, he was a systematic trader at Citadel Securities, operating at the core of the world‚Äôs largest equities market-making platform, where live troubleshooting in the Linux terminal was a critical part of his work. Before that, he worked in quantitative research at Proof Trading. Matt has published research across cryptography, number theory, and algebraic topology, and holds a master‚Äôs degree from Columbia University, where he focused on machine learning systems and causal machine learning.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/matthew-schoenbauer-353180157/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/53a2-400o400o1-J8kvvUEzwc4DGRUJSTBuzr.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915312",
        "Title": "Production software keeps breaking and it will only get worse.  Here‚Äôs how Traversal is fixing it.",
        "Description": "Software is eating the world. AI is eating software. AI-powered SWE means a whole lot more software is going to be written that powers mission critical systems in the coming years, with hardly any of it written by humans. Hence, when these software systems inevitably break, it‚Äôs going to be next to impossible to troubleshoot them. Towards addressing this issue, we‚Äôll do a product launch of Traversal‚Äôs AI, a significant step towards self-healing software systems. We will showcase how it is already used to autonomously troubleshoot production incidents in some of the most complex enterprise environments.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Product launch",
        "Tracks": "SWE Agents",
        "Room": "Yerba Buena Ballroom 7&8: SWE Agents",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "431907d7-ade9-4bba-aebe-173770b772cd",
    "Name": "Raj Agrawal",
    "Company": "Traversal",
    "Company Domain": "traversal.com",
    "Company URL": "https://traversal.com/",
    "Company Website": "",
    "Title": "CTO, Cofounder",
    "TagLine": "CTO,  Cofounder",
    "Bio": "CTO,  Cofounder of Traversal.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/7c40-400o400o1-nsFrh2AwXLtDdeUmZQg9P8.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915312",
        "Title": "Production software keeps breaking and it will only get worse.  Here‚Äôs how Traversal is fixing it.",
        "Description": "Software is eating the world. AI is eating software. AI-powered SWE means a whole lot more software is going to be written that powers mission critical systems in the coming years, with hardly any of it written by humans. Hence, when these software systems inevitably break, it‚Äôs going to be next to impossible to troubleshoot them. Towards addressing this issue, we‚Äôll do a product launch of Traversal‚Äôs AI, a significant step towards self-healing software systems. We will showcase how it is already used to autonomously troubleshoot production incidents in some of the most complex enterprise environments.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Product launch",
        "Tracks": "SWE Agents",
        "Room": "Yerba Buena Ballroom 7&8: SWE Agents",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "1b3e98d3-0b37-4945-8ad4-8eac22ba15ed",
    "Name": "Raaz Dwivedi",
    "Company": "Traversal",
    "Company Domain": "interactionlabs.ai",
    "Company URL": "https://traversal.com/",
    "Company Website": "https://traversal.com/",
    "Title": "Chief Scientist and Co-founder",
    "TagLine": "Chief Scientist",
    "Bio": "Raaz Dwivedi is the Chief Scientist and a co-founder of Traversal. In the last year and a half, Traversal has been building an autonomous AI system, using AI agents, LLMs, and causal machine learning for root causing production incidents. Raaz is an AI researcher by training and in the past decade has built efficient decision-making systems using causal machine learning and reinforcement learning as an Assistant Professor at Cornell Tech, as a Postdoc at Harvard and MIT, and as a PhD student at UC Berkeley. His work has won him several research and teaching awards.\r\n",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/raaz-dwivedi/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/5c30-400o400o1-rs6aD9hYBxwsaGANJgtKtb.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915312",
        "Title": "Production software keeps breaking and it will only get worse.  Here‚Äôs how Traversal is fixing it.",
        "Description": "Software is eating the world. AI is eating software. AI-powered SWE means a whole lot more software is going to be written that powers mission critical systems in the coming years, with hardly any of it written by humans. Hence, when these software systems inevitably break, it‚Äôs going to be next to impossible to troubleshoot them. Towards addressing this issue, we‚Äôll do a product launch of Traversal‚Äôs AI, a significant step towards self-healing software systems. We will showcase how it is already used to autonomously troubleshoot production incidents in some of the most complex enterprise environments.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Product launch",
        "Tracks": "SWE Agents",
        "Room": "Yerba Buena Ballroom 7&8: SWE Agents",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "a4f09d20-4ee3-4b43-9f2e-9afac1a1b96b",
    "Name": "Misha  Laskin",
    "Company": "Reflection",
    "Company Domain": "reflection.ai",
    "Company URL": "https://www.reflection.ai/",
    "Company Website": "https://www.reflection.ai/",
    "Title": "CEO",
    "TagLine": "CEO & co-founder",
    "Bio": "Misha Laskin is the co-founder and CEO of Reflection AI, a company building superintelligent coding agents. He was formerly a staff research scientist at Google DeepMind, where he worked on the Gemini RL team.",
    "X (Twitter)": "https://x.com/MishaLaskin",
    "LinkedIn": "https://www.linkedin.com/in/mishalaskin/",
    "Blog": "https://www.reflection.ai/superintelligence/",
    "Profile Picture": "https://sessionize.com/image/6313-400o400o1-GnZFh6GscoxV8XhnTNgHXT.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915745",
        "Title": "Post-Training Open Models with RL for Autonomous Coding",
        "Description": "The models and techniques to build fully autonomous coding agents - not just coding copilots - are already here. In this talk, former Google DeepMind staff research scientist, now CEO of Reflection Misha Laskin will present new research on post-training open weight LLMs for autonomous SWE tasks. He‚Äôll focus on how scaling LLMs with Reinforcement Learning improves the autonomous coding capabilities of LLMs, and provide insight on the technical challenges required to train such systems at scale. ",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "SWE Agents",
        "Room": "Yerba Buena Ballroom 2-6: Reasoning + RL",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "cf3e1c15-0b38-4e11-b24d-e94b852f9789",
    "Name": "Tejas Rajurkar",
    "Company": "AMGI Studios",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.amgistudios.com/",
    "Company Website": "https://www.amgistudios.com/",
    "Title": "Artificial Intelligence Engineer",
    "TagLine": "AI Engineer Lead, AMGI Studios",
    "Bio": "Tejas Rajurkar is an Artificial Intelligence Engineer with a specialized focus on enhancing human-computer interaction through the integration of AI technologies with animation and interactive media. His work emphasizes the development of emotionally responsive, real-time AI characters by leveraging large language models (LLMs), computer vision for emotion recognition, and neural animation systems.\r\n\r\nMr. Rajurkar previously conducted research at the University of Southern California, where he focused on computer vision systems aimed at environmental monitoring and behavioral analysis. His research explored the extraction of patterns and contextual understanding from visual data in dynamic, real-world environments. He further applied these capabilities in industry at Dragonfruit AI, where he was responsible for optimizing scalable video analytics pipelines used in retail and enterprise surveillance systems.\r\n\r\nIn his current role at AMGI Studios, Mr. Rajurkar leads initiatives at the intersection of generative AI, real-time animation, and cloud infrastructure, driving innovation in how AI agents perceive, interact, and express emotion in digital environments.\r\n\r\nIn addition to his engineering contributions, he has led technical seminars and discussions at USC and has instructed students in the foundational principles of machine learning and artificial intelligence, actively contributing to the education of future AI professionals.\r\n",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/tejasrajurkar/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/3a0a-400o400o1-3FxKy3UB6gFvNtABXJDjor.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915950",
        "Title": "LLMs Come Alive: Breathing Life into LLMs with Real-Time Animation",
        "Description": "Creating AI agents that communicate naturally requires more than advanced language models‚Äîit demands believable, real-time animation that feels alive. While conversational agents excel at generating text, synchronizing expressive, Disney-level animation with real-time emotional feedback remains largely unexplored. To bridge this gap, we developed a multimodal AI architecture capable of driving real-time character animation directly from conversational context, vision-based emotion detection, and dynamically updated user profiles.\r\nIn this session, we'll share our technical journey and engineering decisions, covering:\r\n\r\nReal-Time Neural-driven Animation Pipeline: Translating LLM-generated responses into precise visemes, gestures, and expressions using a transformer-based controller, guided \r\ndynamically by lightweight vision models capturing user emotions.\r\n\r\nFlexible, Provider-Agnostic LLM Integration: Using LangChain orchestration to dynamically switch between local models, AWS Bedrock, OpenAI APIs, or private deployments‚Äîcarefully balancing latency, capability, and cost trade-offs.\r\n\r\nHybrid Memory & User Profile Engine: Architecting a GDPR-compliant user profile system combining structured (SQL) and unstructured (NoSQL) data, gathering user interactions and preferences for sub-10 ms personalization lookups that dynamically influence conversations and animation.\r\n\r\nScalable, Secure Serverless Infrastructure: Docker-based deployment on AWS ECS with OAuth-secured REST APIs, optimized for auto-scaling to seamlessly handle thousands of concurrent interactions.\r\n\r\nWe'll present practical benchmarks, actionable heuristics (\"async memory prefetch,\" \"prompt-tuning vs. LoRA for personalization\"), and lessons learned. Attendees will walk away with a playbook for adapting open models into hyper‚Äëpersonalized, scalable roleplay experiences.\r\n",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Generative Media",
        "Room": "Foothill F: Generative Media",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "f328e41f-bdf7-47a1-a148-e31907578835",
    "Name": "Colin Brady",
    "Company": "AMGI Studios",
    "Company Domain": "amgistudios.com",
    "Company URL": "",
    "Company Website": "Https://Amgistudios.com",
    "Title": "Chief Creative and Technology Officer",
    "TagLine": "Chief Creative and Technology Officer, Member, Academy of Motion Picture Arts and Sciences",
    "Bio": "Profile: Colin Brady\r\n\r\nColin Brady is the Chief Creative and Technology Officer at AMGI Studios and a graduate of the California Institute of the Arts (CalArts). With a career spanning three decades, his credits include Toy Story, Toy Story 2, A Bug‚Äôs Life, Men in Black II, Hugo, The Hunger Games, and Lemony Snicket‚Äôs A Series of Unfortunate Events. He has held key creative roles at leading studios such as Pixar and Industrial Light & Magic, contributing to some of the most influential animated and visual effects-driven films of the modern era.\r\n\r\nIn addition to his film work, Colin is a pioneer in real-time animation and AI-assisted storytelling. He holds several patents in animation technology and co-founded AMGI Studios to explore the intersection of cutting-edge tools and creative expression. His focus is on building intuitive, performance-driven animation systems that empower artists to work at the speed of imagination, bringing storytelling into a new era of immediacy and innovation.",
    "X (Twitter)": "https://x.com/colin_a_brady?s=21&t=Uj3As5339A347nd3if838w",
    "LinkedIn": "https://www.linkedin.com/in/colin-brady-1441312?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=ios_app",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/bf05-400o400o1-f8K89Uek7iT6Me4iWLTrgm.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915950",
        "Title": "LLMs Come Alive: Breathing Life into LLMs with Real-Time Animation",
        "Description": "Creating AI agents that communicate naturally requires more than advanced language models‚Äîit demands believable, real-time animation that feels alive. While conversational agents excel at generating text, synchronizing expressive, Disney-level animation with real-time emotional feedback remains largely unexplored. To bridge this gap, we developed a multimodal AI architecture capable of driving real-time character animation directly from conversational context, vision-based emotion detection, and dynamically updated user profiles.\r\nIn this session, we'll share our technical journey and engineering decisions, covering:\r\n\r\nReal-Time Neural-driven Animation Pipeline: Translating LLM-generated responses into precise visemes, gestures, and expressions using a transformer-based controller, guided \r\ndynamically by lightweight vision models capturing user emotions.\r\n\r\nFlexible, Provider-Agnostic LLM Integration: Using LangChain orchestration to dynamically switch between local models, AWS Bedrock, OpenAI APIs, or private deployments‚Äîcarefully balancing latency, capability, and cost trade-offs.\r\n\r\nHybrid Memory & User Profile Engine: Architecting a GDPR-compliant user profile system combining structured (SQL) and unstructured (NoSQL) data, gathering user interactions and preferences for sub-10 ms personalization lookups that dynamically influence conversations and animation.\r\n\r\nScalable, Secure Serverless Infrastructure: Docker-based deployment on AWS ECS with OAuth-secured REST APIs, optimized for auto-scaling to seamlessly handle thousands of concurrent interactions.\r\n\r\nWe'll present practical benchmarks, actionable heuristics (\"async memory prefetch,\" \"prompt-tuning vs. LoRA for personalization\"), and lessons learned. Attendees will walk away with a playbook for adapting open models into hyper‚Äëpersonalized, scalable roleplay experiences.\r\n",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Generative Media",
        "Room": "Foothill F: Generative Media",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "a5eaab61-2879-4f57-a709-62c7e7562ea6",
    "Name": "Leonard Tang",
    "Company": "Haize Labs",
    "Company Domain": "haizelabs.com",
    "Company URL": "https://www.haizelabs.com/",
    "Company Website": "https://haizelabs.com/",
    "Title": "Co-founder and CEO",
    "TagLine": "Founder & CEO",
    "Bio": "I  the co-founder and CEO of Haize Labs, where we are solving the ultimate extant problem in AI: ensuring its reliability, quality, and alignment for any application. You might also know of us for our red-teaming work.\r\n\r\nPrior, I studied math and computer science at Harvard. My research then covered adversarial robustness, math reasoning, computational neuroscience, interpretability, and large(-ish) language models. Much of that has now been distilled into the Haize technology agenda. I also dropped out of, before starting, a Stanford PhD in computer science.\r\n\r\nIn the limit of my life, I am chiefly invested in starting Bell Labs 2.0.",
    "X (Twitter)": "https://twitter.com/leonardtang_",
    "LinkedIn": "https://linkedin.com/in/leonardtang",
    "Blog": "https://leonardtang.me/",
    "Profile Picture": "https://sessionize.com/image/444b-400o400o1-SHYqN26nGnPTjHAE6QVgy5.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915978",
        "Title": "Fuzzing in the GenAI Era",
        "Description": "\"Evaluation\" is one of those concepts that every AI practitioner vaguely knows is important, but few practitioners truly understand. Is \"eval\" the dataset for measuring the quality of your AI system? Is \"eval\" the measure, the metric of quality? Is \"eval\" the process of human annotation and scoring? Or is \"eval\" a third-party dataset run once to benchmark a model?\r\n\r\nTo mitigate this cacophony, this talk will provide an opinionated and principled perspective for what we actually mean when we say ‚Äúevaluation‚Äù, beyond the traditional for-loop-over-a-static dataset. \r\n\r\nIn particular, this perspective draws heavy inspiration from *fuzzing*, i.e. bombarding AI with simulated, unexpected user inputs to uncover corner cases at scale. This factors into sub-problems regarding:\r\n\r\n- Quality Metric. What is the actual criteria we, as humans, are using to determine if an AI system is producing good or bad responses? How do we elicit these criteria before the human SME can articulate them? How do we, as efficiently as possible, operationalize this criteria with an automated *Judge*?\r\n\r\n- Stimuli Generation. Given a metric, how do we know, with confidence, that an AI system is performing well with respect to the metric? What data is representative and sufficient for discovering all potential bugs of an AI system? And how do we generate this complex, diverse, faithful data at scale? \r\n\r\nWe will discuss in detail the philosophy, technology, and case studies behind both problems of Quality Metric and Stimuli Generation, and how they interact in concert.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Security",
        "Room": "Foothill C: Security",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "98dc110d-5a68-453b-b1cc-8bba6f70ba6a",
    "Name": "Jaspreet Singh",
    "Company": "Intuit",
    "Company Domain": "gmail.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "Senior Staff Software Engineer",
    "TagLine": "Senior Staff Software Engineer",
    "Bio": "I‚Äôm Jaspreet Singh, a Senior Staff Software Engineer with 12 years of experience in the tech industry. I am the tech lead for the Smart Turbotax AI team at Intuit - focusing on development of new GenAI powered experiences in Intuit Turbotax. I have worked extensively on Personalization and Recommendations problems in the past and I‚Äôm very passionate about bringing the latest in AI to help drive Taxes are done experiences for our users. I recently became a father for the first time, and enjoy spending time with my little one. As a speaker at the AI Engineer World‚Äôs Fair, I‚Äôm excited to share our journey of transforming our user‚Äôs tax filing journeys with the power of Gen AI..",
    "X (Twitter)": "https://x.com/singh_jp",
    "LinkedIn": "https://www.linkedin.com/in/jpsingh1",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/aca7-400o400o1-JvNiKdDRX2bwTvQy7Uyzhi.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916085",
        "Title": "How Intuit uses LLMs to explain taxes to millions of taxpayers",
        "Description": "I will talk about how Intuit uses LLMs to explain tax situations to Turbotax users.\r\nUsers want explanations of their tax situations - this drives confidence in the product. Over the course of last two tax years, Intuit has built out explanations using Anthropic and openAI‚Äôs models to develop genAI powered explanations. This includes design a complex system with prompt engineered solutions and both LLM & human powered evaluations to ensure high quality bar that our users expect when filing taxes with us.\r\nDuring the course of my talk, I will talk across GenAI development lifecycle at scale - including development , evaluations and scaling. And security evaluations. We also developed a fine-tuned version of Claude Haiku & shall be covering that in the presentation.\r\nWe also expanded into tax question and answering powered by RAG, including graphRAG and I would be covering those developments too.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Fortune 500",
        "Room": "Golden Gate Ballroom C: AI in the Fortune 500",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "a7f032d8-e2b0-4ca5-989d-820575b736d6",
    "Name": "Annika Brundyn",
    "Company": "NVIDIA",
    "Company Domain": "nvidia.com",
    "Company URL": "",
    "Company Website": "https://www.nvidia.com/en-us/",
    "Title": "Senior Solutions Architect",
    "TagLine": "GenAI Architect",
    "Bio": "Annika Brundyn is a Senior Solutions Architect at NVIDIA focused on deploying generative AI systems in the real world. She works at the intersection of inference infrastructure, reasoning models, and retrieval pipelines, and has contributed to flagship projects like NVIDIA‚Äôs NeMo Retriever and the GR00T vision-language-action model. Her experience spans frontier model research and enterprise-grade deployment. She spends a lot of time helping models make fewer ‚Äúcreative‚Äù mistakes in production.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/annikabrundyn",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/80ac-400o400o1-JJGDuN81u6KSFdmYWRYLxm.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916103",
        "Title": "What Is a Humanoid Foundation Model? An Introduction to GR00T N1",
        "Description": "Foundation models don‚Äôt just write or draw anymore‚Äîthey‚Äôre starting to move.\r\n\r\nGR00T N1 is NVIDIA‚Äôs open Vision-Language-Action (VLA) foundation model for humanoid robots. Built with a dual-system architecture, it combines a System 2 module for high-level reasoning with a System 1 module for real-time, fluid motor control. It‚Äôs trained end-to-end on a an impressive mix of data‚Äîfrom human videos to robot trajectories to synthetic simulations‚Äîand deployed on a full-sized humanoid robot performing bimanual manipulation tasks in the real world.\r\nThis talk is a high-level, beginner-friendly overview of GR00T N1:\r\n- What makes a robot foundation model different from an LLM or vision model\r\n- How GR00T‚Äôs architecture is inspired by cognitive systems\r\n- Why grounding language, vision, and action together unlocks new generalist capabilities\r\n\r\nIf you‚Äôve ever wondered how large-scale AI is crossing over into the physical world, this session will get you up to speed‚Äîno robotics PhD required.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Autonomy+Robotics",
        "Room": "Foothill E: Autonomy + Robotics",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "85704f37-4b3d-47ef-9a67-f5cd637f6f9f",
    "Name": "Aastha Jhunjhunwala",
    "Company": "NVIDIA",
    "Company Domain": "nvidia.com",
    "Company URL": "",
    "Company Website": "https://www.nvidia.com/en-us/",
    "Title": "Solutions Architect",
    "TagLine": "Solutions Architect",
    "Bio": "Aastha Jhunjhunwala is a Solutions Architect at NVIDIA, focused on building optimized generative AI applications across industries. She works at the intersection of large-scale LLM pretraining, large language model inference, and NVIDIA‚Äôs full-stack generative AI infrastructure. Aastha has helped enterprises scale LLM workflows‚Äîfrom training models with billions of parameters to serving them efficiently with high-throughput inference. When she‚Äôs not working with language models, you‚Äôll find her deep in the mountains, trading tokens for trail markers.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/307b-400o400o1-V4tq6YkdtFNb2REDEHG7vc.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916103",
        "Title": "What Is a Humanoid Foundation Model? An Introduction to GR00T N1",
        "Description": "Foundation models don‚Äôt just write or draw anymore‚Äîthey‚Äôre starting to move.\r\n\r\nGR00T N1 is NVIDIA‚Äôs open Vision-Language-Action (VLA) foundation model for humanoid robots. Built with a dual-system architecture, it combines a System 2 module for high-level reasoning with a System 1 module for real-time, fluid motor control. It‚Äôs trained end-to-end on a an impressive mix of data‚Äîfrom human videos to robot trajectories to synthetic simulations‚Äîand deployed on a full-sized humanoid robot performing bimanual manipulation tasks in the real world.\r\nThis talk is a high-level, beginner-friendly overview of GR00T N1:\r\n- What makes a robot foundation model different from an LLM or vision model\r\n- How GR00T‚Äôs architecture is inspired by cognitive systems\r\n- Why grounding language, vision, and action together unlocks new generalist capabilities\r\n\r\nIf you‚Äôve ever wondered how large-scale AI is crossing over into the physical world, this session will get you up to speed‚Äîno robotics PhD required.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Autonomy+Robotics",
        "Room": "Foothill E: Autonomy + Robotics",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "59e622be-92dc-41b8-b8a5-b5a541cdff17",
    "Name": "Jeff Huber",
    "Company": "Chroma",
    "Company Domain": "trychroma.com",
    "Company URL": "https://www.trychroma.com/",
    "Company Website": "https://www.trychroma.com/",
    "Title": "CEO and cofounder",
    "TagLine": "CEO",
    "Bio": "Jeff Huber is the CEO and cofounder of Chroma. Jeff's work has been featured in TechCrunch, VentureBeat, MacWorld, GQ, Fast Company, Fortune, Forbes, Business Insider, Quartz and others. Chroma is a widely-loved and adopted open-source vector database.",
    "X (Twitter)": "https://twitter.com/jeffreyhuber",
    "LinkedIn": "https://www.linkedin.com/in/jeffchuber/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/34f2-400o400o1-rnYjraDKkutyWWRmMgtkLP.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916104",
        "Title": "How to look at your data; what to look for, how to measure",
        "Description": "By the end of this talk, you'll understand what it takes to apply clustering techniques and data analysis to understand what is the valuable work that your AI application is doing through analyzing conversation histories and how to create generative evals to benchmark your newly discovered superpowers. ",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Case Study/War Story",
        "Tracks": "Evals",
        "Room": "Golden Gate Ballroom B: Evals",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "c8042607-1aa2-4286-9a44-e8f44c0ad616",
    "Name": "Jason Liu",
    "Company": "567 Studio",
    "Company Domain": "jxnl.co",
    "Company URL": "",
    "Company Website": "",
    "Title": "Machine Learning Engineer",
    "TagLine": "Principal",
    "Bio": "Machine learning engineer, consultant, educator. ",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/a19c-400o400o1-s99sCKoyTQHKYLtEdFttto.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916104",
        "Title": "How to look at your data; what to look for, how to measure",
        "Description": "By the end of this talk, you'll understand what it takes to apply clustering techniques and data analysis to understand what is the valuable work that your AI application is doing through analyzing conversation histories and how to create generative evals to benchmark your newly discovered superpowers. ",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Case Study/War Story",
        "Tracks": "Evals",
        "Room": "Golden Gate Ballroom B: Evals",
        "Scheduled At": "5 Jun 2025 12:05 PM"
      }
    ]
  },
  {
    "Speaker ID": "941f74d4-9bd6-47f8-b20c-28895e05e826",
    "Name": "David Mytton",
    "Company": "Arcjet",
    "Company Domain": "arcjet.com",
    "Company URL": "https://arcjet.com/",
    "Company Website": "https://arcjet.com",
    "Title": "Founder",
    "TagLine": "Founder",
    "Bio": "David is the founder of Arcjet, a security as code product that helps developers protect their apps from bots, API abuse, spam, and other attacks. He also writes the weekly console.dev devtools newsletter.",
    "X (Twitter)": "https://x.com/davidmytton",
    "LinkedIn": "https://www.linkedin.com/in/davidmytton/",
    "Blog": "https://davidmytton.blog",
    "Profile Picture": "https://sessionize.com/image/167b-400o400o1-3Xa6zGGMPkfYqAwBCE8ne5.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "913351",
        "Title": "How to defend your sites from AI bots",
        "Description": "Constantly seeing CAPTCHAs? It used to be easy to detect the humans from the droids, but what else can we do when synthetic clients make up nearly half of all web requests. Rotating IPs, spoofed browsers, and agents acting on behalf of real users - are we doomed to forever be solving puzzles?\r\n\r\nIn this talk, we‚Äôll explore user agents, HTTP fingerprints, and IP reputation signals that make humans and agents stand out from scrapers, build a realistic threat model, and dig into the behaviors that reveal the LLM-mimicry. Leave with AX- and UX-safe code, benchmarks, and tools to help you take back control.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Security",
        "Room": "Foothill C: Security",
        "Scheduled At": "5 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "ccf69e35-16bc-4f6d-8b5c-79d4b374eb1f",
    "Name": "Josh Albrecht",
    "Company": "Imbue",
    "Company Domain": "imbue.ai",
    "Company URL": "https://imbue.com/",
    "Company Website": "https://imbue.com/",
    "Title": "CTO and Co-founder",
    "TagLine": "CTO and Co-founder",
    "Bio": "Josh Albrecht is CTO and Co-founder of Imbue, an AI lab launched in 2022 that has since raised $230M at a $1B valuation to create coding agents that make it easier for more people to write software. Josh is also a partner at angel fund Outset Capital, where he invests in promising pre-seed companies. Previously, Josh founded multiple companies including an AI recruiting startup that went through Y Combinator and a 3D injection molding software company that was acquired. He was also an early engineer at Addepar, served as a Thiel Fellow mentor, and published machine learning research as an academic researcher. ",
    "X (Twitter)": "https://x.com/joshalbrecht",
    "LinkedIn": "https://www.linkedin.com/in/joshalbrecht/",
    "Blog": "https://joshalbrecht.com/",
    "Profile Picture": "https://sessionize.com/image/47d9-400o400o1-fhsDJ9SBoUuiAy5EZxX6pZ.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914017",
        "Title": "Beyond the Prototype: Using AI to Write High-Quality Code",
        "Description": "In this case study-based keynote, Josh Albrecht, CTO of Imbue, examines the critical engineering challenges in building AI coding systems that create more than just prototypes. Drawing from Imbue's research developing Sculptor, an experimental coding agent environment, Josh shares key insights into the fundamental technical obstacles encountered when evolving AI-assisted coding from toy applications to more robust software systems. \r\n\r\nThe session will explore approaches to core challenges like safely executing code, managing context across large codebases, automating test generation, and creating systems that can identify potential pitfalls in AI-generated code. Attendees will gain practical insights into the technical underpinnings of next-generation coding agents that aim to handle complex software engineering challenges architecting larger systems, increasing meaningful test coverage and designing systems that are easy to debug‚Äîmoving us closer to AI systems that can help create maintainable software.\r\n",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "SWE Agents",
        "Room": "Yerba Buena Ballroom 7&8: SWE Agents",
        "Scheduled At": "5 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "1a1b94ac-0d10-4afd-8c90-a8280da87cbc",
    "Name": "Keegan McCallum",
    "Company": "Luma AI",
    "Company Domain": "keeganmccallum.com",
    "Company URL": "",
    "Company Website": "https://lumalabs.ai",
    "Title": "Head of ML Infrastructure",
    "TagLine": "Head of ML infrastructure at Luma AI",
    "Bio": "I'm Keegan McCallum, the Head of ML infrastructure at Luma AI. I began my career in research focusing on portfolio optimization. Since then I've founded two startups, lead engineering at two others and have landed at Luma AI working on an unconventional multimodal path to AGI among a cracked team of researchers and engineers. When I'm not working, I'm usually out in the woods hiking with my family, or exploring the culinary delights in whatever city I happen to be in. I'm excited to share the insights and war stories I've gathered launching one of the most successful AI products to date in a (hopefully) fun and engaging way",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/keeganmccallum3",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/24e1-400o400o1-Ln1jAmBHhguW8jzCpKLo3V.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914081",
        "Title": "General Intelligence is Multimodal",
        "Description": "Talking about Luma AI, our mission, and how our ML infrastructure enables SOTA multimodal model development ",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Case Study/War Story",
        "Tracks": "Generative Media",
        "Room": "Foothill F: Generative Media",
        "Scheduled At": "5 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "1699f319-4792-451a-a5fb-bd4d8b5da132",
    "Name": "Kyle Corbitt",
    "Company": "OpenPipe",
    "Company Domain": "openpipe.ai",
    "Company URL": "https://openpipe.ai/",
    "Company Website": "https://openpipe.ai/",
    "Title": "Co-founder and CEO",
    "TagLine": "CEO ",
    "Bio": "Kyle Corbitt is the co-founder and CEO of OpenPipe, the RL post-training company. OpenPipe has trained thousands of customer models for both enterprises and tech-forward startups.\r\n\r\nBefore founding OpenPipe, Kyle led the Startup School team at Y Combinator, which was responsible for the product and content that YC produces for early-stage companies. Prior to that he worked as an engineer at Google and studied ML at school.",
    "X (Twitter)": "https://x.com/corbtt",
    "LinkedIn": "https://www.linkedin.com/in/kcorbitt/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/3669-400o400o1-hxPfhuJsFt4RgxzgB5As4B.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914533",
        "Title": "How to Train Your Agent: Building Reliable Agents with RL",
        "Description": "Have you ever launched an awesome agentic demo, only to realize no amount of prompting will make it reliable enough to deploy in production? Agent reliability is a famously difficult problem to solve!\r\n\r\nIn this talk we‚Äôll learn how to use GRPO to help your agent learn from its successes and failures and improve over time. We‚Äôve seen dramatic results with this technique, such as an email assistant agent that whose success rate jumped from 74% to 94% after replacing o4-mini with an open source model optimized using GRPO.\r\n\r\nWe‚Äôll share case studies as well as practical lessons learned around the types of problems this works well for and the unexpected pitfalls to avoid.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Reasoning+RL",
        "Room": "Yerba Buena Ballroom 2-6: Reasoning + RL",
        "Scheduled At": "5 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "0db693b9-12cb-437d-a92f-922ba0751480",
    "Name": "Ivan Burazin",
    "Company": "Daytona",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.daytona.io/",
    "Company Website": "https://www.daytona.io/",
    "Title": "Co-founder",
    "TagLine": "CEO",
    "Bio": "Ivan Burazin co-founded Codeanywhere, the very first cloud IDE, back in 2009 where he and the team had to create everything from scratch, from the IDE itself, to the entire orchestration. Concurrently, he established Shift, the premier developer conference in Europe, which was later acquired by Infobip - a global communications cloud giant in 2021. Following the acquisition, Ivan served on the executive board of this 4,000-person company and as the Chief Developer Experience Officer, where he oversaw global developer-oriented operations.\r\nIn 2023, Ivan co-founded Daytona, a fast-growing open-source platform addressing the limitations of AI coding agents by enabling them to programmatically and securely interact with runtime environments. \r\nBacked by $7M in funding, Daytona empowers developers, from startups to Fortune 500 companies to enable AI agents to achieve their full potential.\r\n",
    "X (Twitter)": "https://twitter.com/ivanburazin",
    "LinkedIn": "https://www.linkedin.com/in/ivanburazin/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/ba67-400o400o1-RZgw2DqaC7TEEp4b41MiwA.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914814",
        "Title": "AX is the only Experience that Matters",
        "Description": "If you‚Äôre building devtools for humans, you‚Äôre building for the past. \r\n\r\nAlready a quarter of Y Combinator‚Äôs latest batch used AI to write 95% or more of their code. AI agents are scaling at an exponential rate and soon, they‚Äôll outnumber human developers by orders of magnitude.\r\n\r\n\r\nThe real bottleneck isn‚Äôt intelligence. It‚Äôs tooling. Terminals, local machines, and dashboards weren‚Äôt built for agents. They make do‚Ä¶ until they can‚Äôt.\r\n\r\nIn this talk, I‚Äôll share how we killed the CLI at Daytona, rebuilt our infrastructure from first principles, and what it takes to build devtools that agents can actually use. Because in an agent-native future, if agents can‚Äôt use your tool, no one will.\r\n",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Architects",
        "Room": "SOMA: AI Architects",
        "Scheduled At": "5 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "54da0027-870b-42b5-ba02-971f67bbbadd",
    "Name": "Kevin Madura",
    "Company": "AlixPartners",
    "Company Domain": "alixpartners.com",
    "Company URL": "https://www.alixpartners.com/our-people/28458/kevin-madura/",
    "Company Website": "https://alixpartners.com",
    "Title": "Technical Advisor and Testifying Expert",
    "TagLine": "Director, Advanced Technologies",
    "Bio": "Kevin leads technical advisory engagements and investigations in situations involving complex software, applied AI, and digital assets. As testifying expert and \"translator\" of technical material, he regularly interfaces with executive leadership, legal counsel, regulators, and engineers, balancing deep technical expertise with strategic clarity to drive outcomes.",
    "X (Twitter)": "https://x.com/kmad",
    "LinkedIn": "https://www.linkedin.com/in/kevinmadura/",
    "Blog": "https://kmad.github.io",
    "Profile Picture": "https://sessionize.com/image/8ec5-400o400o1-WcgVoUZzWdW9zEnwmsGvec.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914890",
        "Title": "The Billable Hour is Dead; Long Live the Billable Hour?",
        "Description": "If software was eating the world before, knowledge work will soon be devoured by AI. In corporate America there are thousands of hours spent on rote tasks every day by employees, consultants, and lawyers alike. But is AI really capable of replacing work in the real world yet? \r\nProductivity estimates from GenAI range from 1.5% (NBER) to 96% (‚òù us! Ô∏è). In this talk we'll share war stories of where the answer is yes (and no) and how we reduced human time spent on tasks from days to minutes in high-impact situations. \r\nThe path from promise to actual product, used in real world settings, from our experience, is still unmapped. Learn what we built, how we built it - with code - and how we got stakeholder buy-in to deploy it.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Fortune 500",
        "Room": "Golden Gate Ballroom C: AI in the Fortune 500",
        "Scheduled At": "5 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "f0ac1816-a92b-4ecc-b18f-ad668982dcde",
    "Name": "Mo Bhasin",
    "Company": "AlixPartners",
    "Company Domain": "gmail.com",
    "Company URL": "",
    "Company Website": "https://www.alixpartners.com/",
    "Title": "Director of AI Products",
    "TagLine": "Director of AI Products",
    "Bio": "Mo Bhasin is Director of AI Products at AlixPartners, where he leads development of the firm's internal genAI platform. He helped scale the platform to 50+ deployments, and grew the AI team from 2 to 20 in under a year. \r\n\r\nOver the last 15 years, he's built products as a data scientist at Google, Nest, and most recently as a startup founder at Outoftheblue.ai.\r\n\r\nHe holds an engineering degree from the University of California Berkeley, and an MBA from University of Chicago Booth School of Business.",
    "X (Twitter)": "https://x.com/BernoulliSays",
    "LinkedIn": "https://www.linkedin.com/in/bhasinmohit/",
    "Blog": "https://medium.com/@BernoulliSays",
    "Profile Picture": "https://sessionize.com/image/1d3b-400o400o1-Q4j3urbZUDa83vKfPyz7EA.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914890",
        "Title": "The Billable Hour is Dead; Long Live the Billable Hour?",
        "Description": "If software was eating the world before, knowledge work will soon be devoured by AI. In corporate America there are thousands of hours spent on rote tasks every day by employees, consultants, and lawyers alike. But is AI really capable of replacing work in the real world yet? \r\nProductivity estimates from GenAI range from 1.5% (NBER) to 96% (‚òù us! Ô∏è). In this talk we'll share war stories of where the answer is yes (and no) and how we reduced human time spent on tasks from days to minutes in high-impact situations. \r\nThe path from promise to actual product, used in real world settings, from our experience, is still unmapped. Learn what we built, how we built it - with code - and how we got stakeholder buy-in to deploy it.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Fortune 500",
        "Room": "Golden Gate Ballroom C: AI in the Fortune 500",
        "Scheduled At": "5 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "30f37b27-8758-420b-9873-0341d14a581c",
    "Name": "John Dickerson",
    "Company": "Mozilla AI",
    "Company Domain": "mozilla.ai",
    "Company URL": "",
    "Company Website": "https://www.mozilla.ai/",
    "Title": "CEO",
    "TagLine": "CEO, Mozilla AI",
    "Bio": "John Dickerson is CEO of Mozilla AI, leading the charge on building an open-source-AI-first ecosystem for the Internet.  Prior to that, he was co-founder and Chief Scientist of Arthur AI, an enterprise AI performance monitoring and security startup that has raised $55 million+ and calls many in the Fortune 500 its customers.  Before answering the call of industry, he was a tenured Associate Professor of Computer Science at the University of Maryland; he now supports academic R&D from the industry side.  He has worked extensively in responsible AI, worldwide blood donation via Meta, worldwide organ allocation via the United Network for Organ Sharing and others, combinatorial auctions via household names in the US, and various US governmental actors via DARPA, the FTC, and others.",
    "X (Twitter)": "https://x.com/johnpdickerson",
    "LinkedIn": "https://www.linkedin.com/in/john-dickerson/",
    "Blog": "https://jpdickerson.com/",
    "Profile Picture": "https://sessionize.com/image/30f3-400o400o1-4WpKLK424fi8w7TpfzMVjR.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915059",
        "Title": "2025 is the Year of Evals!  Just like 2024, and 2023, and ‚Ä¶",
        "Description": "AI is getting deployed without guardrails, without governance, without due diligence.  Surely this is the year we‚Äôll see a Fortune 500 CEO fired because of a preventable AI incident.  Surely this is the year we‚Äôll see enterprises wake up to pre-deployment evaluation and post-deployment monitoring being an urgent need.  This story hasn‚Äôt changed for a decade, but surely this is the year it will.\r\n\r\nIn this talk, I‚Äôll cover what enterprise-level AI/ML evaluation has looked like for the last decade - what‚Äôs changed, what hasn‚Äôt, what sells, what doesn‚Äôt, and where I see things going from here on out.  Evaluation matters - we all know this - but using my experience in the trenches over the last decade or so I hope to bridge the gap between what practitioners need and what the C-suite pays for in the space of AI evaluations.\r\n",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Evals",
        "Room": "Golden Gate Ballroom B: Evals",
        "Scheduled At": "5 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "0d17aad6-33ce-4d6b-b31c-1ad2573841cc",
    "Name": "Christopher Chedeau",
    "Company": "Facebook",
    "Company Domain": "gmail.com",
    "Company URL": "https://web.facebook.com/",
    "Company Website": "",
    "Title": "Software Engineer",
    "TagLine": "Frenchy Front-end Engineer",
    "Bio": "Co-creator of React Native and Prettier. Creator of Excalidraw, \"CSS-in-JS\", Yoga and React Conf.",
    "X (Twitter)": "https://www.twitter.com/vjeux",
    "LinkedIn": "",
    "Blog": "https://vjeux.com",
    "Profile Picture": "https://sessionize.com/image/3247-400o400o1-MT1CZUUmYRnNRwxKuu1DMZ.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915389",
        "Title": "AI and Human Whiteboarding Partnership",
        "Description": "Covid sent everybody home and created the space of virtual whiteboards. At first the experience reused the physical constraints but soon it became better than a physical whiteboard thanks to using virtual native concepts like copy-paste and using keyboard input.\r\nThe next step in this evolution is to integrate AI into the workflow. We've tried a lot of things with Excalidraw and ended up landing on turning prompt into diagram. Come to the talk to understand how it fits into the workflow and how we implemented it.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Case Study/War Story",
        "Tracks": "Design Engineering",
        "Room": "Foothill G 1&2: Design Engineering",
        "Scheduled At": "5 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "e5bc5c02-d408-4cb9-b70e-32ac94965e00",
    "Name": "Sherwood Callaway",
    "Company": "11x AI",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.11x.ai/",
    "Company Website": "https://www.11x.ai/",
    "Title": "Engineering Manager",
    "TagLine": "Tech Lead, Alice ",
    "Bio": "Sherwood Callaway is an emerging leader in the world of AI startups and AI product development. He currently serves as the first engineering manager at 11x, a series B AI startup backed by Benchmark and Andreessen Horowitz, where he oversees technical work on \"Alice\", an AI sales rep that outperforms top human SDRs.\r\n\r\nAlice is an advanced agentic AI working in production and at scale. Under Sherwood‚Äôs leadership, the system grew from initial prototype to handling over 1 million prospect interactions per month across 300+ customers, leveraging partnerships with OpenAI, Anthropic, and LangChain while maintaining consistent performance and reliability. Alice is now generating eight figures in ARR.\r\n\r\nSherwood joined 11x in 2024 through the acquisition of his YC-backed startup, Opkit, where he built and commercialized one of the first-ever AI phone calling solutions for a specific industry vertical (healthcare). Prior to Opkit, he was the second infrastructure engineer at Brex, where he designed, built, and scaled the production infrastructure that supported Brex‚Äôs application and engineering org through hypergrowth. He currently lives in San Francisco, CA.",
    "X (Twitter)": "https://x.com/realshcallaway",
    "LinkedIn": "https://www.linkedin.com/in/sherwoodcallaway/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/d508-400o400o1-PYvpvjHEzP33kV7TZ5WgNo.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916215",
        "Title": "Ingest, Chunk, Retrieve: How We Built an AI Sales Rep that Trains Herself",
        "Description": "AI agents and digital workers are becoming an essential tool for teams of all sizes and across all industries. However, training these agents to become experts in your product, business, and customers remains a significant challenge. But what if onboarding a digital worker was as simple as uploading your pitch deck? At 11x, we built Alice, an AI sales rep that writes outbound emails with the nuance and context of a top-performing human - because she learns like one too.\r\n\r\nIn this talk, we'll share how we built a RAG system that lets users train Alice on their internal materials: PDFs, websites, call recordings, and more. We'll walk through our ingestion flow, OCR and chunking pipeline, and explain how we leveraged different technologies and vendors to support a wide-range of file types. We'll also discuss how we leveraged Pinecone and other vector embedding technologies to drive relevant, high-performing messaging. Finally, I'll share what we‚Äôve learned running this system in production across 300+ customers and over 1m prospect interactions each month.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Retrieval+Search",
        "Room": "Golden Gate Ballroom A: Retrieval + Search",
        "Scheduled At": "5 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "78e6fb6b-5779-484c-b0ae-1b721861eb76",
    "Name": "Satwik Singh",
    "Company": "11x AI",
    "Company Domain": "gmail.com",
    "Company URL": "https://11x.ai/",
    "Company Website": "https://11x.ai",
    "Title": "Member of Technical Staff",
    "TagLine": "Member of Technical Staff ",
    "Bio": "Satwik Singh is a core builder and emerging technical leader in the rapidly evolving field of applied AI and agentic systems. As a Member of Technical Staff at 11x AI, Satwik is at the forefront of developing \"Alice\", an AI sales representative that operates autonomously at scale‚Äîtransforming how modern GTM teams work.\r\n\r\nAt 11x, Satwik has architected and delivered several of the company's most critical agent capabilities. He led the creation of the Knowledge Base Retrieval-Augmented Generation (RAG) and Deep Research pipeline, which powers Alice's ability to reason over complex product information and tailor responses with high fidelity: a first-of-its-kind system in the GTM agent space. He has also worked across systems to handle the credits ledger, and engineered the Sourcing Agent that autonomously crafts campaigns. Satwik has been instrumental in shaping the technical foundation of Alice's intelligence and reliability.\r\n\r\nPrior to 11x, Satwik was a software engineer at Meta, where he worked on Generative AI products within the Core Ads organization and contributed to infrastructure across Reality Labs. His work helped ship first-generation GenAI creative enhancements for Feed Ads‚Äîdriving significant revenue gains at scale.\r\n\r\nSatwik's unique strength lies in his ability to move seamlessly between infrastructure, AI product, and agent behavior‚Äîdesigning systems that are production-ready, high-impact, and aligned with real business outcomes. With deep hands-on experience and a vision for what Agentic AI can become, he's helping define the next era of intelligent software.",
    "X (Twitter)": "https://x.com/Aryavarta_81",
    "LinkedIn": "https://linkedin.com/in/itsmesatwik",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/2fa7-400o400o1-7W6CXjsx33yL3yMziQtfZd.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916215",
        "Title": "Ingest, Chunk, Retrieve: How We Built an AI Sales Rep that Trains Herself",
        "Description": "AI agents and digital workers are becoming an essential tool for teams of all sizes and across all industries. However, training these agents to become experts in your product, business, and customers remains a significant challenge. But what if onboarding a digital worker was as simple as uploading your pitch deck? At 11x, we built Alice, an AI sales rep that writes outbound emails with the nuance and context of a top-performing human - because she learns like one too.\r\n\r\nIn this talk, we'll share how we built a RAG system that lets users train Alice on their internal materials: PDFs, websites, call recordings, and more. We'll walk through our ingestion flow, OCR and chunking pipeline, and explain how we leveraged different technologies and vendors to support a wide-range of file types. We'll also discuss how we leveraged Pinecone and other vector embedding technologies to drive relevant, high-performing messaging. Finally, I'll share what we‚Äôve learned running this system in production across 300+ customers and over 1m prospect interactions each month.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Retrieval+Search",
        "Room": "Golden Gate Ballroom A: Retrieval + Search",
        "Scheduled At": "5 Jun 2025 02:00 PM"
      }
    ]
  },
  {
    "Speaker ID": "6eba3426-a49c-45a0-af6c-89a89a5d97d9",
    "Name": "Will Bryk",
    "Company": "Exa",
    "Company Domain": "sixeastern.com",
    "Company URL": "https://exa.ai/blog",
    "Company Website": "",
    "Title": "CEO",
    "TagLine": "CEO",
    "Bio": "A year before ChatGPT launched, Will was already spending his time building Exa‚Äôs API to crawl the web intelligently, focusing on finding quality sources over SEO spam. Backed by NVIDIA and Lightspeed, Exa now powers products for customers like Databricks, Cursor, and LlamaIndex.",
    "X (Twitter)": "https://x.com/WilliamBryk",
    "LinkedIn": "https://www.linkedin.com/in/william-bryk/",
    "Blog": "https://exa.ai/blog",
    "Profile Picture": "https://sessionize.com/image/28e6-400o400o1-npNk1HpDJ8XS1x9yMjkxiv.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914024",
        "Title": "Building a Smarter AI Agent with Neural RAG",
        "Description": "RAG quality for AI agents is critical, and traditional keyword-based search engines consistently underperform in agentic or multi-step tasks, where semantic grounding and contextual nuance matter most.\r\n\r\nIn this talk, Will Bryk, CEO of Exa will live code two AI agent applications‚Äìone using traditional keyword search RAG and one using neural network RAG via vector search. He‚Äôll then evaluate both applications based on task performance, relevance, and latency. With a live demo (no theory or pre-baked applications), the audience will get a firsthand look at the practical differences between keyword and semantic systems in production, and learn embedding strategies, indexing trade-offs, hybrid retrieval techniques, prompt tuning, and more. ",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "Golden Gate Ballroom A: Retrieval + Search",
        "Scheduled At": "5 Jun 2025 02:25 PM"
      }
    ]
  },
  {
    "Speaker ID": "ef2bca3d-26df-4a59-a8e7-f197a34abaa9",
    "Name": "Robert Brennan",
    "Company": "All Hands AI",
    "Company Domain": "all-hands.dev",
    "Company URL": "https://www.all-hands.dev/",
    "Company Website": "https://www.all-hands.dev",
    "Title": "CEO",
    "TagLine": "CEO",
    "Bio": "Robert Brennan has been writing software for 15 years, with a focus on natural language processing and developer tools. He is currently the CEO of All Hands AI, the company behind OpenHands (formerly OpenDevin), a fully autonomous AI developer. Previously he was VP of Product Development at Fairwinds, ran a startup called Datafire, and worked as a Senior Software Engineer at Google.",
    "X (Twitter)": "https://x.com/rbren_dev",
    "LinkedIn": "https://linkedin.com/in/robert-a-brennan",
    "Blog": "https://www.all-hands.dev/blog",
    "Profile Picture": "https://sessionize.com/image/62d2-400o400o1-3DaPYZY7SULucDrMfzQzkX.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915387",
        "Title": "Software Development Agents: What Works and What Doesn't",
        "Description": "The adoption of AI into software development has been bumpy. While autocomplete tools like Copilot have gone mainstream, autonomous agents like Devin and OpenHands have generated both enthusiasm and skepticism. Some engineers claim they generate a 10x productivity boost; others that they just create noise and tech debt.\r\n\r\nThe difference between the enthusiasts and the skeptics is that the enthusiasts have reasonable expectations for what these agents can do, and have both practical and intuitive knowledge for how to use them effectively.\r\n\r\nIn this session, we'll talk about what tasks are appropriate for today's software agents, what tasks they might start to succeed at in 2025, and what tasks are best left to humans no matter how good they get.\r\n\r\nSession Outline:\r\nLearn how to use software development agents like OpenHands (fka OpenDevin) effectively, without creating noise and tech debt.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "SWE Agents",
        "Room": "Yerba Buena Ballroom 7&8: SWE Agents",
        "Scheduled At": "5 Jun 2025 02:25 PM"
      }
    ]
  },
  {
    "Speaker ID": "b2ff31e4-a1fd-4f6f-9641-87c9a23c6bb0",
    "Name": "Jared Hanson",
    "Company": "Keycard",
    "Company Domain": "keycard.sh",
    "Company URL": "https://www.keycard.sh/",
    "Company Website": "https://www.keycard.sh/",
    "Title": "Co-founder",
    "TagLine": "Co-Founder",
    "Bio": "Jared Hanson is the co-founder of Keycard, a company building identity infrastructure for the agent-native world.  Previously at Okta and Auth0, Jared is an expert on OpenID, OAuth, and all things identity.  He‚Äôs also the author of Passport.js, the popular authentication framework for Node.js.  At Keycard, he is applying that knowledge to securing AI and infrastructure.",
    "X (Twitter)": "https://x.com/jaredhanson",
    "LinkedIn": "https://www.linkedin.com/in/jaredhanson/",
    "Blog": "https://www.jaredhanson.me/",
    "Profile Picture": "https://sessionize.com/image/6bc5-400o400o1-Be3w5EvJh5jBNYPiYFm9JP.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915751",
        "Title": "How to Secure Agents using OAuth",
        "Description": "We all know sharing passwords is bad (unless you want free TV), so why are we sharing API keys with AI?  We shouldn't, and that‚Äôs why we need to talk about OAuth.\r\n\r\nIn this talk, we will give a brief intro to OAuth.  Then we will talk about the state of authorization in MCP.  We will show how an MCP client uses OAuth to authenticate a user and securely access private resources and tools hosted by an MCP server.  Then we‚Äôll look at ways autonomous agents can use OAuth on their own behalf, talking to other agents and MCP servers directly.  We‚Äôll learn how to use OAuth to build agents that humans and machines can trust.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Security",
        "Room": "Foothill C: Security",
        "Scheduled At": "5 Jun 2025 02:25 PM"
      }
    ]
  },
  {
    "Speaker ID": "0d54907d-a141-49a3-8d3c-4f5834c0cbcf",
    "Name": "Ben Hylak",
    "Company": "Raindrop.ai",
    "Company Domain": "dawnai.com",
    "Company URL": "https://raindrop.ai/",
    "Company Website": "https://raindrop.ai",
    "Title": "Co-founder",
    "TagLine": "Co-Founder",
    "Bio": "Ben Hylak is co-founder at Raindrop, building Sentry for AI products. He was previously a designer at Apple for 4 years, building the Apple Vision Pro. ",
    "X (Twitter)": "https://x.com/benhylak",
    "LinkedIn": "https://www.linkedin.com/in/benhylak/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/8705-400o400o1-PF84iPXFpuf9ff9PC2DPYA.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915921",
        "Title": "Testing the Un-Testable: Monitoring AI Products in the Wild",
        "Description": "Evals are straightforward‚Äîlike unit tests, they confirm your model got specific test cases right.\r\n\r\nBut in the real world, your AI encounters millions of unpredictable interactions each day. How do you gauge user trust, identify frustrations, and adapt when there's no single \"correct\" output? Diving through endless logs and manually adding one eval at a time won't cut it.\r\n\r\nIn this session, we'll explore how leading teams are moving beyond static evals; leveraging semantic analytics, LLM teachers, and AI-powered monitoring to deeply understand user experiences at scale‚Äîbuilding AI products that don‚Äôt just pass tests, but genuinely resonate with users.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Architects",
        "Room": "SOMA: AI Architects",
        "Scheduled At": "5 Jun 2025 02:25 PM"
      }
    ]
  },
  {
    "Speaker ID": "ec32a532-c1e0-4e0b-8877-6116ed2995f7",
    "Name": "Randall Hunt",
    "Company": "Caylent",
    "Company Domain": "caylent.com",
    "Company URL": "https://caylent.com",
    "Company Website": "https://caylent.com",
    "Title": "Technology Leader",
    "TagLine": "CTO at Caylent",
    "Bio": "Randall Hunt is a technology leader, investor, and hands-on keyboard coder based in Los Angeles, CA. Previously, Randall led software and developer relations teams at Facebook, SpaceX, AWS, MongoDB, and NASA. Randall spends most of his time listening to customers, building demos, writing blog posts, and mentoring junior engineers. Python and C++ are his favorite programming languages, but he begrudgingly admits that Javascript rules the world. Outside of work, Randall loves to read science fiction, advise startups, travel, and ski.",
    "X (Twitter)": "https://x.com/jrhunt",
    "LinkedIn": "https://www.linkedin.com/in/ranman/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/146b-400o400o1-K4KVZWvVXeiN3CaJcBgTtd.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "925912",
        "Title": "Embeddings ARE NOT All You Need: Understanding Tradeoffs in Multimodal Search",
        "Description": "Multimodal search demos show impressive capabilities but understanding how to scale these systems while balancing cost and performance is where things get tricky.\r\n\r\nThrough three real-world implementations from wildlife stock footage to breaking news to sports highlights, I'll demonstrate how HNSW-indexed vector embeddings and more traditional caption-based approaches each excel in different domains. You'll see how querying pooled image embeddings struggle with spatiotemporal relationships that simple JSON tagging handles effortlessly. You'll see how traditional computer vision techniques applied as preprocessing steps enable video understanding models to more accurately answer ‚Äúwas the athlete over this line?‚Äù.\r\n\r\nI'll share implementation patterns for these approaches with animated architecture diagrams. We‚Äôll cover why chunking and preprocessing strategies impact both accuracy and index size. By the end of this talk, you'll understand the nuanced technical tradeoffs between embeddings, metadata filtering, and hybrid retrieval for your specific multimodal search challenges. Most importantly, you'll get some real world costs around indexing and continued operation.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Fortune 500",
        "Room": "Golden Gate Ballroom C: AI in the Fortune 500",
        "Scheduled At": "5 Jun 2025 02:25 PM"
      }
    ]
  },
  {
    "Speaker ID": "5e52da6a-611f-4e42-b767-ceaa757c96f5",
    "Name": "Nathan Lambert",
    "Company": "Allen Institute for AI",
    "Company Domain": "natolambert.com",
    "Company URL": "https://allenai.org/",
    "Company Website": "https://allenai.org/",
    "Title": "Senior Research Scientist and Post-Training Lead",
    "TagLine": "Senior Research Scientist at Ai2 & Founder of Interconnects.ai",
    "Bio": "Nathan Lambert is a Senior Research Scientist and post-training lead at the Allen Institute for AI focusing on building open language models. At the same time he founded and operates Interconnects.ai to increase transparency and understanding of current AI models and systems.\r\n\r\nPreviously, he helped build an RLHF research team at HuggingFace. He received his PhD from the University of California, Berkeley working at the intersection of machine learning and robotics. He was advised by Professor Kristofer Pister in the Berkeley Autonomous Microsystems Lab and Roberto Calandra at Meta AI Research. He was lucky to intern at Facebook AI and DeepMind during his Ph.D. Nathan was was awarded the UC Berkeley EECS Demetri Angelakos Memorial Achievement Award for Altruism for his efforts to better community norms.",
    "X (Twitter)": "https://twitter.com/natolambert",
    "LinkedIn": "https://www.linkedin.com/in/natolambert/",
    "Blog": "https://www.interconnects.ai/",
    "Profile Picture": "https://sessionize.com/image/5217-400o400o1-WyvArXo2YbAyFyb1eH36wp.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "926721",
        "Title": "What Reinforcement Learning with Verifiable Rewards Changed",
        "Description": "Reinforcement learning with verifiable rewards (RLVR) came onto the field with a storm after the DeepSeek R1 model showed that training reasonable models was accessible to the entire AI industry. Next it became table stakes for high scores in math and code, but quickly it's shifting to opening the doors on new types of models entirely -- those enabling tool use, reasoning, code execution, and everything to come together to new experiences.\r\n\r\nThis talk describes how RLVR emerged in such a sudden way, what we can glean about AI research generally, and how RLVR changed the AI models we will use forever. ",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "Reasoning+RL",
        "Room": "Yerba Buena Ballroom 2-6: Reasoning + RL",
        "Scheduled At": "5 Jun 2025 02:25 PM"
      }
    ]
  },
  {
    "Speaker ID": "95cbe8fd-d8e5-43d7-92cf-56f1edc9b11a",
    "Name": "Steve  Ruiz",
    "Company": "tldraw",
    "Company Domain": "tldraw.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "unknown",
    "TagLine": "",
    "Bio": "",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "934617",
        "Title": "tldraw.computer",
        "Description": "(tbc)",
        "Format": "Talk",
        "Level": "",
        "Scope": "",
        "Tracks": "Design Engineering",
        "Room": "Foothill G 1&2: Design Engineering",
        "Scheduled At": "5 Jun 2025 02:25 PM"
      }
    ]
  },
  {
    "Speaker ID": "7d64d49c-59de-4f07-86ac-ca54f40cbff8",
    "Name": "Rustin Banks",
    "Company": "Google Labs",
    "Company Domain": "google.com",
    "Company URL": "https://labs.google/",
    "Company Website": "https://labs.google/",
    "Title": "AI Product Manager",
    "TagLine": "Product Manager, AI Coding ",
    "Bio": "I'm Rustin, an AI Product Manager at Google Labs. I taught myself to program at age 12 using a compiler I purchased on AOL classifieds. As a teenager I hosted a popular bulletin board system (BBS) out of my cousin‚Äôs closet using salvaged 286 computers. I‚Äôve always had a passion for making the world better using technology. When I saw AI write code I dedicated the rest of my career to AI coding. At Google labs I am lucky to explore the frontier of coding models and agents.  ",
    "X (Twitter)": "https://x.com/rustinb",
    "LinkedIn": "https://www.linkedin.com/in/rustinbanks/",
    "Blog": "https://rustinbanks.com/",
    "Profile Picture": "https://sessionize.com/image/e0f8-400o400o1-9FpwPjJj37un3C7rtXE6tv.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914012",
        "Title": "Your Coding Agent Just Got Cloned And Your Brain Isn't Ready",
        "Description": "Will the future engineer code alongside a single coding agent, or will they spend their day orchestrating many agents? Traditional development rewards synchronous focus. This session dives into the significant mindshift required to move from sequential coding to orchestrating parallel agents. We are the builders of \"Jules\", Google's massively parallel asynchronous coding agent (to be opened up in May). We'll share real-world insights from building Jules and explore how to rewire your brain for this powerful new \"post-IDE\" development paradigm.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "SWE Agents",
        "Room": "Yerba Buena Ballroom 7&8: SWE Agents",
        "Scheduled At": "5 Jun 2025 02:50 PM"
      }
    ]
  },
  {
    "Speaker ID": "fabd056c-2440-49ec-8199-3ac7d6080a7d",
    "Name": "Mark Bissell",
    "Company": "Goodfire AI",
    "Company Domain": "goodfire.ai",
    "Company URL": "https://www.goodfire.ai/",
    "Company Website": "https://www.goodfire.ai/",
    "Title": "Applied Researcher",
    "TagLine": "Applied Interpretability Research ",
    "Bio": "Mark Bissell is an applied researcher at Goodfire AI working on real-world applications for mechanistic interpretability. He recently joined Goodfire after 3 years at Palantir, where he worked on various U.S. healthcare initiatives including research projects with the NIH, vaccine distribution during the Covid pandemic (Operation Warp Speed), and AI-enabled hospital operations across many of the nation's leading health systems. \r\n\r\nMark is passionate about translating frontier research into practical solutions. He believes that recent AI developments increase the importance broad skillsets, and that roles of the future will blur the lines between traditionally distinct categories such as engineer, researcher, inventor, designer, and entrepreneur. ",
    "X (Twitter)": "https://x.com/MarkMBissell",
    "LinkedIn": "https://www.linkedin.com/in/mark-bissell/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/3340-400o400o1-32dNeZ1139AHoGD7YpQUGT.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914798",
        "Title": "Operationalizing AI Interpretability with Neural Programming Interfaces (NPIs)",
        "Description": "Mechanistic interpretability is a frontier field that aims to reverse engineer neural networks. At Goodfire, we're operationalizing the latest in interpretability research by building Ember: the universal platform for neural programming. Ember decodes the neurons of an AI model to give direct, programmable access to its internal representations.\r\nIn this talk, we'll share more about what's unlocked by moving beyond black-box inputs and outputs, including entirely new ways to apply, train, and align AI models. We're excited for a future in which neural programming allows users to discover new knowledge hidden in their model, precisely shape its behaviors, and improve its performance. ",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Generative Media",
        "Room": "Foothill F: Generative Media",
        "Scheduled At": "5 Jun 2025 02:50 PM"
      }
    ]
  },
  {
    "Speaker ID": "b734b775-2254-4df3-90b1-bb2da4ac9638",
    "Name": "Brett Kotch",
    "Company": "The Pragmatic AI Programmer",
    "Company Domain": "outlook.com",
    "Company URL": "www.pragramaticaiprogrammer.com",
    "Company Website": "",
    "Title": "Technology Innovator",
    "TagLine": "AI for Technology",
    "Bio": "Brett Kotch has transformed trading technology at top global financial institutions, including Millennium, Citibank, Barclays, and Liquidnet, where he was part of the original team enabling anonymous execution of large trades, creating one of Wall Street‚Äôs largest pools of institutional liquidity. Brett is actively driving innovative solutions to advance AI within technology. Brett holds a degree in Computer Science from Columbia University.\r\n\r\n",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/4cd2-400o400o1-fRJj6RumYBNw3BrrMqLqbX.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915353",
        "Title": "The Evolution of Software Development with AI",
        "Description": "Artificial Intelligence is a rapidly advancing technology revolutionizing the world, especially in software creation. As AI advances, it handles more intricate tasks, significantly reshaping how we write software.\r\n\r\nThe journey through the evolution of programming with AI can be categorized into seven distinct stages. Each stage represents a unique milestone in how AI integrates with and enhances software development.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Leadership: Architects",
        "Room": "SOMA: AI Architects",
        "Scheduled At": "5 Jun 2025 02:50 PM"
      }
    ]
  },
  {
    "Speaker ID": "b3e35f24-1320-492a-99af-40f7ae49eb82",
    "Name": "Rene Brandel",
    "Company": "Casco (YC X25)",
    "Company Domain": "gmail.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "Security Researcher",
    "TagLine": "CEO",
    "Bio": "https://www.youtube.com/watch?v=QAXL-Lbjf94",
    "X (Twitter)": "",
    "LinkedIn": "https://linkedin.com/in/renebrandel",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/bd86-400o400o1-VusEb89Bug3H9UGtJHm22x.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915873",
        "Title": "How we hacked YC Spring 2025 batch‚Äôs AI agents",
        "Description": "We hacked 7 of the16 publicly-accessible YC X25 AI agents. This allowed us to leak user data, execute code remotely, and take over databases. All within 30 minutes each. In this session, we'll walk through the common mistakes these companies made and how you can mitigate these security concerns before your agents put your business at risk.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Security",
        "Room": "Foothill C: Security",
        "Scheduled At": "5 Jun 2025 02:50 PM"
      }
    ]
  },
  {
    "Speaker ID": "c3afa709-163c-42f3-b7ea-a9428027b912",
    "Name": "Rita  Kozlov",
    "Company": "cloudflare",
    "Company Domain": "gmail.com",
    "Company URL": "cloudflare.com",
    "Company Website": "",
    "Title": "Platform Engineer",
    "TagLine": "vp developers & ai, cloudflare",
    "Bio": "From the very beginning, Rita has been a key figure in the development of Cloudflare's developer platform. Their initial experience as a solutions engineer, helping early enterprise customers adopt the service, gave them firsthand insight into user needs. It was the power of Cloudflare Workers that truly resonated, inspiring a vision for a serverless future. For the past eight years, they have built out the platform which now spans products including storage, compute and AI, and is used by everyone from indie millions of indie developers to Fortune 500 companies. ",
    "X (Twitter)": "https://twitter.com/ritakozlov_",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/4a76-400o400o1-JWNeEGkowi8eboPsWT89bu.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "935969",
        "Title": "Building Agents (the hard parts!)",
        "Description": "AI workloads are rapidly shifting from AI being used for augmentation (co-pilots), to AI becoming responsible for full, end-to-end automation (agents). But building effective agents, and even more importantly, agent experiences that boost productivity requires many pieces. In this talk, we'll be covering the building blocks of agents, how to put them together, and what we've learned from top companies building agents along the way. ",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Leadership: Fortune 500",
        "Room": "Golden Gate Ballroom C: AI in the Fortune 500",
        "Scheduled At": "5 Jun 2025 02:50 PM"
      }
    ]
  },
  {
    "Speaker ID": "af9c04da-4bdc-4238-9755-9bf1530b72c3",
    "Name": "Sean Grove",
    "Company": "OpenAI",
    "Company Domain": "gmail.com",
    "Company URL": "https://openai.com/",
    "Company Website": "https://openai.com/",
    "Title": "Alignment Reasoning Specialist",
    "TagLine": "Member of Technical Staff",
    "Bio": "Sean Grove works on alignment reasoning at OpenAI, helping translate high‚Äëlevel intent into enforceable specs and evaluations. Before OpenAI he founded OneGraph, a GraphQL developer‚Äëtools startup later acquired by Netlify. He has delivered dozens of technical talks worldwide on developer tooling, APIs, AI UX and design, and now alignment.",
    "X (Twitter)": "https://x.com/sgrove",
    "LinkedIn": "https://www.linkedin.com/in/segrove/",
    "Blog": "https://www.riseos.com/",
    "Profile Picture": "https://sessionize.com/image/7e44-400o400o1-M6CbERvhHqSDdghtgqPjC9.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "925974",
        "Title": "Prompt Engineering is Dead - Everything is a Spec",
        "Description": "[!!Subject to change!!]\r\n\r\nLarge models are trained through mountains of data and learned reward functions, yet - quis custodiet ipsos custodes? - what exactly are those amorphous blobs of data and rewards trying to specify? Building LLMs in any domain demands both clarity of thought and the skill to communicate those thoughts precisely - not only to other humans but to the models themselves. Without either, we risk unpleasant surprises.\r\n\r\nThis talk dives into:\r\n\t‚Ä¢\tWhy prompt spaghetti and data gumbo inevitably collapse at scale, unleashing behaviors we never intended - while a rigorously versioned spec keeps safety, personality, and UX firmly aligned, and makes incidents easier and faster to diagnose and fix.\r\n\t‚Ä¢\tHow OpenAI‚Äôs public Model‚ÄØSpec provides a clear template, complemented by emerging ‚Äúdev tools‚Äù that turn hazy human intent into precise, human-and-machine-readable policy.\r\n\t‚Ä¢\tHow deliberative alignment training teaches models to first read and reason about the spec, boosting robustness without inflating context windows.\r\n\t‚Ä¢\tPractical tactics for catching ambiguity, untangling contradictions, and preserving global consistency. Plus, techniques for verifying that deployed models truly follow the contract we crafted.\r\n\r\nResources: Model‚ÄØSpec‚ÄØ(2025‚Äë04‚Äë11) and Deliberative‚ÄØAlignment, Guan‚ÄØet‚ÄØal.,‚ÄØ2024.",
        "Format": "Keynote",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "AI in Action",
        "Room": "Keynote/General Session (Yerba Buena 7&8)",
        "Scheduled At": "5 Jun 2025 04:40 PM"
      }
    ]
  }
]