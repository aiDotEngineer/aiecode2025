[
  {
    "Speaker ID": "ccad15eb-e444-4773-9c0c-8f331f2b5c13",
    "Name": "Tom Smoker",
    "Company": "WhyHow.AI",
    "Company Domain": "whyhow.ai",
    "Company URL": "https://www.whyhow.ai/",
    "Company Website": "https://www.whyhow.ai/",
    "Title": "Co-Founder",
    "TagLine": "Technical Founder ",
    "Bio": "Co-Founder @ WhyHow.AI",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/thomassmoker",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/32a2-400o400o1-72WfcKvQhQ3sFATn9wQxqr.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "900332",
        "Title": "Beyond Documents: Implementing Knowledge Graphs in Legal Agents",
        "Description": "Structured Representations are pretty important in the law, where the relationships between clauses, documents, entities, and multiple parties matter. Structured Representation means Structured Context Injection. Better Context, Less Hallucinations. We walk through a couple of case studies of systems that we’ve built in production for legal use-cases - from recursive contractual clause retrieval, to HITL legal reasoning news agents.\r\n\r\nYou'll gain insights into how structured representations significantly improve the effectiveness and reliability of legal agents.\r\n",
        "Format": "",
        "Level": "Intermediate",
        "Scope": "",
        "Tracks": "GraphRAG",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "527dd628-aaa1-4248-a232-5d92803d426a",
    "Name": "Joel Hron",
    "Company": "Thomson Reuters",
    "Company Domain": "thomsonreuters.com",
    "Company URL": "https://www.thomsonreuters.com/en",
    "Company Website": "https://www.thomsonreuters.com/en",
    "Title": "Chief Technology Officer",
    "TagLine": "CTO",
    "Bio": "Joel Hron is a passionate innovator driving the future of product technology and AI at Thomson Reuters. As Chief Technology Officer, he leads Product Engineering and AI Research & Development, pushing the boundaries of what’s possible in Legal, Tax, Audit, Trade, Compliance, and Risk solutions.\r\n\r\nJoel joined Thomson Reuters in 2022 through the acquisition of ThoughtTrace, where he served as CTO. Previously, he led AI and TR Labs, launching seven groundbreaking GenAI products in just 18 months, transforming legal research, tax analysis, and contract drafting.\r\n\r\nHis approach is centered on rethinking processes through technology, building teams rooted in trust, transparency, and customer-centric innovation. Joel envisions AI not as a replacement for human expertise, but as a force that enhances professional decision-making, making expert information more accessible and impactful.\r\n\r\nA New Orleans native, Joel’s global career spans work in London and Africa, and he now calls Zug, Switzerland home. He holds a Master’s in Mechanical Engineering from the University of Texas at Austin and a Bachelor’s in Engineering from Texas Christian University.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/joel-hron-90a3421a/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/d150-400o400o1-GySHFV3G8UNoTbUdavrqVa.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "903524",
        "Title": "From Copilot to Colleague: Building Trustworthy Productivity Agents for High-Stakes Work",
        "Description": "This keynote will explore what it takes to move from basic generative assistants to fully agentic AI—systems that don’t just suggest but plan, act, and adapt—all within the structured, high-trust environments where professionals actually work.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Product launch",
        "Tracks": "Leadership: Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "0526d7d4-e6b6-4fae-a9bc-38f96ba75bd3",
    "Name": "Chang She",
    "Company": "LanceDB",
    "Company Domain": "lancedb.com",
    "Company URL": "https://www.lancedb.com/",
    "Company Website": "https://www.lancedb.com",
    "Title": "Co-founder",
    "TagLine": "CEO",
    "Bio": "Two decades of building data tools for ML/AI. Pandas co-author. Building LanceDB, the database for multimodal AI.",
    "X (Twitter)": "https://x.com/changhiskhan",
    "LinkedIn": "https://www.linkedin.com/in/changshe/",
    "Blog": "https://blog.lancedb.com",
    "Profile Picture": "https://sessionize.com/image/7a07-400o400o1-MuSbRRkcoMr4jC4RVdNg4t.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "903966",
        "Title": "Scaling Enterprise-Grade RAG Systems: Lessons from the Legal Frontier",
        "Description": "In domains like law, compliance, and tax, building enterprise-grade RAG means very large scale, spikey workloads, a focus on accuracy, and non-negotiable privacy.\r\nIn this talk, we'll share war stories and battle scars of how Harvey has built the world's most advanced AI agents for the legal profession on top of a highly optimized retrieval architecture. We'll cover how to get better retrieval via both sparse and dense retrieval methods, why domain-specific reranking is essential, and how to handle ambiguity in real-world queries.\r\nWe'll also touch on how LanceDB's search engine enables this architecture by delivering low-latency, high-throughput retrieval across millions of documents of varying sizes without compromising privacy. This solid foundation enables Harvey to build a product that brings highly accurate answers to hundreds of law firms and professional services firms across 45 countries.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Retrieval+Search",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "f3bfd5b7-b22f-48b4-a577-002c5856346e",
    "Name": "Aman Kishore",
    "Company": "Harvey AI",
    "Company Domain": "harvey.ai",
    "Company URL": "https://www.harvey.ai/",
    "Company Website": "https://harvey.ai",
    "Title": "Former Founder",
    "TagLine": "Former Founder",
    "Bio": "Former Founder",
    "X (Twitter)": "https://x.com/_amankishore",
    "LinkedIn": "https://www.linkedin.com/in/aman-kishore/",
    "Blog": "https://amanml.com",
    "Profile Picture": "https://sessionize.com/image/9222-400o400o1-aRYyy3aGCPXsRcR1usvcme.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "903966",
        "Title": "Scaling Enterprise-Grade RAG Systems: Lessons from the Legal Frontier",
        "Description": "In domains like law, compliance, and tax, building enterprise-grade RAG means very large scale, spikey workloads, a focus on accuracy, and non-negotiable privacy.\r\nIn this talk, we'll share war stories and battle scars of how Harvey has built the world's most advanced AI agents for the legal profession on top of a highly optimized retrieval architecture. We'll cover how to get better retrieval via both sparse and dense retrieval methods, why domain-specific reranking is essential, and how to handle ambiguity in real-world queries.\r\nWe'll also touch on how LanceDB's search engine enables this architecture by delivering low-latency, high-throughput retrieval across millions of documents of varying sizes without compromising privacy. This solid foundation enables Harvey to build a product that brings highly accurate answers to hundreds of law firms and professional services firms across 45 countries.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Retrieval+Search",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "8704af51-8a94-4a8b-adc1-3322925e7274",
    "Name": "Calvin Qi",
    "Company": "Harvey AI",
    "Company Domain": "harvey.ai",
    "Company URL": "https://www.harvey.ai/",
    "Company Website": "",
    "Title": "Retrieval Augmented Generation Specialist",
    "TagLine": "Tech Lead Manager",
    "Bio": "Calvin works on Retrieval Augmented Generation at Harvey for expert use cases in Legal, Tax, and more.",
    "X (Twitter)": "https://x.com/calvincongelado",
    "LinkedIn": "https://www.linkedin.com/in/calvinqi/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/1cfe-400o400o1-ngjKE6r3bZUEwDRvW2QE3o.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "903966",
        "Title": "Scaling Enterprise-Grade RAG Systems: Lessons from the Legal Frontier",
        "Description": "In domains like law, compliance, and tax, building enterprise-grade RAG means very large scale, spikey workloads, a focus on accuracy, and non-negotiable privacy.\r\nIn this talk, we'll share war stories and battle scars of how Harvey has built the world's most advanced AI agents for the legal profession on top of a highly optimized retrieval architecture. We'll cover how to get better retrieval via both sparse and dense retrieval methods, why domain-specific reranking is essential, and how to handle ambiguity in real-world queries.\r\nWe'll also touch on how LanceDB's search engine enables this architecture by delivering low-latency, high-throughput retrieval across millions of documents of varying sizes without compromising privacy. This solid foundation enables Harvey to build a product that brings highly accurate answers to hundreds of law firms and professional services firms across 45 countries.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Retrieval+Search",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "41650cf7-bce8-486c-bff9-1283aa976cbe",
    "Name": "Vaibhav Page",
    "Company": "BlackRock",
    "Company Domain": "blackrock.com",
    "Company URL": "https://www.blackrock.com/corporate",
    "Company Website": "",
    "Title": "Principal Engineer",
    "TagLine": "Principal Engineer ",
    "Bio": "Vaibhav is a Principal Engineer at BlackRock, where he leads the development of the Data Science and AI platform powering \r\ninvestment research and automation across the firm. Vaibhav is also the author of Argo-Events, a CNCF-graduated project widely used for event-driven automation in cloud-native environments.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/vaibhav-page-b0621741",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/7460-400o400o1-Sp7vVBU4Ue9iXMPDyNJPPm.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "904722",
        "Title": "Accelerating Investment Operations: How BlackRock Builds Custom Knowledge Apps at Scale.",
        "Description": "Investment Operations teams are the backbone of asset and investment management firms. Their day-to-day work not only enables portfolio managers to respond swiftly to market events but also ensures that complex, unstructured data flows seamlessly across the organization.\r\nIn this talk, we introduce a modular, Kubernetes-native AI framework purpose-built to scale custom Knowledge Apps across the enterprise. Designed with speed, flexibility, and compliance in mind, the framework empowers teams to launch production-grade document extraction applications in minutes instead of months, unlocking new levels of automation and efficiency for investment management workflows.\r\nWe’ll also share how this framework has helped BlackRock streamline document extraction processes, generate investment signals, reduce operational overhead, and accelerate the delivery of high-impact business use cases—all while maintaining the robustness and control required in a regulated industry.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "45160f46-e17e-4801-9395-eaaa9549e70b",
    "Name": "Infant Vasanth",
    "Company": "BlackRock",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.blackrock.com/corporate",
    "Company Website": "",
    "Title": "Engineering Team Lead, Studio Compute Platform and Data & AI Acceleration",
    "TagLine": "Senior Director of Engineering",
    "Bio": "Infant Vasanth leads the engineering team responsible for the Studio Compute Platform, BlackRock's analytics and automation platform that enables our users to conduct research & analysis, run automations and distribute research at scale.\r\nIn addition, Infant is also leading the Data & AI Acceleration team focusing on efforts to enhance Aladdin Studio's AI capabilities along side the Operational AI capabilities(prospectus analyzer, operational agents etc.)",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/irosariov/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/c520-400o400o1-JnUBivkDWXsKDLfHtbyEQw.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "904722",
        "Title": "Accelerating Investment Operations: How BlackRock Builds Custom Knowledge Apps at Scale.",
        "Description": "Investment Operations teams are the backbone of asset and investment management firms. Their day-to-day work not only enables portfolio managers to respond swiftly to market events but also ensures that complex, unstructured data flows seamlessly across the organization.\r\nIn this talk, we introduce a modular, Kubernetes-native AI framework purpose-built to scale custom Knowledge Apps across the enterprise. Designed with speed, flexibility, and compliance in mind, the framework empowers teams to launch production-grade document extraction applications in minutes instead of months, unlocking new levels of automation and efficiency for investment management workflows.\r\nWe’ll also share how this framework has helped BlackRock streamline document extraction processes, generate investment signals, reduce operational overhead, and accelerate the delivery of high-impact business use cases—all while maintaining the robustness and control required in a regulated industry.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "b6c36208-886a-4ea6-a91a-12adba06960c",
    "Name": "Eno Reyes",
    "Company": "Factory",
    "Company Domain": "factory.ai",
    "Company URL": "https://www.factory.ai/",
    "Company Website": "https://www.factory.ai/",
    "Title": "Cofounder and CTO",
    "TagLine": "CTO",
    "Bio": "Eno Reyes is cofounder and CTO of Factory, a platform that accelerates enterprise software development with autonomous AI agents and unified context from across your engineering tools. Enterprises are using Factory to accelerate everything from bug-fixing and coding to PRD creation, release automation, migrations, and more.\r\n\r\nPrior to Factory, he was an ML engineer at Hugging Face working on enterprise LLMs.",
    "X (Twitter)": "https://x.com/EnoReyes",
    "LinkedIn": "https://www.linkedin.com/in/enoreyes/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/0ead-400o400o1-PswjrSTdxdyg7Jhq9EfQgq.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "904751",
        "Title": "Ship Production Software in Minutes, Not Months",
        "Description": "Planning, coding, testing, monitoring—the endless cycle that spans 10+ tools that fragment our focus and slows delivery to a crawl. Vibe coding doesn't work when you've got 10TB of code. If you just sighed, you're one of many professional software engineers trapped in the traditional software development lifecycle (SDLC) that was designed before AI could parallelize your entire workflow.\r\n\r\nBut what if you could orchestrate multiple AI agents on tasks beyond just generating code, while you focus on the creative decisions that matter?\r\n\r\nIn this talk, I'll demonstrate how real enterprise organizations are changing their entire SDLC—going from understanding, planning, coding, and testing all the way to incident response—using AI agents. You'll witness the next evolution of software engineering—where AI doesn't just generate code, but orchestrates the entire development lifecycle.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Product launch",
        "Tracks": "SWE Agents",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "b739c7b1-589c-4479-857b-7bbf1fca41b8",
    "Name": "Denys Linkov",
    "Company": "Wisedocs",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.wisedocs.ai/",
    "Company Website": "",
    "Title": "Head of ML",
    "TagLine": "Head of ML",
    "Bio": "Denys is the Head of ML at Wisedocs, Startup Advisor and a Sessional Lecturer at the University of Toronto. He's worked with 50+ enterprises in their AI journey in the AI automation and Medical document spaces. He's worked across the AI product stack, being hands-on building key ML systems, managing product delivery teams, and working directly with customers on best practices. ",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/denyslinkov/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/e241-400o400o1-TAaqdSME9z1qd3rGUw2jw.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "904822",
        "Title": "Structuring a modern AI team",
        "Description": "You've been given an AI mandate but don't have additional headcount, what next? Re-skilling, up-skilling and team augmentation become essential to delivering on a new mandate. In this talk we'll cover strategies to structure cross functional AI teams with domain experts, software engineers and ML engineers. We'll cover key skills and milestones that each traditional role can contribute to in unique ways.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Leadership: Architects",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "1f442afe-45ef-48c0-9782-5a5267729d06",
    "Name": "Dr. Jasper Zhang, PhD",
    "Company": "Hyperbolic",
    "Company Domain": "hyperbolic.com",
    "Company URL": "",
    "Company Website": "https://hyperbolic.xyz/",
    "Title": "CEO and Co-founder",
    "TagLine": "CEO",
    "Bio": "Dr. Jasper Zhang is the CEO and Co-founder of Hyperbolic. A mathematical prodigy, he completed his Ph.D. in Mathematics at UC Berkeley in just two years. He is a Gold Medalist in both the Alibaba Global Math Competition and the Chinese Mathematical Olympiad. Before founding Hyperbolic, he held roles at Ava Labs and Citadel Securities, bringing deep expertise in quantitative finance and AI.",
    "X (Twitter)": "https://x.com/zjasper666",
    "LinkedIn": "https://www.linkedin.com/in/yuezhang95/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/dd71-400o400o1-fJG88PsUEVX7XTXyfoHZ7b.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "905305",
        "Title": "Building Hyperbolic: The On-Demand AI Cloud for GPUs, Inference, and AI Services",
        "Description": "AI moves fast. Legacy cloud can’t keep up. This session breaks down how Hyperbolic is redefining what developers should expect from AI infrastructure. We’ll cover how to instantly spin up low-cost GPUs, serve cutting-edge models with serverless inference, and deploy AI services at scale without the DevOps, rate limits, or pricing surprises. Whether you're training, fine-tuning, or just shipping fast, this is the new standard for building with AI.",
        "Format": "Talk",
        "Level": "Expert",
        "Scope": "Technical deep dive",
        "Tracks": "Infrastructure",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "155070cc-ad6b-4382-9085-2a872555c9bb",
    "Name": "Devansh Tandon",
    "Company": "Google",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.google.com/",
    "Company Website": "",
    "Title": "Principal Product Manager",
    "TagLine": "Principal Product Manager ",
    "Bio": "Devansh Tandon is a Principal Product Manager at Google, leading YouTube’s discovery system and GenAI efforts. At YouTube, Devansh leads a team of research scientists and ML engineers to develop the recommendation engine, which powers 70%+ of YouTube watchtime for 2B+ daily active users. \r\n\r\nHe led Google DeepMind & YouTube partnerships, and has launched GenAI products including video summaries & AI dubbing for YouTube. At DeepMind, Devansh led the development of a new generative recommendation system – adapting Gemini to power YouTube recommendations – from research to scaled consumer launch for 200m+ DAU. \r\n\r\nPreviously, Devansh has led AI teams in Google Search, Google News and Google Ads. He graduated Magna Cum Laude from Yale University, with a BS in Computer Science and Economics.  ",
    "X (Twitter)": "https://x.com/devanshtandon_",
    "LinkedIn": "https://www.linkedin.com/in/devanshtandon/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/6bb5-400o400o1-VTEFgfQNYAUbPERTbzh4yr.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "906567",
        "Title": "Teaching Gemini to Speak YouTube: Adapting LLMs for Video Recommendations to 2B+ DAU",
        "Description": "YouTube recommendations drive nearly two-thirds of the platform's staggering 5 billion daily watch hours for 2 billion+ DAU. Traditionally powered by large embedding models (LEMs), we're undertaking a fundamental shift: rebuilding our recommendation stack using foundation models like Gemini. This talk dives into our engineering journey adapting general-purpose LLMs (Gemini) for the highly specialized, dynamic, and massive-scale task of YouTube recommendations.\r\n\r\nWe'll start with a critical first step: creating a \"language\" for YouTube videos. Learn how we developed 'SemanticID', a novel tokenization scheme that distills multimodal video features (text, audio, frames) into discrete tokens representable by an LLM. Our paper (Better Generalization with Semantic IDs: A Case Study in Ranking for Recommendations) is a landmark work in this space.  \r\n\r\nWe then adapt the base Gemini checkpoint to understand sequences of these video tokens alongside natural language, effectively teaching it the grammar of user watch behavior. A key insight: unlike static LLM training, YouTube's corpus evolves so rapidly (millions of new videos daily) that daily retraining is non-negotiable to maintain recommendation quality.\r\n\r\nNow we can prompt LRM with user history and context to generate personalized candidate recommendations, achieving the biggest engagement wins on YouTube in the last ~decade. \r\n\r\nThere’s a lot of attention on the LLM-led transformation of Search (with AI Overviews, Perplexity, ChatGPT-Search etc). However, across large consumer apps, it’s the recommendation systems & feeds that drive most consumer engagement, not just search (eg. YouTube recs drive 67% of WatchTime). This talk is about the LLM-led transformation of recommendations & feeds – building a recommendation engine on top of Gemini.\r\n",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "RecSys",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "4705a4cd-bdb4-461f-a90a-82b02a2b2177",
    "Name": "Michael Zhi Yu Luo",
    "Company": "UC Berkeley",
    "Company Domain": "berkeley.edu",
    "Company URL": "",
    "Company Website": "",
    "Title": "PhD Candidate",
    "TagLine": "UC Berkeley, PhD",
    "Bio": "Michael Luo is a 4th year PhD at UC Berkeley, advised by Ion Stoica. His research covers training agents and building agent systems.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/0c88-400o400o1-7ot7J2uC8SCGmn8vZ85iFS.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "906694",
        "Title": "DeepCoder: A Fully Open-Source 14B Coder at O3-Level",
        "Description": "This talk covers the full training recipe to achieve O3-level for coding.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Reasoning+RL",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "c849b8ac-e452-466a-a7dd-5c163c2780e2",
    "Name": "Dan Mason",
    "Company": "Stride",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.stride.build/",
    "Company Website": "http://stride.build",
    "Title": "Principal, AI",
    "TagLine": "Principal, Head of AI",
    "Bio": "Dan Mason\r\nPrincipal, AI - Stride\r\n\r\nDan is a product and technology leader with unusually broad experience -- in 20+ years at companies like ESPN, Shutterstock, Viacom, NBCUniversal and a variety of startups and scaleups, he’s accumulated a wealth of knowledge about how digital product development works (and doesn’t), and is excited to apply those insights to reimagining teams and products in the age of LLMs.   He is an engineer turned product manager with strong technical skills, and the teams he leads are highly cross-functional -- often including product, technology, design, PMO and data science. \r\n\r\nDan leads Stride’s AI/LLM practice and is focused on thought leadership, code generation, workflow automation, and shaping and leading generative AI client engagements.  He is also an active product coach and consultant, and a member of Docker’s Technical Advisory Group.  Dan lives in New Jersey with his wife and three busy teenagers, and holds a BA in Computer Science and English Literature from Williams College.\r\n",
    "X (Twitter)": "http://x.com/danmason",
    "LinkedIn": "http://www.linkedin.com/in/dnmason",
    "Blog": "http://jpsj.me",
    "Profile Picture": "https://sessionize.com/image/b32e-400o400o1-RexErF1ktkKWJAvUg7cyQc.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "907544",
        "Title": "Case Study + Deep Dive: Telemedicine Support Agents with LangGraph/MCP",
        "Description": "Workshop/walkthrough of a Stride/Avila Science partnership to build agentic telemedicine support",
        "Format": "Workshop",
        "Level": "Advanced",
        "Scope": "Case Study/War Story",
        "Tracks": "AI in Action",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "210c2993-39c7-40d5-bf2a-73d5795d287a",
    "Name": "David Karam",
    "Company": "Pi Labs",
    "Company Domain": "withpi.ai",
    "Company URL": "",
    "Company Website": "https://withpi.ai",
    "Title": "Co-founder",
    "TagLine": "CEO",
    "Bio": "I'm David K. I love straddling the line between deep tech research and application development. I’ve spent a decade at Google as Product Director working on Search’s core AI and NLU systems, helping Search’s own version of “AI Engineers” develop magical applications. Around a year ago I left with my cofounder to start Pi Labs where we’re trying to bring that same spirit to the rest of the industry. Outside work I love to read, cook, and spend time in nature.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/dskaram/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/ce69-400o400o1-paRtRckcMShnkTvVacSEzy.jpg",
    "Session Count": 2,
    "Sessions": [
      {
        "Session ID": "907684",
        "Title": "Scoring models beat LLM judges any day of the week",
        "Description": "Do you wish your LLM judge was highly accurate, rapid fast, data-tunable, and continuously integrated across your stack? This talk describes a new architecture for AI metrics based on foundation scoring models and a set of integrations that run above them. This architecture was inspired by decades of AI and machine learning development in Google Search, reinvented for the modern LLM stack by our team over the past year. \r\n\r\nWe will share the history of that trajectory and then dive into the technical details: the use of encoder models trained specifically for scoring to enable higher accuracy and lower latency and the deployment of auto-generated tunable metric trees that can combine a wide variety of soft and hard signals across your stack into a human-calibrated score. We’ll end with various examples of how these scoring models are being deployed across the whole stack from online control flows for agents, to reward models for algorithms like RL, to rankers for inference time scaling methods like ensemble generation.\r\n",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Evals",
        "Room": "",
        "Scheduled At": ""
      },
      {
        "Session ID": "907695",
        "Title": "Layering every technique in RAG, one query at a time",
        "Description": "Start with the simplest Search - in-memory embeddings with relevance ranking. End with the most complex planet-scale Search - 70+ corpus mix of token, embeddings, and knowledge graphs, all jointly retrieved, custom ranked, joint re-ranked, and then LLM-processed, at 160,000 queries per second in under 200msec.\r\n\r\nThis talk will be a fun “one query at a time” survey of all techniques in RAG in incremental complexity, showing the limits of each technique and what the next layered one opens up in terms of capabilities to handle ever-more complex queries in RAG. You’ll learn why queries like [falafel] are notoriously hard to Search over, why chunking your documents can be disastrous, how you can sometimes can get away with a simple bm25, and how some Search problems are so hard to solve that you’re better off punting the problem to the LLM or the UX. Brought to you by the team that worked on 50+ Search products, in the context of Google.com and custom Enterprise Search.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "5c1894f2-b91e-48f1-a1f2-b67c8effc3d0",
    "Name": "Michael Albada",
    "Company": "Microsoft Security AI Research",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.microsoft.com/en-us/research/video/ai-and-security/?msockid=043945adec02666a0fcc5073ed8a6700",
    "Company Website": "https://michaelalbada.com",
    "Title": "Machine Learning Engineer and Applied AI Researcher",
    "TagLine": "Principal Applied Scientist",
    "Bio": "Michael Albada is a machine learning engineer and applied AI researcher focused on building agentic systems that bridge research and real-world impact. At Microsoft, he leads initiatives applying generative AI to cybersecurity, helping protect organizations and individuals through intelligent automation.\r\n\r\nMichael has previously developed large-scale ML systems for geospatial intelligence at Uber and natural language understanding at ServiceNow. His work spans consumer products, enterprise SaaS, and applied research, with deep expertise in foundation models, recommender systems, NLP, and scalable ML infrastructure, and he holds a B.A. from Stanford, MPhil from Cambridge, and an MS in computer science from Georgia Tech.\r\n\r\nHe is the author of the upcoming O’Reilly book Building Applications with AI Agents, a practical guide to designing and deploying single- and multi-agent systems with foundation models. As a speaker, Michael brings a passion for turning complex research into actionable insights—and for equipping engineers to build the next generation of AI-powered applications. ",
    "X (Twitter)": "https://x.com/michaelalbada",
    "LinkedIn": "https://www.linkedin.com/in/albada/",
    "Blog": "https://theneuralnexus.substack.com/",
    "Profile Picture": "https://sessionize.com/image/86a0-400o400o1-GVeeLaHhznoN9xHFcdKA6W.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "907834",
        "Title": "Building Applications with AI Agents",
        "Description": "Generative AI has dramatically shortened the distance between ideas and implementation, enabling faster prototyping and deployment than ever before. But while language models can streamline individual tasks, true transformation comes from combining these capabilities into intelligent, autonomous systems—AI agents.\r\n\r\nThis talk explores how to build and deploy foundation model-enabled agent systems that go beyond simple prompt chaining or chatbots. Drawing from real-world implementations and the latest research, it offers a clear and practical path to designing both single-agent and multi-agent systems capable of handling complex workflows with minimal oversight.\r\n\r\nAttendees will gain a deeper understanding of the core design principles behind agentic systems, the architectural trade-offs involved in orchestrating multiple agents, and the strategies required to develop tailored solutions that enhance efficiency and innovation. Whether just beginning or scaling up, participants will leave with actionable insights to navigate the rapidly evolving world of AI autonomy.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Leadership: Architects",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "3a74e448-594e-4322-9578-c04d843724b7",
    "Name": "Jonathan Mortensen",
    "Company": "Confident Security",
    "Company Domain": "confidentsecurity.com",
    "Company URL": "https://confident.security/",
    "Company Website": "https://confident.security",
    "Title": "CEO",
    "TagLine": "CEO",
    "Bio": "Jonathan Mortensen is a technology executive and founder with expertise spanning AI, data infrastructure, and cybersecurity. Currently serving as CEO of a stealth AI startup and Founder Fellow at South Park Commons, Jonathan previously founded bit.io, a multi-cloud serverless PostgreSQL platform acquired by Databricks. As bit.io's CTO, he built innovative database technology that handled hundreds of thousands of databases securely across multiple cloud providers. Prior to founding bit.io, Jonathan led data science and engineering teams at BlueVoyant, where he designed high-volume data pipelines processing 50 million events per second. He holds a PhD in Biomedical Informatics from Stanford University and combines technical depth with leadership experience across engineering, revenue, and operations.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/jonathanmortensen/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/e696-400o400o1-WVBy6tYtCrRMBBsykwHt4T.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "909905",
        "Title": "The Unofficial Guide to Apple’s Private Cloud Compute",
        "Description": "In October 2024, Apple released a new private AI technology onto millions of devices called “Private Cloud Compute”. It brings the same level of privacy and security a local device offers but on an “untrusted\" remote server. This talk discusses how Private Cloud Compute represents a paradigm shift in confidential computing and explores the core advancements that made it possible to become mainstream. We’ll explore its novel architecture that allows developers to run sensitive, multi-tenant workloads with cryptographically-provably privacy guarantees at scale and at reasonable cost. Attendees will leave with an understanding of how to leverage this technology for data and AI applications where privacy and security is paramount.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Security",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "cfff00f5-73e9-4881-bb4a-b9e34b98b26e",
    "Name": "Gorkem Yurtseven",
    "Company": "fal",
    "Company Domain": "fal.ai",
    "Company URL": "https://fal.ai/",
    "Company Website": "",
    "Title": "Co-founder and CTO",
    "TagLine": "CTO ",
    "Bio": "Gorkem Yurtseven is the co-founder and CTO of fal, a generative media platform empowering developers to build with cutting-edge AI models. Previously, he was a Senior Software Engineer at AWS and holds a degree in Computer Engineering from the University of Pennsylvania.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/gorkemy/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/0248-400o400o1-S1h1zJfr2zCBnGvaWQN9j.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "910158",
        "Title": "The State of Generative Media Today",
        "Description": "Generative AI is reshaping the creative landscape, enabling the production of images, audio, and video with unprecedented speed and sophistication. This session offers an in-depth exploration of the current state of generative media, highlighting cutting-edge models, platforms, and tools that are transforming the industry. ",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Technical deep dive",
        "Tracks": "Generative Media",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "fff30ce6-b9f4-4043-b85c-0d1bee36eb22",
    "Name": "Kelvin Ma",
    "Company": "Google Photos",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.google.com/intl/en_us/photos/about/",
    "Company Website": "https://www.google.com/intl/en_us/photos/about/",
    "Title": "Product Engineer",
    "TagLine": "Software Engineer ",
    "Bio": "I'm Kelvin Ma. A product engineer with 15 years of experience working across innovative consumer applications that is used by millions of consumers. I'm passionate about using technology to build tools that improves users lives by allowing greater expression, building skills, and fostering communication.  ",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/kelvin-ma-6512bb12/",
    "Blog": "https://blog.kelvin.ma/posts/",
    "Profile Picture": "https://sessionize.com/image/1f56-400o400o1-UcpJeF5xe2NCAhuBgnJLk2.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "910197",
        "Title": "Magic Editor Under the Hood: Weaving Generative AI into a Billion-User App",
        "Description": "Go behind the scenes of Google Photos' Magic Editor. Explore the engineering feats required to integrate complex CV and cutting-edge generative AI models into a seamless mobile experience. We'll discuss optimizing massive models for latency/size, the crucial interplay with graphics rendering (OpenGL/Halide), and the practicalities of turning research concepts into polished features people actually use.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Generative Media",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "61c5d52b-517f-45fb-ac0a-ca1acdd5180d",
    "Name": "Philipp Schmid",
    "Company": "Google DeepMind",
    "Company Domain": "google.com",
    "Company URL": "https://deepmind.google/",
    "Company Website": "",
    "Title": "Senior AI Developer Relations Engineer",
    "TagLine": "AI Developer Experience",
    "Bio": "Philipp Schmid is a Senior AI Developer Relations Engineer at Google DeepMind working on Gemini, Gemma with the mission to help every developer and builder to create and benefit from AI in a responsible way. ",
    "X (Twitter)": "https://x.com/_philschmid",
    "LinkedIn": "https://www.linkedin.com/in/philipp-schmid-a6a2bb196/",
    "Blog": "https://www.philschmid.de/",
    "Profile Picture": "https://sessionize.com/image/9039-400o400o1-fAE2ViRtc5VLsug3jFkR4W.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "910732",
        "Title": "AI Engineering with the Google Gemini 2.5 Model Family",
        "Description": "Hands on Workshop on learning to use Gemini 2.5 Pro in combination with Agentic tooling and MCP Servers.",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "AI in Action",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "5ed85946-1d55-415e-b2af-5e4feb00cf02",
    "Name": "Sharon Zhou",
    "Company": "Lamini",
    "Company Domain": "lamini.ai",
    "Company URL": "https://www.lamini.ai/",
    "Company Website": "https://lamini.ai",
    "Title": "Co-founder and CEO",
    "TagLine": "CEO",
    "Bio": "Dr. Sharon Zhou is the co-founder and CEO of Lamini, which has won this year’s VentureBeat Gen AI Startup Award and has been recognized as a Forbes Cloud 100 Rising Star. As a former faculty member at Stanford, she led a 50+ person Generative AI research group and published award-winning papers in generative AI. Sharon teaches some of the most popular AI courses on Coursera, including Fine-tuning LLMs, reaching millions of professionals. She earned her PhD in AI from Stanford, where she was advised by Dr. Andrew Ng. Before her PhD, she worked as an AI product manager at Google. She received her bachelor's degree in computer science and Classics from Harvard. Additionally, Sharon has served as an AI advisor in Washington, D.C., and has been featured in MIT Technology Review’s 35 Under 35 list.",
    "X (Twitter)": "https://x.com/realSharonZhou/",
    "LinkedIn": "https://www.linkedin.com/in/zhousharon/",
    "Blog": "https://lamini.ai/blog",
    "Profile Picture": "https://sessionize.com/image/e748-400o400o1-VL15xTuayZHeuqkmaPhLAj.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "911270",
        "Title": "Want reliable agents? Generate better (synthetic) data.",
        "Description": "You don’t need a bigger model. You need better synthetic data.\r\n\r\nIn this talk, we’ll demonstrate how you can build reliable, domain-specific agents, without manually labeling thousands of samples. \r\n\r\nUsing agentic data pipelines, you can finally achieve 9s of accuracy—e.g., 95%+ accuracy on domain-specific tasks like Text-to-SQL. We'll show how, with just a handful of high-quality examples, you can generate, validate, and iteratively expand your dataset. \r\n\r\nThis workflow keeps humans in the loop where they add the most value (spotting inconsistencies, defining edge cases, etc.) while letting LLMs do what they do best (finding patterns, generating diverse examples, enforcing structure, etc.). The result is faster iteration and higher-quality training data—without tedious and expensive manual labeling.\r\n\r\nBuilding reliable agents also requires good evaluation data sets. Evaluations are critical for measuring alignment with your training objectives. Again, using agentic pipelines, you can continuously assess model performance, identify failure modes, and generate more synthetic data to further improve your model. \r\n\r\nWith this proven approach, you can train smaller models to be experts in your domain with a small amount of data in a relatively short amount of time. \r\n\r\n",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Agent Reliability",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "fa5f22ad-339b-485d-bbf2-620cbd069be9",
    "Name": "Damien Murphy",
    "Company": "Google",
    "Company Domain": "bench.io",
    "Company URL": "",
    "Company Website": "https://bench.io",
    "Title": "Full Stack Developer",
    "TagLine": "Founding Solutions Engineer @ Bench",
    "Bio": "Full Stack Dev for 20+ years focusing on AI Agents",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/damienm1/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/2926-400o400o1-ptD5NY2jT64p32qQh2v4M2.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "911821",
        "Title": "A2A & MCP: Automating Business Processes with LLMs",
        "Description": "Ever wished your webhooks could think for themselves? Join us to discover how A2A agents can transform passive webhook endpoints into intelligent workflow processors.\r\n\r\nIn this session, we'll show you how to build a system that automatically spawns AI Agents to handle incoming webhooks. \r\n\r\nUsing Google's Agent-to-Agent framework and MCP, you'll learn how to create dynamic AI agents that respond to events, communicate with external services, and make decisions based on content analysis.\r\n\r\nSee the future of workflow automation where webhooks don't just trigger actions—they trigger intelligence!",
        "Format": "Workshop",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "MCP",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "6f7997a2-1fef-42ef-947e-9c80e4648c0f",
    "Name": "Hassan El Mghari",
    "Company": "Together AI",
    "Company Domain": "together.ai",
    "Company URL": "https://www.together.ai/",
    "Company Website": "https://www.together.ai/",
    "Title": "Lead, Developer Relations",
    "TagLine": "DevRel lead ",
    "Bio": "Hassan El Mghari is a software engineer based in New York specializing in building full-stack AI applications. His AI applications have a combined user base of over 3 million. He currently leads the developer relations team at Together.ai, where his work includes building example AI apps, creating content, and educating developers on AI development.",
    "X (Twitter)": "https://twitter.com/nutlope",
    "LinkedIn": "https://www.linkedin.com/in/nutlope/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/2767-400o400o1-MnFYxtNJ6podCsRVudboUA.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "911846",
        "Title": "Using OSS models to build AI apps with millions of users",
        "Description": "In this talk, Hassan will go over how he builds open source AI apps that get millions of users like roomGPT.io (2.9 million users), restorePhotos.io (1.1 million users), Blinkshot.io (1 million visitors), and LlamaCoder.io (1.4 million visitors). He'll go over his journey in AI, demo some of the apps that he's built, and dig into his tech stack and code to explain how he builds these apps from scratch. He’ll also go over how to market them and go over his top tips and tricks for building great full-stack AI applications quickly and efficiently.\r\n\r\nThis talk will start from first principles and give you a glimpse into Hassan’s workflow of idea -> working app -> many users. Attendees should come out of this session equipped with the resources to build impressive AI applications and understand some of the behind the scenes of how they’re built and marketed. This will hopefully serve as an educational and inspirational talk that encourages builders to go build cool things.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Tiny Teams",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "bb2ab6f3-c148-4f33-b1c8-da2ecdc1b6c7",
    "Name": "Samuel Colvin",
    "Company": "Pydantic Inc.",
    "Company Domain": "pydantic.dev",
    "Company URL": "",
    "Company Website": "https://pydantic.dev/",
    "Title": "Founder",
    "TagLine": "Founder of Pydantic",
    "Bio": "Samuel Colvin is a Python and Rust developer, and Founder of Pydantic Inc., backed by Sequoia to build Pydantic Logfire (AI observability) and PydanticAI (production grade Agent Framework).\r\n\r\n The Pydantic library, which he created in 2017, is downloaded over 300M times per month and is a core component of virtually every GenAI Python library (both provider SDKs and agent frameworks).",
    "X (Twitter)": "https://x.com/samuel_colvin",
    "LinkedIn": "https://www.linkedin.com/in/samuel-colvin/",
    "Blog": "https://github.com/samuelcolvin",
    "Profile Picture": "https://sessionize.com/image/bbf4-400o400o1-Y9XzjuwEQJkVe5LdLiuGmB.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "911925",
        "Title": "MCP is all you need",
        "Description": "Everyone is talking about agents, and right after that, they’re talking about agent-to-agent communications. Not surprisingly, various nascent, competing protocols are popping up to handle it.\r\n\r\nBut maybe all we need is MCP — the OG of GenAI communication protocols (it's from way back in 2024!).\r\n\r\nLast year, Jason Liu gave the second most watched AIE talk — “Pydantic is all you need”.\r\n\r\nThis year, I (the creator of Pydantic) am continuing the tradition by arguing that MCP might be all we need for agent-to-agent communications.\r\n\r\nWhat I’ll cover:\r\n\r\n- Misusing Common Patterns: MCP was designed for desktop/IDE applications like Claude Code and Cursor. How can we adapt MCP for autonomous agents?\r\n- Many Common Problems: MCP is great, but what can go wrong? How can you work around it? Can the protocol be extended to solve these issues?\r\n- Monitoring Complex Phenomena: How does observability work (and not work) with MCP?\r\n- Multiple Competing Protocols: A quick run-through of other agent communication protocols like A2A and AGNTCY, and probably a few more by June 😴\r\n- Massive Crustaceans Party: What might success look like if everything goes to plan?",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "MCP",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "3c85e31c-c243-4811-8ce4-30f89896ef7c",
    "Name": "Alvaro Morales",
    "Company": "Orb",
    "Company Domain": "aircoverpr.com",
    "Company URL": "https://www.withorb.com/",
    "Company Website": "https://www.withorb.com/",
    "Title": "CEO and co-founder",
    "TagLine": "Co-founder and CEO",
    "Bio": "Alvaro Morales is the co-founder and CEO of Orb, a leading billing and monetization platform enabling SaaS and GenAI companies to adopt flexible, usage-based, and outcome-driven pricing models. Since founding Orb in 2021, he has helped businesses transition from traditional seat-based pricing to dynamic, data-driven monetization strategies that scale with customer value. Previously, he led growth engineering at Asana, optimizing pricing and revenue strategies. Morales holds Master’s and Bachelor’s degrees in Computer Science from MIT and has worked at Palantir, Yahoo!, and MIT’s CSAIL. A fintech innovator, he is shaping the future of AI monetization in a usage-based economy.",
    "X (Twitter)": "https://x.com/alvaromorales",
    "LinkedIn": "https://www.linkedin.com/in/alvaro-morales/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/6c39-400o400o1-JBNFJeGFzwhuctMDmcV6j5.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "912033",
        "Title": "Monetizing AI: From Zero to Profit",
        "Description": "As AI continues to transform industries, companies are faced with the critical challenge of effectively monetizing AI-driven products in a way that captures value, ensures customer adoption, and scales revenue sustainably. Unlike traditional SaaS models, AI-powered products have unique complexities - such as fluctuating usage patterns, variable compute costs, and evolving customer demands, making conventional pricing strategies unhelpful to the growth of an AI product-led startup.\r\n\r\nIn this session, Alvaro Morales, CEO and co-founder of Orb, will explore why the often overlooked monetization aspect of AI is critical for businesses. He’ll share real-world examples and data to demonstrate how adaptive pricing models can drive cost savings, enhance customer experience, and reduce operational bottlenecks.\r\n\r\nAlvaro will lead a live demo, showcasing how engineers can simulate AI pricing strategies and subsequently integrate them with a simple plug-and-play solution. He’ll also share how real-world revenue simulations enable companies to test and refine pricing before implementing — reducing risk, boosting adoption, and unlocking new revenue streams. As a quick example, cloud software development platform Replit was looking to adopt a usage-based pricing model for a new product, but their existing billing system couldn't support the new model, and building a new billing system would delay the launch timeline. In order to get things done, they turned to Orb, which enabled them to make pricing changes up to the last minute. After the launch, Orb became the single source of truth for both Replit and its customers - providing usage alerts to notify Replit when users hit cost thresholds and provide insights into user spend and payment methods.\r\n\r\nKey takeaways: \r\nThe challenge of AI monetization – Why traditional subscription-based SaaS pricing models don’t work for AI-powered products.\r\nPrecision pricing – Exploring how usage-based, tiered, and hybrid pricing models can maximize revenue potential. \r\nRevenue simulation for AI pricing – Leveraging real-time data to test, adjust and optimize pricing strategies.\r\nAvoiding common pricing pitfalls – Identifying mistakes that can lead to revenue leakage and customer churn.\r\n\r\nThis session is designed for AI executives, product leaders, and engineering teams looking for actionable strategies to build adaptive, scalable pricing models that drive long-term growth and profitability.\r\n\r\n",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "Leadership: Architects",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "3f1fc718-d686-4c68-9a90-3127e4d56977",
    "Name": "Sam Julien",
    "Company": "Writer",
    "Company Domain": "writer.com",
    "Company URL": "https://writer.com/",
    "Company Website": "http://www.writer.com",
    "Title": "Director of Developer Relations",
    "TagLine": "Director of Developer Relations ",
    "Bio": "Sam Julien is the Director of Developer Relations at Writer and is passionate about helping engineers improve their effectiveness and advance their careers. He loves spending time outside with his family in the Pacific Northwest. You can find more of Sam's work at samjulien.com.",
    "X (Twitter)": "https://twitter.com/samjulien",
    "LinkedIn": "https://www.linkedin.com/in/samjulien/",
    "Blog": "http://www.samjulien.com/",
    "Profile Picture": "https://sessionize.com/image/d8ef-400o400o1-shSzxoCEXpouBFY9r148f5.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "912811",
        "Title": "When Vectors Break Down: Graph-Based RAG for Dense Enterprise Knowledge",
        "Description": "Enterprise knowledge bases are filled with \"dense mapping,\" thousands of documents where similar terms appear repeatedly, causing traditional vector retrieval to return the wrong version or irrelevant information. When our customers kept hitting this wall with their RAG systems, we knew we needed a fundamentally different approach.\r\n\r\nIn this talk, I'll share Writer's journey developing a graph-based RAG architecture that achieved 86.31% accuracy on the RobustQA benchmark while maintaining sub-second response times, significantly outperforming vector approaches.\r\n\r\nI'll survey the key techniques behind this performance leap and why graph-based approaches excel with complex enterprise information structures like product documentation, financial documents, and technical specifications that challenge traditional RAG systems. You'll learn about using specialized LLMs to build semantic relationships, how compression techniques efficiently handle concentrated enterprise data patterns, and how infusing key data points in the memory layer of the LLM lowers hallucination.\r\n\r\nThe presentation will provide practical insights into identifying when graph-based approaches make sense for your organization's specific data challenges, helping you make informed architectural decisions for your next enterprise RAG system.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "GraphRAG",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "3d517cc2-a374-4d44-a137-3baecda39663",
    "Name": "Gavin  Uberti",
    "Company": "Etched",
    "Company Domain": "etched.com",
    "Company URL": "https://www.etched.com/",
    "Company Website": "https://www.etched.com/",
    "Title": "Co-founder and CEO",
    "TagLine": "CEO",
    "Bio": "Gavin Uberti is the co-founder and CEO of Etched. Prior to founding Etched, Gavin worked at OctoAI (formerly OctoML), where he developed software to improve the performance of AI models. He has guest lectured at Columbia University and TinyML. Gavin dropped out of Harvard University, where he was concurrently pursuing a bachelor's in math and a master's in computer science.",
    "X (Twitter)": "https://x.com/UbertiGavin",
    "LinkedIn": "https://www.linkedin.com/in/guberti/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/9ecc-400o400o1-Hb9ZHtXJdR2mJwGQZ5Z2L5.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "912986",
        "Title": "Flipping the Inference Stack: Why GPUs Bottleneck Real-Time AI at Scale",
        "Description": "AI inference today is stuck in a loop: throw more GPUs at the problem, scale horizontally, rinse and repeat. But that playbook is hitting a wall. Latency, cost, and energy grids are all suffering, and the capability for real-time AI at scale looks further and further away. In this talk, AI hardware expert and founder Gavin Uberti will break down why the current approach to inference is masking deep inefficiencies, and how rethinking the hardware stack from the ground up (starting with inference-first chips) is the only way to unlock real-time AI at scale. ",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Infrastructure",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "941f74d4-9bd6-47f8-b20c-28895e05e826",
    "Name": "David Mytton",
    "Company": "Arcjet",
    "Company Domain": "arcjet.com",
    "Company URL": "https://arcjet.com/",
    "Company Website": "https://arcjet.com",
    "Title": "Founder",
    "TagLine": "Founder",
    "Bio": "David is the founder of Arcjet, a security as code product that helps developers protect their apps from bots, API abuse, spam, and other attacks. He also writes the weekly console.dev devtools newsletter.",
    "X (Twitter)": "https://x.com/davidmytton",
    "LinkedIn": "https://www.linkedin.com/in/davidmytton/",
    "Blog": "https://davidmytton.blog",
    "Profile Picture": "https://sessionize.com/image/167b-400o400o1-3Xa6zGGMPkfYqAwBCE8ne5.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "913351",
        "Title": "How to defend your sites from AI bots",
        "Description": "Constantly seeing CAPTCHAs? It used to be easy to detect the humans from the droids, but what else can we do when synthetic clients make up nearly half of all web requests. Rotating IPs, spoofed browsers, and agents acting on behalf of real users - are we doomed to forever be solving puzzles?\r\n\r\nIn this talk, we’ll explore user agents, HTTP fingerprints, and IP reputation signals that make humans and agents stand out from scrapers, build a realistic threat model, and dig into the behaviors that reveal the LLM-mimicry. Leave with AX- and UX-safe code, benchmarks, and tools to help you take back control.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Security",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "0bfc23a2-2561-42b7-a0c5-8a992dca6bc4",
    "Name": "Preeti Somal",
    "Company": "Temporal",
    "Company Domain": "moxiegrouppr.com",
    "Company URL": "https://temporal.io/",
    "Company Website": "https://temporal.io/",
    "Title": "Senior Vice President of Engineering",
    "TagLine": "SVP Engineering",
    "Bio": "Preeti is Senior Vice President of Engineering at Temporal. Preeti is passionate about building great products, growing world class organizations and solving complex problems. Prior to Temporal, Preeti led the Platform, Security and IT engineering organizations at HashiCorp. Her extensive career includes engineering leadership roles at Yahoo!, VMware and Oracle. While at Yahoo! Preeti was VP of Cloud Services in the Platform organization delivering highly scalable services used by engineers across Yahoo to build and operate applications with improved agility, reliability and security. These services power Yahoo!’s consumer and advertising business.\r\n",
    "X (Twitter)": "https://x.com/psomal",
    "LinkedIn": "https://www.linkedin.com/in/preeti-somal-131890/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/3776-400o400o1-77P8PG7wuNAKdjxiCsQNDp.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "913755",
        "Title": "Scaling AI agents without breaking reliability",
        "Description": "As AI agents move from prototypes to production, developers are running into new challenges with orchestration, failure handling, and infrastructure. This session will unpack lessons from teams already building real-world systems and share how to design for reliability from the start.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Agent Reliability",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "43c3c635-137d-4ed2-bdad-b8767f9d3e08",
    "Name": "Julia Neagu",
    "Company": "Quotient AI",
    "Company Domain": "quotientai.co",
    "Company URL": "https://www.quotientai.co/",
    "Company Website": "https://www.quotientai.co",
    "Title": "Co-founder and CEO",
    "TagLine": "Co-founder and CEO",
    "Bio": "Julia is the co-founder and CEO of Quotient AI, which provides intelligent observability for AI apps by automatically detecting failures, uncovering root causes, and recommending improvements. Before Quotient, she was the Director of Data for Copilot, GitHub's AI pair programmer, where her team built the systems evaluating the large language models behind Copilot. Previously, she was the Director of Analytics at Tamr and led end-to-end quantitative modeling at Aon's Intellectual Property Solutions group. Julia has a PhD and MA in Physics from Harvard, an AB in Physics from Princeton.",
    "X (Twitter)": "https://x.com/JuliaANeagu",
    "LinkedIn": "https://www.linkedin.com/in/julianeagu/",
    "Blog": "https://blog.quotientai.co",
    "Profile Picture": "https://sessionize.com/image/8209-400o400o1-4YzMawHbhpq483ah1puTk5.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "913839",
        "Title": "Evaluating AI Search: A Practical Framework for Augmented AI Systems",
        "Description": "AI search is becoming the front door to information, whether through Retrieval-Augmented Generation (RAG), Search-Augmented Generation (SAG), or custom agents that synthesize answers on top of indexed content. As users rely more heavily on these systems, evaluating their quality becomes mission-critical. But traditional metrics like precision and recall don’t capture the full picture.\r\n\r\nIn this talk, we introduce a practical evaluation framework for AI-powered search, across three dimensions:\r\n- Are the retrieved sources relevant to the query?\r\n- And is the final answer complete?\r\n- Are the sources faithfully used in the generated answer?\r\n\r\nWe’ll share lessons from working with search companies and present early findings from a new benchmark evaluating popular augmented AI systems across these dimensions. Rather than ranking winners and losers, we explore where different systems excel or break down, and how these tradeoffs inform product decisions.\r\n\r\nThis talk is for AI engineers and product teams who want to build trusted, high-quality AI search experiences, and need a way to measure if it’s actually working.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "854869f9-a386-4aab-b82d-18cae7cb2edb",
    "Name": "Deanna Emery",
    "Company": "Quotient AI",
    "Company Domain": "quotientai.co",
    "Company URL": "https://www.quotientai.co/",
    "Company Website": "https://www.quotientai.co/",
    "Title": "Founding AI Researcher",
    "TagLine": "Founding AI Researcher",
    "Bio": "Deanna is the Founding AI Researcher at Quotient AI, where she is leading research on evaluation of Large Language Models in real-world products and applications. Before Quotient, Deanna was a Principal Data Scientist at Aon, where she led the team building language models for valuation of intellectual property assets. She began her career as a researcher at Harvard-Smithsonian Center for Astrophysics and Caltech LIGO. Deanna has a MS in Machine Learning from UC Berkeley and BA in Physics from Harvard University. She is passionate about diversity and inclusion in STEM; she has conducted research on diversity in named patent inventors, working with companies to measure and address diversity gaps, and she is an active board member at a STEM education non-profit.",
    "X (Twitter)": "https://x.com/DeannaLEmery",
    "LinkedIn": "https://www.linkedin.com/in/deanna-emery/",
    "Blog": "https://blog.quotientai.co/",
    "Profile Picture": "https://sessionize.com/image/2da3-400o400o1-G2BZr4Vp16J2uGz7DrPhBj.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "913839",
        "Title": "Evaluating AI Search: A Practical Framework for Augmented AI Systems",
        "Description": "AI search is becoming the front door to information, whether through Retrieval-Augmented Generation (RAG), Search-Augmented Generation (SAG), or custom agents that synthesize answers on top of indexed content. As users rely more heavily on these systems, evaluating their quality becomes mission-critical. But traditional metrics like precision and recall don’t capture the full picture.\r\n\r\nIn this talk, we introduce a practical evaluation framework for AI-powered search, across three dimensions:\r\n- Are the retrieved sources relevant to the query?\r\n- And is the final answer complete?\r\n- Are the sources faithfully used in the generated answer?\r\n\r\nWe’ll share lessons from working with search companies and present early findings from a new benchmark evaluating popular augmented AI systems across these dimensions. Rather than ranking winners and losers, we explore where different systems excel or break down, and how these tradeoffs inform product decisions.\r\n\r\nThis talk is for AI engineers and product teams who want to build trusted, high-quality AI search experiences, and need a way to measure if it’s actually working.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "59c828a3-f138-42e6-aef6-658fb368a5f5",
    "Name": "Dani Grant",
    "Company": "Jam.dev",
    "Company Domain": "jam.dev",
    "Company URL": "https://jam.dev/",
    "Company Website": "https://jam.dev",
    "Title": "CEO",
    "TagLine": "CEO",
    "Bio": "Dani Grant is the CEO of Jam, a dev tools startup helping 65,000+ improve their bug reporting process, backed by executives from Apple, GitHub, and Vercel, and VCs such as Village Global (LPs include Mark Zuckerberg, Bill Gates, Jeff Bezos). Before Jam, Dani was an early product manager at Cloudflare, where she worked on core developer products such as 1.1.1.1 (now used by 10 million+ people). She also worked as a VC at Union Square Ventures.",
    "X (Twitter)": "https://x.com/thedanigrant",
    "LinkedIn": "https://www.linkedin.com/in/danigrant/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/f54d-400o400o1-BmuFhJE6JSR34GDt7z5Gok.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "913965",
        "Title": "The AI Engineer’s Guide to Raising VC",
        "Description": "A no fluff, all tactics discussion. More AI engineers should build startups, the world needs more software. But there’s a way to raise VC and it’s hard to do it if you’ve never seen it done. We are going to walk through the exact playbook to raise your first round of funding. We will show you real pitch decks, real cold emails and real term sheets so when you go out to raise your first round of funding, you are setup to do it. Every AI Engineer should be equip to start their own company and this session makes sure raising $$$ is not going to be the blocker.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Leadership: Architects",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "1e3aac41-c748-4eae-a84a-5234414c6983",
    "Name": "Chelcie Taylor",
    "Company": "Notable Capital",
    "Company Domain": "notablecap.com",
    "Company URL": "https://www.notablecap.com/",
    "Company Website": "",
    "Title": "Early Stage AI Apps Investments Lead",
    "TagLine": "Investor ",
    "Bio": "Leading early stage AI apps investments at Notable Capital ($5B AUM VC). ",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/c820-400o400o1-NLe4TJ95okX5sEofbe6bjJ.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "913965",
        "Title": "The AI Engineer’s Guide to Raising VC",
        "Description": "A no fluff, all tactics discussion. More AI engineers should build startups, the world needs more software. But there’s a way to raise VC and it’s hard to do it if you’ve never seen it done. We are going to walk through the exact playbook to raise your first round of funding. We will show you real pitch decks, real cold emails and real term sheets so when you go out to raise your first round of funding, you are setup to do it. Every AI Engineer should be equip to start their own company and this session makes sure raising $$$ is not going to be the blocker.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Leadership: Architects",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "7d64d49c-59de-4f07-86ac-ca54f40cbff8",
    "Name": "Rustin Banks",
    "Company": "Google Labs",
    "Company Domain": "google.com",
    "Company URL": "https://labs.google/",
    "Company Website": "https://labs.google/",
    "Title": "AI Product Manager",
    "TagLine": "Product Manager, AI Coding ",
    "Bio": "I'm Rustin, an AI Product Manager at Google Labs. I taught myself to program at age 12 using a compiler I purchased on AOL classifieds. As a teenager I hosted a popular bulletin board system (BBS) out of my cousin’s closet using salvaged 286 computers. I’ve always had a passion for making the world better using technology. When I saw AI write code I dedicated the rest of my career to AI coding. At Google labs I am lucky to explore the frontier of coding models and agents.  ",
    "X (Twitter)": "https://x.com/rustinb",
    "LinkedIn": "https://www.linkedin.com/in/rustinbanks/",
    "Blog": "https://rustinbanks.com/",
    "Profile Picture": "https://sessionize.com/image/e0f8-400o400o1-9FpwPjJj37un3C7rtXE6tv.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914012",
        "Title": "Your Coding Agent Just Got Cloned And Your Brain Isn't Ready",
        "Description": "Will the future engineer code alongside a single coding agent, or will they spend their day orchestrating many agents? Traditional development rewards synchronous focus. This session dives into the significant mindshift required to move from sequential coding to orchestrating parallel agents. We are the builders of \"Jules\", Google's massively parallel asynchronous coding agent (to be opened up in May). We'll share real-world insights from building Jules and explore how to rewire your brain for this powerful new \"post-IDE\" development paradigm.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "SWE Agents",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "8d28dd81-4424-49b9-b16c-507e07ca5dea",
    "Name": "Sam Bhagwat",
    "Company": "Mastra",
    "Company Domain": "gmail.com",
    "Company URL": "https://mastra.ai/",
    "Company Website": "http://mastra.ai/",
    "Title": "Co-founder and CEO",
    "TagLine": "Co-founder",
    "Bio": "Sam is the co-founder and CEO of Mastra and the author of Principles of AI Agents. Previously, Sam was the co-founder of Gatsby.js, the popular web framework.",
    "X (Twitter)": "http://twitter.com/calcsam",
    "LinkedIn": "https://www.linkedin.com/in/sambhagwat/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/f75d-400o400o1-E9ZPVLaCAtZtRZ11JFZFGX.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914015",
        "Title": "Agents vs Workflows: Why Not Both?",
        "Description": "One current hot debate is should you make your top-level abstraction a ReAct type agent running in a loop? or should you make it a structured workflow graph?\r\n\r\nOpenAI is launching their new framework and throwing shade on workflow graph approaches\r\n\r\nTBH we think this whole debate is kinda dumb. \r\n\r\nWe've seen a lot of folks be able to structure the problem in a way that a workflow graph makes a lot of sense. \r\n\r\nWe also see a ton of agents where you need to run the core bit in a loop for a long time.\r\n\r\nYou can also give your agents structured workflow graphs as a tool. You can use structured workflow graphs as a handoff mechanism between agents. What we've seen from the community is frankly that folks need to tinker with multiple approaches and combine primitives in interesting ways\r\n\r\nWe'll share a couple stories where teams ended up with workflow graph based approaches, a couple where teams ended up with agent based approaches, and a couple where a blended approach made sense.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Agent Reliability",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "ccf69e35-16bc-4f6d-8b5c-79d4b374eb1f",
    "Name": "Josh Albrecht",
    "Company": "Imbue",
    "Company Domain": "imbue.com",
    "Company URL": "https://imbue.com/",
    "Company Website": "https://imbue.com/",
    "Title": "CTO and Co-founder",
    "TagLine": "CTO and Co-founder",
    "Bio": "Josh Albrecht is CTO and Co-founder of Imbue, an AI lab launched in 2022 that has since raised $230M at a $1B valuation to create coding agents that make it easier for more people to write software. Josh is also a partner at angel fund Outset Capital, where he invests in promising pre-seed companies. Previously, Josh founded multiple companies including an AI recruiting startup that went through Y Combinator and a 3D injection molding software company that was acquired. He was also an early engineer at Addepar, served as a Thiel Fellow mentor, and published machine learning research as an academic researcher. ",
    "X (Twitter)": "https://x.com/joshalbrecht",
    "LinkedIn": "https://www.linkedin.com/in/joshalbrecht/",
    "Blog": "https://joshalbrecht.com/",
    "Profile Picture": "https://sessionize.com/image/47d9-400o400o1-fhsDJ9SBoUuiAy5EZxX6pZ.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914017",
        "Title": "Beyond the Prototype: Using AI to Write High-Quality Code",
        "Description": "In this case study-based keynote, Josh Albrecht, CTO of Imbue, examines the critical engineering challenges in building AI coding systems that create more than just prototypes. Drawing from Imbue's research developing Sculptor, an experimental coding agent environment, Josh shares key insights into the fundamental technical obstacles encountered when evolving AI-assisted coding from toy applications to more robust software systems. \r\n\r\nThe session will explore approaches to core challenges like safely executing code, managing context across large codebases, automating test generation, and creating systems that can identify potential pitfalls in AI-generated code. Attendees will gain practical insights into the technical underpinnings of next-generation coding agents that aim to handle complex software engineering challenges architecting larger systems, increasing meaningful test coverage and designing systems that are easy to debug—moving us closer to AI systems that can help create maintainable software.\r\n",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "SWE Agents",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "6eba3426-a49c-45a0-af6c-89a89a5d97d9",
    "Name": "Will Bryk",
    "Company": "Exa",
    "Company Domain": "sixeastern.com",
    "Company URL": "https://exa.ai/blog",
    "Company Website": "",
    "Title": "CEO",
    "TagLine": "CEO",
    "Bio": "A year before ChatGPT launched, Will was already spending his time building Exa’s API to crawl the web intelligently, focusing on finding quality sources over SEO spam. Backed by NVIDIA and Lightspeed, Exa now powers products for customers like Databricks, Cursor, and LlamaIndex.",
    "X (Twitter)": "https://x.com/WilliamBryk",
    "LinkedIn": "https://www.linkedin.com/in/william-bryk/",
    "Blog": "https://exa.ai/blog",
    "Profile Picture": "https://sessionize.com/image/28e6-400o400o1-npNk1HpDJ8XS1x9yMjkxiv.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914024",
        "Title": "Building a Smarter AI Agent with Neural RAG",
        "Description": "RAG quality for AI agents is critical, and traditional keyword-based search engines consistently underperform in agentic or multi-step tasks, where semantic grounding and contextual nuance matter most.\r\n\r\nIn this talk, Will Bryk, CEO of Exa will live code two AI agent applications–one using traditional keyword search RAG and one using neural network RAG via vector search. He’ll then evaluate both applications based on task performance, relevance, and latency. With a live demo (no theory or pre-baked applications), the audience will get a firsthand look at the practical differences between keyword and semantic systems in production, and learn embedding strategies, indexing trade-offs, hybrid retrieval techniques, prompt tuning, and more. ",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "a9f28f8a-f80a-4b02-91db-8ef8b0d1fd98",
    "Name": "Victor Dibia",
    "Company": "Microsoft Research",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.microsoft.com/en-us/research/",
    "Company Website": "https://victordibia.com/",
    "Title": "Principal Research Software Engineer",
    "TagLine": "Principal Research Software Engineer, Microsoft Research",
    "Bio": "Victor Dibia is a Principal Research Software Engineer at Microsoft Research where his current work is focused on the design of multi-agent systems powered by Generative AI models. Victor is a core contributor to AutoGen - a leading python open source library for building multi-agent applications and the creator of AutoGen Studio, a low code interface for authoring, testing and debugging multi-agent workflows. ",
    "X (Twitter)": "https://x.com/vykthur",
    "LinkedIn": "https://www.linkedin.com/in/dibiavictor/",
    "Blog": "https://newsletter.victordibia.com/",
    "Profile Picture": "https://sessionize.com/image/27ba-400o400o1-hiaSDw7CaydL52YybJTVH7.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914027",
        "Title": "UX Design Principles for (Semi) Autonomous Multi-Agent Systems",
        "Description": "Autonomous or semi-autonomous multi-agent systems (MAS) involve exponentially complex configurations (system config, agent configs, task management and delegation, etc.). These present unique interface design challenges for both developer tooling and end-user experiences.\r\nIn this session, I'll explore UX design principles for multi-agent systems, addressing critical questions: What is the true configuration space for autonomous MAS? How can users arrive at the correct mental model of an MAS's capabilities, if at all? How can we improve trust and safety through techniques like cost-aware action delegation? What makes agent actions observable? How do we enable seamless interruptibility? Attendees will gain actionable insights to create more transparent, trustworthy, and user-centered multi-agent applications, illustrated through real-world implementations in AutoGen Studio - a low code developer tool built on AutoGen (44k stars on GitHub, MIT license) and similar tools.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Design Engineering",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "18eabb2b-c250-49a1-b522-ed04bf90ca10",
    "Name": "Yogendra Miraje",
    "Company": "FactSet",
    "Company Domain": "gmail.com",
    "Company URL": "",
    "Company Website": "https://www.factset.com/",
    "Title": "AI Engineer",
    "TagLine": "Lead AI Engineer in FactSet",
    "Bio": "I'm a backend engineer turned ML engineer turned AI engineer, with 16 years of experience building intelligent systems. I hold a Master’s degree in Computer Science from Northeastern University in Boston, and I currently work as an AI Engineer in FactSet.\r\n\r\nI'm also the host of AI Blindspot, a podcast where we explore the frontiers of artificial intelligence—and the blind spots we often overlook in its development and deployment.\r\n\r\nWith a strong foundation in systems engineering, deep technical fluency, and a product-minded approach, I focus on aligning autonomous agents with real-world user goals, emphasizing safety, control, and robust evaluation techniques.\r\n\r\nI'm passionate about building AI that’s not just powerful, but grounded, aligned, and truly useful in practice.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/mirajey/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/d02c-400o400o1-Vc48gw6Vdd4CCqVdpWCx3j.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914049",
        "Title": "How to Build Planning Agents without losing control",
        "Description": "Planning agents help solve complex tasks by breaking them into steps. They work across enterprise systems where data lives in many places. These agents are powerful but can be hard to control. This session shows how to use blueprints as guardrails for these agents. I will explain techniques to ensure agents follow the right plan. I will cover evaluation methods to verify agents stay aligned with user goals.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Leadership: Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "b08fa907-c722-40c1-a87f-70cdd1b1abeb",
    "Name": "Dexter Horthy",
    "Company": "HumanLayer",
    "Company Domain": "humanlayer.dev",
    "Company URL": "https://www.humanlayer.dev/",
    "Company Website": "https://humanlayer.dev",
    "Title": "AI Agent Developer",
    "TagLine": "Founder",
    "Bio": "Hey - I'm Dex, and I'm hacking on safer more reliable agents at HumanLayer. HumanLayer helps AI builders create agents that feel more like real coworkers - taking them out of ChatGPT-style interfaces and deploying them into slack, email, or wherever their users already are. Before this I was working on AI Agents that managed SQL warehouses, and did a long stint at replicated.com helping the worlds best software teams deliver Kubernetes apps into customer environments. I've been coding since 17, when I built tools for NASA researchers to navigate the south pole of the moon. Enjoyer of tacos and burpees (not necessarily in that order)",
    "X (Twitter)": "https://twitter.com/dexhorthy",
    "LinkedIn": "https://www.linkedin.com/in/dexterihorthy",
    "Blog": "https://theouterloop.substack.com",
    "Profile Picture": "https://sessionize.com/image/ae9e-400o400o1-MiCnM3v6KqD2jb5Rwr3cCv.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914080",
        "Title": "12 Factor Agents - Principles of Reliable LLM Applications",
        "Description": "Hi, I'm Dex. I've been hacking on AI agents for a while.\r\n\r\nI've tried every agent framework out there, from the plug-and-play crew/langchains to the \"minimalist\" smolagents of the world to the \"production grade\" langraph, griptape, etc.\r\n\r\nI've talked to a lot of really strong founders who are all building really impressive things with AI. Most of them are rolling the stack themselves. I don't see a lot of frameworks in production customer-facing agents.\r\n\r\nI've been surprised to find that most of the products out there billing themselves as \"AI Agents\" are not all that agentic. A lot of them are mostly deterministic code, with LLM steps sprinkled in at just the right points to make the experience truly magical.\r\n\r\nAgents, at least the good ones, don't follow the \"here's your prompt, here's a bag of tools, loop until you hit the goal\" pattern. Rather, they are comprised of mostly just software.\r\n\r\nSo, I set out to answer:\r\n\r\nWhat are the principles we can use to build LLM-powered software that is actually good enough to put in the hands of production customers?\r\n",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Agent Reliability",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "1a1b94ac-0d10-4afd-8c90-a8280da87cbc",
    "Name": "Keegan McCallum",
    "Company": "Luma AI",
    "Company Domain": "keeganmccallum.com",
    "Company URL": "",
    "Company Website": "https://lumalabs.ai",
    "Title": "Head of ML Infrastructure",
    "TagLine": "Head of ML infrastructure at Luma AI",
    "Bio": "I'm Keegan McCallum, the Head of ML infrastructure at Luma AI. I began my career in research focusing on portfolio optimization. Since then I've founded two startups, lead engineering at two others and have landed at Luma AI working on an unconventional multimodal path to AGI among a cracked team of researchers and engineers. When I'm not working, I'm usually out in the woods hiking with my family, or exploring the culinary delights in whatever city I happen to be in. I'm excited to share the insights and war stories I've gathered launching one of the most successful AI products to date in a (hopefully) fun and engaging way",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/keeganmccallum3",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/24e1-400o400o1-Ln1jAmBHhguW8jzCpKLo3V.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914081",
        "Title": "General Intelligence is Multimodal",
        "Description": "Talking about Luma AI, our mission, and how our ML infrastructure enables SOTA multimodal model development ",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Case Study/War Story",
        "Tracks": "Generative Media",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "219b4939-2990-4c4e-9c88-75228cd526df",
    "Name": "Shafik Quoraishee",
    "Company": "New York Times",
    "Company Domain": "nytimes.com",
    "Company URL": "https://www.nytimes.com/",
    "Company Website": "https://www.nytimes.com/",
    "Title": "Senior Android Games Engineer",
    "TagLine": "Game Engineer and A.I. Enthusiast",
    "Bio": "I'm currently a Senior Android Games Engineer that works on the New York Times Games Team, working on the integration of games such as Wordle, Connections and the NYT Crossword, into the NYT Games Android App.\r\n\r\nI am also an A.I. enthusiast and practitioner with multiple years experience in the field and published research that has been deployed across  real world systems with both civilian to government applications.\r\n\r\nLinked In: https://www.linkedin.com/in/shafik-quoraishee/",
    "X (Twitter)": "https://x.com/SQuoraishee",
    "LinkedIn": "https://www.linkedin.com/in/shafik-quoraishee/",
    "Blog": "https://squoraishee.medium.com/",
    "Profile Picture": "https://sessionize.com/image/2b7d-400o400o1-RDsnvc2VDuvTZ43uXaXrhN.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914361",
        "Title": "AI and Game Theory: A Case Study on NYT's Connections",
        "Description": "This session will examine the interplay between human intuition and artificial intelligence in puzzle-solving, using the popular New York Times Connections game as a practical case study. \r\n\r\nWe'll investigate how gameplay can be systematically evaluated through AI algorithms, exploring machine learning strategies such as clustering, semantic mapping, and natural language processing. \r\n\r\nAttendees will gain insights into building AI-driven puzzle solvers, learn methods for quantitatively assessing gameplay complexity, and discuss the potential impacts of AI on puzzle game design and player engagement.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Design Engineering",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "290c81c8-f994-4e84-8667-ca8b6ffd95e4",
    "Name": "Rossella Blatt Vital",
    "Company": "Sprout Social",
    "Company Domain": "gmail.com",
    "Company URL": "",
    "Company Website": "https://sproutsocial.com",
    "Title": "VP of AI, Data, and Data Science",
    "TagLine": "VP of Engineering - AI",
    "Bio": "Rossella Blatt Vital is a passionate AI leader with nearly 20 years of experience turning data into business value—from hands-on research and model-building to strategic executive leadership. She began her journey with a PhD in machine learning, focusing on brain-computer interfaces and cancer detection, and spent years writing code, building models, and shipping AI-powered products before stepping into leadership roles across startups, academia, and Fortune 100 companies.\r\n\r\nAs VP of AI, Data, and Data Science at Sprout Social, Rossella leads the company’s AI transformation—driving strategy across engineering, applied science, and analytics. Her team is building AI-first capabilities across product experiences, platform infrastructure, and foundational data systems.\r\n\r\nShe’s passionate about building meaningful technology—and the teams that power it—with the belief that AI, when led with vision and integrity, can help shape a more thoughtful and human-centered future.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/rossellablatt/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/5f23-400o400o1-9RohnfFYvyXR6djmr53QcA.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914401",
        "Title": "From Hype to Habit: How We’re Building an AI-First SaaS Company—While Still Shipping the Roadmap",
        "Description": "What does it really take to move a modern SaaS company from AI experimentation to becoming truly AI-first?\r\n\r\nAt Sprout Social, we’re in the midst of that transformation—rearchitecting strategy, systems, teams, and incentives to put AI at the heart of how we think, build, and deliver value. This is a story in motion: a behind-the-scenes look at how we’re evolving from isolated AI feature experiments to an AI-native operating model.\r\n\r\nI’ll share what we’re learning as we navigate the innovation dilemma—integrating disruptive AI capabilities without breaking what already works or our roadmap. That includes rethinking how we define success, how we hire, reward, grow talent, and how we handle legal and ethical complexity without slowing down. We’ll explore the real-world tensions between rapid innovation, value delivery, making progress on Responsible AI, all while elevating internal AI fluency, and engaging with the broader AI ecosystem to stay at the edge. \r\n\r\nThis isn’t a playbook from the finish line—it’s a candid reflection from deep inside the journey.\r\n\r\nMy goal is to help other leaders chart their own AI path with greater clarity, confidence, and care.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Introductory (landscape)",
        "Tracks": "Leadership: Architects",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "1699f319-4792-451a-a5fb-bd4d8b5da132",
    "Name": "Kyle Corbitt",
    "Company": "OpenPipe",
    "Company Domain": "openpipe.ai",
    "Company URL": "https://openpipe.ai/",
    "Company Website": "https://openpipe.ai/",
    "Title": "Co-founder and CEO",
    "TagLine": "CEO ",
    "Bio": "Kyle Corbitt is the co-founder and CEO of OpenPipe, the RL post-training company. OpenPipe has trained thousands of customer models for both enterprises and tech-forward startups.\r\n\r\nBefore founding OpenPipe, Kyle led the Startup School team at Y Combinator, which was responsible for the product and content that YC produces for early-stage companies. Prior to that he worked as an engineer at Google and studied ML at school.",
    "X (Twitter)": "https://x.com/corbtt",
    "LinkedIn": "https://www.linkedin.com/in/kcorbitt/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/3669-400o400o1-hxPfhuJsFt4RgxzgB5As4B.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914533",
        "Title": "How to Train Your Agent: Building Reliable Agents with RL",
        "Description": "Have you ever launched an awesome agentic demo, only to realize no amount of prompting will make it reliable enough to deploy in production? Agent reliability is a famously difficult problem to solve!\r\n\r\nIn this talk we’ll learn how to use GRPO to help your agent learn from its successes and failures and improve over time. We’ve seen dramatic results with this technique, such as an email assistant agent that whose success rate jumped from 74% to 94% after replacing o4-mini with an open source model optimized using GRPO.\r\n\r\nWe’ll share case studies as well as practical lessons learned around the types of problems this works well for and the unexpected pitfalls to avoid.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Reasoning+RL",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "b3866d58-4534-4446-905b-6fc6fcc780dd",
    "Name": "Dominik Kundel",
    "Company": "OpenAI",
    "Company Domain": "openai.com",
    "Company URL": "https://openai.com/",
    "Company Website": "",
    "Title": "Developer Experience & SDKs",
    "TagLine": "Developer Experience ",
    "Bio": "Dominik is a developer and product leader with a passion for Developer Experience and Generative AI. He's currently working on Developer Experience & SDKs at OpenAI. Previously he lead Product & Design for Twilio's Emerging Tech & Innovation organization where his team worked on customer-aware AI agents. Dominik loves tinkering with anything that can run JavaScript, from front-end servers to CLIs and coffee machines. You can find him tweeting @dkundel and in his spare time he's working on cocktails, food and photography.",
    "X (Twitter)": "https://twitter.com/dkundel",
    "LinkedIn": "https://linkedin.com/in/dkundel",
    "Blog": "https://dkundel.com",
    "Profile Picture": "https://sessionize.com/image/a94f-400o400o1-KHnAdgMpikgEpDLJB3QNzU.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914537",
        "Title": "Building voice agents with OpenAI",
        "Description": "We'll walk through the differences between chained and speech-to-speech powered voice agents, how to approach them, best practices and transform a text-based agent into our first voice-enabled agent",
        "Format": "Workshop",
        "Level": "Introductory and overview",
        "Scope": "Technical deep dive",
        "Tracks": "Voice",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "337aa731-b47d-43b7-87e3-d33e19f2fb89",
    "Name": "Chin Keong Lam",
    "Company": "Patho.ai",
    "Company Domain": "gmail.com",
    "Company URL": "http://www.patho.ai/",
    "Company Website": "https://www.patho.ai",
    "Title": "unknown",
    "TagLine": "AI Engineer & Co-Founder ",
    "Bio": "https://www.linkedin.com/in/cklam12345/",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/cklam12345/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/975d-400o400o1-KzGdm6FGGNSBRkgBXex9ky.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914548",
        "Title": "Wisdom Discovery at Scale: Code Less KAG with n8n MultiAI Agents",
        "Description": "\"Wisdom Discovery at Scale: Code Less KAG with n8n MultiAI Agents\"",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "GraphRAG",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "de9c3919-7e80-4455-9778-b1fdb30ddac6",
    "Name": "Sid Bendre",
    "Company": "Oleve",
    "Company Domain": "oleve.co",
    "Company URL": "https://www.oleve.co/",
    "Company Website": "https://www.oleve.co/",
    "Title": "Co-founder and Head of Platform",
    "TagLine": "Co-Founder",
    "Bio": "Sid Bendre is the co-founder of Oleve, a company building a portfolio of iconic consumer software across multiple verticals. With a lean team, Oleve has already launched two virally successful consumer AI products that have amassed over 250 million views across social media platforms. One of their products reached #4 on the App Store's Education charts in 2024 and #5 in 2025, competing alongside giants like Photomath (Google) and Duolingo. Backed by Neo, Cal Henderson (co-founder of Slack), Russell Kaplan (President of Cognition), and Maria Zhang (ex-CTO of Tinder), Oleve is building the AI infrastructure to run a $1B portfolio of consumer software over the next decade. At Oleve, Sid leads technical and AI efforts, running the “Platform” team responsible for the underlying AI infrastructure that powers their lean scaling approach. Before Oleve, Sid led AI experimentation efforts at a startup hedge fund and worked at Slack, Zendesk, and Microsoft.",
    "X (Twitter)": "https://x.com/SidBendre",
    "LinkedIn": "https://www.linkedin.com/in/sidbendre/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/0d00-400o400o1-BQmZLpsEnnPaQ4Ynw4eQqm.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914550",
        "Title": "The New Lean Startup",
        "Description": "In this session, I will be presenting a case study of Oleve's journey, revealing how we've scaled a profitable multi-product portfolio with a tiny team. I'll walk you through the emergence of \"tiny teams,\" our two-track engineering methodology that has become our blueprint, as well as an inside look at our technical alpha – specifically how we've engineered deterministic AI agents to deliver magical and reliable consumer experiences to millions. You'll learn how we've built internal tools to grow leanly and created operating playbooks to scale operations without traditional headcount requirements. I'll also share our approach to scrappy infrastructure innovation and how our investment in internal tooling has served as a critical force multiplier. Finally, I'll give an overview of parts of the profitable portfolio playbook that keeps us lean, adaptable, and profitable across multiple product lines.\r\n\r\nStructure of talk:\r\n- the tiny teams revolution\r\n- the two-track engineering approach\r\n- technical alpha: deterministic ai agents at scale\r\n- scrappy infrastructure innovation\r\n- internal tooling as a multiplier\r\n- the profitable portfolio playbook",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Case Study/War Story",
        "Tracks": "Tiny Teams",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "3424ead2-2223-4bf6-9ef0-254a8540f68c",
    "Name": "Greg Kamradt",
    "Company": "ARC Prize Foundation",
    "Company Domain": "arcprize.org",
    "Company URL": "https://arcprize.org/",
    "Company Website": "https://arcprize.org/",
    "Title": "President",
    "TagLine": "President",
    "Bio": "Greg Kamradt is President of the ARC Prize Foundation, the ARC‑AGI benchmark series that challenges frontier AI models on out‑of‑distribution reasoning tasks.",
    "X (Twitter)": "https://x.com/GregKamradt",
    "LinkedIn": "https://www.linkedin.com/in/gregkamradt/",
    "Blog": "https://gregkamradt.com/",
    "Profile Picture": "https://sessionize.com/image/9fcf-400o400o1-TmRC2WfLNcXZ13UTXGicuB.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914786",
        "Title": "Inside ARC Prize, Scaling Reasoning, and Dynamic Evals",
        "Description": "ARC Prize Foundation is building the North Star for AGI—rigorous, open benchmarks that track reasoning progress in modern AI. We'll cover how we've evaluated frontier models since GPT-3.5 and share a preview of ARC-AGI-3: a dynamic, game-like benchmark launching next year to test general intelligence.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "Reasoning+RL",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "fabd056c-2440-49ec-8199-3ac7d6080a7d",
    "Name": "Mark Bissell",
    "Company": "Goodfire AI",
    "Company Domain": "goodfire.ai",
    "Company URL": "https://www.goodfire.ai/",
    "Company Website": "https://www.goodfire.ai/",
    "Title": "Applied Researcher",
    "TagLine": "Applied Interpretability Research ",
    "Bio": "Mark Bissell is an applied researcher at Goodfire AI working on real-world applications for mechanistic interpretability. He recently joined Goodfire after 3 years at Palantir, where he worked on various U.S. healthcare initiatives including research projects with the NIH, vaccine distribution during the Covid pandemic (Operation Warp Speed), and AI-enabled hospital operations across many of the nation's leading health systems. \r\n\r\nMark is passionate about translating frontier research into practical solutions. He believes that recent AI developments increase the importance broad skillsets, and that roles of the future will blur the lines between traditionally distinct categories such as engineer, researcher, inventor, designer, and entrepreneur. ",
    "X (Twitter)": "https://x.com/MarkMBissell",
    "LinkedIn": "https://www.linkedin.com/in/mark-bissell/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/3340-400o400o1-32dNeZ1139AHoGD7YpQUGT.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914798",
        "Title": "Operationalizing AI Interpretability with Neural Programming Interfaces (NPIs)",
        "Description": "Mechanistic interpretability is a frontier field that aims to reverse engineer neural networks. At Goodfire, we're operationalizing the latest in interpretability research by building Ember: the universal platform for neural programming. Ember decodes the neurons of an AI model to give direct, programmable access to its internal representations.\r\nIn this talk, we'll share more about what's unlocked by moving beyond black-box inputs and outputs, including entirely new ways to apply, train, and align AI models. We're excited for a future in which neural programming allows users to discover new knowledge hidden in their model, precisely shape its behaviors, and improve its performance. ",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "AI in Action",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "0db693b9-12cb-437d-a92f-922ba0751480",
    "Name": "Ivan Burazin",
    "Company": "Daytona",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.daytona.io/",
    "Company Website": "https://www.daytona.io/",
    "Title": "Co-founder",
    "TagLine": "CEO and Co-Founder at Daytona",
    "Bio": "Ivan Burazin co-founded Codeanywhere, the very first cloud IDE, back in 2009 where he and the team had to create everything from scratch, from the IDE itself, to the entire orchestration. Concurrently, he established Shift, the premier developer conference in Europe, which was later acquired by Infobip - a global communications cloud giant in 2021. Following the acquisition, Ivan served on the executive board of this 4,000-person company and as the Chief Developer Experience Officer, where he oversaw global developer-oriented operations.\r\nIn 2023, Ivan co-founded Daytona, a fast-growing open-source platform addressing the limitations of AI coding agents by enabling them to programmatically and securely interact with runtime environments. \r\nBacked by $7M in funding, Daytona empowers developers, from startups to Fortune 500 companies to enable AI agents to achieve their full potential.\r\n",
    "X (Twitter)": "https://twitter.com/ivanburazin",
    "LinkedIn": "https://www.linkedin.com/in/ivanburazin/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/ba67-400o400o1-RZgw2DqaC7TEEp4b41MiwA.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914814",
        "Title": "AX is the only Experience that Matters",
        "Description": "If you’re building devtools for humans, you’re building for the past. \r\n\r\nAlready a quarter of Y Combinator’s latest batch used AI to write 95% or more of their code. AI agents are scaling at an exponential rate and soon, they’ll outnumber human developers by orders of magnitude.\r\n\r\n\r\nThe real bottleneck isn’t intelligence. It’s tooling. Terminals, local machines, and dashboards weren’t built for agents. They make do… until they can’t.\r\n\r\nIn this talk, I’ll share how we killed the CLI at Daytona, rebuilt our infrastructure from first principles, and what it takes to build devtools that agents can actually use. Because in an agent-native future, if agents can’t use your tool, no one will.\r\n",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Case Study/War Story",
        "Tracks": "Infrastructure",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "4fdfdeca-1862-4955-a306-59cf77a9f79b",
    "Name": "James Lowe",
    "Company": "Incubator for AI ",
    "Company Domain": "cabinetoffice.gov.uk",
    "Company URL": "https://ai.gov.uk/",
    "Company Website": "https://ai.gov.uk/",
    "Title": "Head of AI Engineering",
    "TagLine": "Head of AI Engineering",
    "Bio": "James Lowe has been a data scientist in public sector for 6 years, including working at 10 Downing Street. He is now the Head of AI Engineering for the Incubator for AI, a small team of experts in the centre of the UK Government building AI products that are delivering public good.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/james-lowe-98011292/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/f5e7-400o400o1-U33Y72yYrp7tVXZgEpLXAL.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914842",
        "Title": "Why your product needs an AI product manager, and why it should be you",
        "Description": "So you've built another cool demo. Now what? You have hype, but not impact. You have kudos but no users. Ultimately you have a demo, but not a product.\r\n\r\nThe unique uncertainty of AI technology demands a new approach – beyond traditional product management. You need an AI Product Manager. This talk explains why this role is essential for building real AI products, using real case studies from the incubator for Artificial Intelligence in the UK Government.\r\n\r\nMore importantly, it reveals why your technical depth makes you uniquely suited to step into this critical leadership gap. Discover why could be the ideal candidate to be the AI Product Manager your product needs, and how to step into that role.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "AI Product Management",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "57f7b222-9000-49c5-be6f-401f5ed85729",
    "Name": "John Pham",
    "Company": "The San Francisco Compute Company",
    "Company Domain": "gmail.com",
    "Company URL": "https://sfcompute.com/",
    "Company Website": "https://sfcompute.com",
    "Title": "Engineer and Designer",
    "TagLine": "Head of Design ",
    "Bio": "I'm John Pham, an engineer and a self-taught designer. I seek the dopamine hits of building delightful experiences for others. I've worked at Vercel, Microsoft and NASA doing just that.",
    "X (Twitter)": "https://twitter.com/johnphamous",
    "LinkedIn": "https://www.linkedin.com/in/johnphamous/",
    "Blog": "https://pham.codes",
    "Profile Picture": "https://sessionize.com/image/3d96-400o400o1-ckJzaLGR1pNqpqzGEBgRR.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914845",
        "Title": "Good design hasn’t changed with AI",
        "Description": "Bad designs are still bad. AI doesn’t make it good. The novelty of AI makes the bad things tolerable, for a short time. Building great designs and experiences with AI have the same first principles pre-AI. When people use software, they want it to feel responsive, safe, accessible and delightful. We’ll go over the big and small details that goes into software that people want to use, not forced to use.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Design Engineering",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "e344968a-0c7a-45c8-8cd1-27a77ead36ce",
    "Name": "Will Brown",
    "Company": "Independent",
    "Company Domain": "columbia.edu",
    "Company URL": "https://www.primeintellect.ai/",
    "Company Website": "https://primeintellect.ai",
    "Title": "Research Engineering Lead",
    "TagLine": "Research Engineering Lead",
    "Bio": "Will Brown is a Research Engineering Lead at Prime Intellect, focusing on RL for reasoning and agents. He previously held research roles at Morgan Stanley and AWS, and completed his PhD in Computer Science at Columbia University. ",
    "X (Twitter)": "https://x.com/willccbb",
    "LinkedIn": "https://www.linkedin.com/in/willcb",
    "Blog": "https://willcb.com",
    "Profile Picture": "https://sessionize.com/image/5808-400o400o1-Jhwoe2fQGyjgKKsxXWZke5.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914856",
        "Title": "Training Agentic Reasoners",
        "Description": "This talk will be a technical deep dive into RL for agentic reasoning via multi-turn tool calling, similar to OpenAI's o3 and Deep Research. In particular, we'll cover:\r\n- When, why, and how\r\n- GRPO vs PPO vs etc\r\n- Designing environments and rewards\r\n- Survey of recent research highlights\r\n- Results on example tasks\r\n- Overview of open-source ecosystem (libraries, compute requirements, tradeoffs, etc.)",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Reasoning+RL",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "0880058d-a4ab-45cd-a57a-912c18d09bd0",
    "Name": "Adam Behrens",
    "Company": "New Generation",
    "Company Domain": "new-gen.ai",
    "Company URL": "https://www.new-gen.ai/",
    "Company Website": "https://www.new-gen.ai/",
    "Title": "Co-founder and CEO",
    "TagLine": "Co-Founder & CEO",
    "Bio": "Adam Behrens is the co-founder and CEO of a, a company that partners with global brands and merchants to unlock AI native commerce opportunities. New Gen builds infrastructure for brands to host their own conversational AI experiences and to connect their data into 3rd party chat clients like ChatGPT and Claude. Adam previously worked on trading infrastructure at Bridgewater and Banking-as-a-Service at Stripe. Outside of training AI models he is busy training his 8 month old Vizsla puppy.",
    "X (Twitter)": "https://x.com/etpuisfume",
    "LinkedIn": "https://www.linkedin.com/in/adam-behrens/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/dd9a-400o400o1-aK2KD9ofRRFnkVARmm586d.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914891",
        "Title": "Machines of Buying & Selling Grace",
        "Description": "How to go beyond browser automation to truly agentic commerce, where AI can buy, sell and negotiate on behalf of users and merchants.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Leadership: Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "9e1f15f4-830e-4239-82ed-7e65bd50ff19",
    "Name": "Paul Klein IV",
    "Company": "Browserbase",
    "Company Domain": "browserbase.com",
    "Company URL": "",
    "Company Website": "https://browserbase.com/",
    "Title": "Founder & CEO",
    "TagLine": "Founder of Browserbase",
    "Bio": "Paul Klein IV is a San‑Francisco‑based serial entrepreneur and engineer. After honing his chops at Twilio during it's IPO and founding Stream Club—a live‑streaming platform acquired by Mux in 2021 he launched Browserbase in 2024 to give developers and AI agents fast, reliable, multi‑region headless‑browser infrastructure. In its first 12 months, Klein raised $27.5 million (a $6.5 M seed and a $21 M Series A led by CRV and Kleiner Perkins with Okta Ventures) . He views Browserbase as the “last‑mile” interface between large language models and the web, enabling end‑to‑end workflow automation far beyond traditional scraping ",
    "X (Twitter)": "https://x.com/pk_iv",
    "LinkedIn": "https://www.linkedin.com/in/paulkleiniv/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/4dc8-400o400o1-HaQv5txvpZSab2mk35AZNR.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914934",
        "Title": "The Web Browser Is All You Need",
        "Description": "(PLACEHOLDER) With the rise of MCP servers, A2A, and our trusty friend, OpenAPI, it turns our the web browser may be the default MCP server for the rest of the internet.\r\n\r\nIn this talk, we'll walk through how a web browsing tool is probably the only tool you'll need to enable production AI Agents. ",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Infrastructure",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "45295eea-039a-4a9e-bbf0-3b5b42d31eee",
    "Name": "Chun Jiang",
    "Company": "Reforge",
    "Company Domain": "reforge.com",
    "Company URL": "https://www.reforge.com/",
    "Company Website": "https://www.reforge.com/",
    "Title": "Product Leader / AI PM Specialist",
    "TagLine": "VP Product ",
    "Bio": "Chun Jiang:\r\nChun was the co-founder and CEO of Monterey AI backed by YC. The company was acquired by Reforge in 2025. Chun previously led products and design at companies like Unfolded (acquired by Foursquare), Scale AI, and Uber. Chun graduated from Cornell in 2018 and has been obsessed with building the most ambitious and delightful Data and AI products in productivity, developer tooling, and autonomous vehicles.\r\n\r\nBrian Balfour:\r\nBrian is the Founder/CEO of Reforge, previously VP Growth @ HubSpot. He has started multiple VC-backed companies and grown user bases to millions of daily active users. Brian writes detailed essays on growth and user acquisition that have been featured in Forbes, Hacker Monthly, and OnStartups to help teams build a growth machine.",
    "X (Twitter)": "https://x.com/chunonline",
    "LinkedIn": "https://www.linkedin.com/in/chunonline/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/8168-400o400o1-wcjCCWFa4CDzHGQ6mK4iR7.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "914975",
        "Title": "Build AI PMs for PMs to Replace PMs",
        "Description": "If you’ve ever been blocked by vague specs, shifting goals, or chasing “vibes,” things have only gotten messier in the age of AI.\r\n\r\nWhat if the PM were an AI—and it understood the product, the customers, the market, the design, and, most importantly, you?\r\n\r\nAt Reforge, we built AI agents that analyze user feedback at scale, perform real-time market analysis, write aspects, model feature impact, and run continuous user research -- pushing us to rethink what \"product work” actually looks like.\r\n\r\nIn this talk, we’ll explore what happens when engineers collaborate with AI PMs instead of humans: evaluation-driven backlogs grounded in real user data, ruthless and precise feature scoping, and product decisions that iterate as fast as the models powering them.\r\n\r\nYou’ll learn the user behaviors and engineering patterns behind feedback analysis, synthetic users, AI-native surveys, and the metrics we use to measure impact before a feature ships—along with the cultural shifts teams need to embrace to make this future a reality.\r\n\r\nIn this new era, the teams who win won’t just adopt AI—they’ll architect workflows where human intuition and machine intelligence ship product side by side.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "AI Product Management",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "e770d774-d3ce-487e-b76e-ec767ab4b0e3",
    "Name": "Alex Volkov",
    "Company": "Weights & Biases",
    "Company Domain": "gmail.com",
    "Company URL": "https://wandb.ai/",
    "Company Website": "https://wandb.ai",
    "Title": "AI Evangelist",
    "TagLine": "AI Evangelist",
    "Bio": "Alex Volkov is an AI Evangelist at Weights & Biases as well as the founder and host of ThursdAI, a weekly newsletter and podcast that explores the latest innovations in AI, their practical applications, and the open-source AI community. Alex is an AI startup founder with 20 years of full-stack software engineering experience, offering a deep well of insights into AI innovation. He’s celebrated for his ability to clarify and summarize the complexities of the rapid AI advances and advocating for its beneficial uses.",
    "X (Twitter)": "https://x.com/altryne",
    "LinkedIn": "",
    "Blog": "https://sub.thursdai.news",
    "Profile Picture": "https://sessionize.com/image/b6dc-400o400o1-n42m8vkZMc2L1ZmuTGD5JD.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915013",
        "Title": "Observable tools - the state of MCP observability",
        "Description": "AI Engineers deserve observable tools! \r\n\r\nMCP getting adoption means that less and less of your agents code is running under your control, and this has DX and observability challenges, let's fix that! \r\n\r\nJoin Alex Volkov from Weights & Biases and Steve Manual from mcp.run on this recap of the current state of MCP observability, including the observable.tools initiative, a recap of where the field stands and what to look forward to + a practical example of MCP tool usage evaluation framework from mcp.run! ",
        "Format": "Talk",
        "Level": "Expert",
        "Scope": "Technical deep dive",
        "Tracks": "MCP",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "ea8c6f3b-982d-4ac8-8a1b-08e569262e93",
    "Name": "Steve Manuel",
    "Company": "Dylibso",
    "Company Domain": "dylibso.com",
    "Company URL": "https://dylibso.com/",
    "Company Website": "https://dylibso.com",
    "Title": "Co-founder & CEO",
    "TagLine": "Co-founder & CEO",
    "Bio": "Steve is the co-founder & CEO of Dylibso, creators of mcp.run. He is an entrepreneur, programmer, guitarist, and general tinkerer. He has been taking things apart and putting them back together since before he can remember… his first words were, “phillips” and “flathead”.",
    "X (Twitter)": "https://x.com/nilslice",
    "LinkedIn": "https://linkedin.com/in/stevemanuel",
    "Blog": "https://docs.mcp.run/blog",
    "Profile Picture": "https://sessionize.com/image/de67-400o400o1-LvvRAywopMF9HRKLyGKJKh.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915013",
        "Title": "Observable tools - the state of MCP observability",
        "Description": "AI Engineers deserve observable tools! \r\n\r\nMCP getting adoption means that less and less of your agents code is running under your control, and this has DX and observability challenges, let's fix that! \r\n\r\nJoin Alex Volkov from Weights & Biases and Steve Manual from mcp.run on this recap of the current state of MCP observability, including the observable.tools initiative, a recap of where the field stands and what to look forward to + a practical example of MCP tool usage evaluation framework from mcp.run! ",
        "Format": "Talk",
        "Level": "Expert",
        "Scope": "Technical deep dive",
        "Tracks": "MCP",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "607fd16a-9612-483a-87ba-1d3031d3a155",
    "Name": "Kwindla Kramer",
    "Company": "Daily",
    "Company Domain": "daily.co",
    "Company URL": "https://www.daily.co/",
    "Company Website": "https://openai.com/",
    "Title": "WebRTC Infrastructure Engineer",
    "TagLine": "CEO ",
    "Bio": "Kwin works on large-scale WebRTC infrastructure at Daily. He is the originator of Pipecat, the widely used, open source, vendor neutral voice agent framework supported by NVIDIA, Google, AWS and used by hundreds of startups. Before co-fonding Daily, Kwin built the sci-fi user interfaces in Minority Report and Iron Man.",
    "X (Twitter)": "https://x.com/kwindla",
    "LinkedIn": "https://www.linkedin.com/in/kwkramer/",
    "Blog": "https://www.linkedin.com/in/sean-dubois/",
    "Profile Picture": "https://sessionize.com/image/d6ae-400o400o1-HJCEgwnJadsHAkcAkU46oh.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915028",
        "Title": "Your realtime AI is ngmi",
        "Description": "Sean DuBois of OpenAI and Pion, and Kwindla Hultman Kramer of Daily and Pipecat, will talk about why you have to design realtime AI systems from the network layer up.\r\n\r\nMost people who build realtime AI apps and frameworks get it wrong. They build from either the model out or the app layer down. But unless you start with the network layer and build up, you'll never be able to deliver realtime audio and video streams reliably. And perhaps even worse, you'll get core primitives wrong: interruption handling, conversation state management, asynchronous function calling.\r\n\r\nSean and Kwin agree on most things: old-school realtime systems people against the rest of the world. But they disagree on some important things, too, and will argue about those things live on stage. Do you need to give developers \"thick\" client-side realtime SDKs? Can you build truly great vendor neutral APIs? (You'll be surprised which of them argues which side, on that topic.)",
        "Format": "Keynote",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "Voice",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "8f80de08-076f-46c5-b824-9c28441cb56f",
    "Name": "Sean DuBois",
    "Company": "OpenAI",
    "Company Domain": "openai.com",
    "Company URL": "https://openai.com/",
    "Company Website": "http://openai.com/",
    "Title": "WebRTC and Realtime API Engineer",
    "TagLine": "WebRTC and Realtime API",
    "Bio": "Sean works on WebRTC and the Realtime API at OpenAI. He built 1-800-CHATGPT. He is the founder of Pion, the most widely used open source WebRTC project. He has previously worked at AWS, LiveKit, Apple, and Etsy.",
    "X (Twitter)": "https://x.com/_pion",
    "LinkedIn": "https://linkedin.com/in/sean-dubois",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/5861-400o400o1-wTc662414LPKiqmxWnCYdk.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915028",
        "Title": "Your realtime AI is ngmi",
        "Description": "Sean DuBois of OpenAI and Pion, and Kwindla Hultman Kramer of Daily and Pipecat, will talk about why you have to design realtime AI systems from the network layer up.\r\n\r\nMost people who build realtime AI apps and frameworks get it wrong. They build from either the model out or the app layer down. But unless you start with the network layer and build up, you'll never be able to deliver realtime audio and video streams reliably. And perhaps even worse, you'll get core primitives wrong: interruption handling, conversation state management, asynchronous function calling.\r\n\r\nSean and Kwin agree on most things: old-school realtime systems people against the rest of the world. But they disagree on some important things, too, and will argue about those things live on stage. Do you need to give developers \"thick\" client-side realtime SDKs? Can you build truly great vendor neutral APIs? (You'll be surprised which of them argues which side, on that topic.)",
        "Format": "Keynote",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "Voice",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "e0e7e5a4-c730-471e-afa3-fcfe5251b3ad",
    "Name": "Brooke Hopkins",
    "Company": "Coval",
    "Company Domain": "coval.dev",
    "Company URL": "https://www.coval.dev/",
    "Company Website": "https://www.coval.dev/",
    "Title": "Founder",
    "TagLine": "Founder ",
    "Bio": "Brooke Hopkins is the Founder at Coval, where her team builds the enterprise-grade reliability infrastructure for conversational AI. Previously, she built evaluation systems at Waymo that helped enable safe autonomous driving. With experience spanning both physical and digital AI domains, Brooke brings unique insights into creating robust testing frameworks that can scale with AI's rapid development.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/bnhop/",
    "Blog": "https://app.coval.dev/the-ultimate-voice-ai-stack",
    "Profile Picture": "https://sessionize.com/image/b34b-400o400o1-95iv2vfdt4j1yxRzZ2afQh.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915031",
        "Title": "What we can learn from self driving in autonomous voice agents",
        "Description": "The reliability challenges facing voice & chat AI deployment today mirror those that the autonomous vehicle industry confronted years ago. This talk explores how evaluation methodologies developed for self-driving cars can be transferred to create autonomous, self-improving evaluation systems for conversational AI. Drawing from my experience building evaluation infrastructure at Waymo and now developing Coval, an enterprise-grade reliability platform for conversational agents, I'll demonstrate how systematic testing infrastructure is not just a technical requirement but a competitive advantage in the rapidly evolving AI landscape.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Introductory (landscape)",
        "Tracks": "Voice",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "4b7f0686-5bfb-43da-980d-0449511b062d",
    "Name": "Anoop Kotha",
    "Company": "OpenAI",
    "Company Domain": "openai.com",
    "Company URL": "https://openai.com/",
    "Company Website": "",
    "Title": "Customer Engineer",
    "TagLine": "Applied AI",
    "Bio": "I'm Anoop Kotha, a member of the OpenAI team that works with our customers to create novel LLM experiences. Previously I was an engineer at Retool. ",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/0f76-400o400o1-hX5wxCLt85iJnmvPhg8DNe.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915067",
        "Title": "Building Effective Voice Agents",
        "Description": "How to build production voice applications and learnings from working with customers along the way",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Voice",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "1feb3f6d-13cb-4ac8-9297-dbd4154ebfcf",
    "Name": "Aman Khan",
    "Company": "Arize AI",
    "Company Domain": "arize.com",
    "Company URL": "",
    "Company Website": "https://arize.com/",
    "Title": "Director of Product, LLM",
    "TagLine": "Director of Product",
    "Bio": "Aman is Director of Product, LLM at Arize AI. Prior to Arize, Aman was the PM on the Jukebox Feature Store in the ML Platform team at Spotify across ~50 data science teams. Aman was also PM for ML Evaluation frameworks across data science and engineering teams for self-driving cars at Cruise, which helped launch the first self-driving car service in an urban environment. Aman studied Mechanical Engineering at UC Berkeley and lived in the SF Bay Area for 9 years before moving to NYC. ",
    "X (Twitter)": "https://x.com/_amankhan",
    "LinkedIn": "https://www.linkedin.com/in/amanberkeley/",
    "Blog": "https://amankhan1.substack.com/",
    "Profile Picture": "https://sessionize.com/image/c833-400o400o1-Ny5azYCUjiB2ccBPSnHeQ2.jpeg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915269",
        "Title": "Shipping AI That Works: An Evaluation Framework for PMs",
        "Description": "GenAI is reshaping the product landscape, creating huge opportunities (along with new expectations) for product managers. Yet while prompt engineering and model tuning get the spotlight, one critical skill can get overlooked: rigorous evaluation.\r\n\r\nThis talk will help PMs move beyond gut-feel “vibe checks” to adopt concrete, repeatable evaluation strategies for LLM-powered products. I'll break down essential eval methodologies, from human feedback and code-based checks to cutting-edge LLM-based evaluations. Drawing on real-world examples, I'll share a practical framework PMs can use to:\r\n\r\n-Confidently evaluate AI-driven features\r\n- Ground decisions in real, repeatable data\r\n- Build trust and delight through consistent quality\r\n",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "AI Product Management",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "2cd31242-f8a9-46fd-8090-6965d08643c5",
    "Name": "Matthew Hertz",
    "Company": "Man Group",
    "Company Domain": "mehertz.com",
    "Company URL": "https://man.com/",
    "Company Website": "https://man.com",
    "Title": "Head of Machine Learning Technology",
    "TagLine": "Head of Machine Learning Technology",
    "Bio": "https://www.man.com/matthew-hertz\r\n\r\n(See speaker pitch for more info as well)\r\n\r\nMatthew Hertz leads the Machine Learning Technology team at Man Group. This team is responsible for the integration of generative AI throughout the firm and the development and maintenance of the front office machine learning platform.\r\n\r\nPrior to this, Matthew was the Head of Engineering for ArcticDB, a high-performance data-frame database optimised for time-series data. Matthew has been building data-driven technology platforms within firms in the financial services industry since 2015.\r\n\r\nMatthew holds a master’s degree in computer science from the University of Southampton.\r\n\r\n",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/matthew-hertz-2aba0aa4/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/160a-400o400o1-3ba3cWjqyueeHxpX17pu1k.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915273",
        "Title": "Quantitative Research in the era of Agentic AI",
        "Description": "Agents and vibe coding have already disrupted software engineering, but what about domains such as systematic quant trading? Can we build an agent to help find alpha - and ultimately to predict the future of financial markets?\r\n\r\nIn this talk, we'll walk you through the journey of creating and deploying the Alpha Assistant - a semi-autonomous research coding agent (\"outer loop\") specifically designed for Man Group's Quantitative Research teams.\r\n\r\nLearn about what goes into building a domain-specific coding agent in a niche, technical, and scientific domain. We'll touch on key themes such as agentic interface design (and why we moved *away* from a Claude Code-esque CLI interface), what we've learnt applying the \"bitter lesson for agents\", and what full autonomy for quant research might look like. ",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "5154a162-47d1-4c47-9cd7-f185140e7cf5",
    "Name": "Anish Agarwal",
    "Company": "Traversal",
    "Company Domain": "traversal.com",
    "Company URL": "https://traversal.com/",
    "Company Website": "https://www.traversal.com",
    "Title": "CEO and Co-founder",
    "TagLine": "CEO and Co-founder",
    "Bio": "Anish Agrawal is the CEO and Co-founder of Traversal, where he and his team are revolutionizing observability and troubleshooting with AI Agents. A Professor of Computer Science and Operations Research at Columbia University, Anish earned his PhD in Computer Science from MIT, specializing in causal machine learning—teaching AI to understand cause and effect from data. Despite achieving his goal of becoming a professor,  Anish pivoted from academia, recognizing a once-in-a-lifetime opportunity to apply his AI research to tackle the industry’s toughest challenges, with autonomous troubleshooting at the forefront. His career also includes roles as a management consultant at BCG and research scientist at Amazon and Microsoft Research.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/anish-agarwal-io/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/f403-400o400o1-aztUHtnrKs7FM8kqdhLAX5.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915312",
        "Title": "Production software keeps breaking and it will only get worse.  Here’s how Traversal is fixing it.",
        "Description": "Software is eating the world. AI is eating software. AI-powered SWE means a whole lot more software is going to be written that powers mission critical systems in the coming years, with hardly any of it written by humans. Hence, when these software systems inevitably break, it’s going to be next to impossible to troubleshoot them. Towards addressing this issue, we’ll do a product launch of Traversal’s AI, a significant step towards self-healing software systems. We will showcase how it is already used to autonomously troubleshoot production incidents in some of the most complex enterprise environments.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Product launch",
        "Tracks": "SWE Agents",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "57c7e83f-4c1b-46ee-9f5a-f231d7eddd90",
    "Name": "Matthew Schoenbauer",
    "Company": "Traversal",
    "Company Domain": "traversal.com",
    "Company URL": "https://traversal.com/",
    "Company Website": "",
    "Title": "Founding Engineer",
    "TagLine": "Founding Engineer",
    "Bio": "Matt Schoenbauer is a founding engineer at Traversal, where he and his team are redefining observability and troubleshooting with AI agents. Previously, he was a systematic trader at Citadel Securities, operating at the core of the world’s largest equities market-making platform, where live troubleshooting in the Linux terminal was a critical part of his work. Before that, he worked in quantitative research at Proof Trading. Matt has published research across cryptography, number theory, and algebraic topology, and holds a master’s degree from Columbia University, where he focused on machine learning systems and causal machine learning.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/matthew-schoenbauer-353180157/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/53a2-400o400o1-J8kvvUEzwc4DGRUJSTBuzr.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915312",
        "Title": "Production software keeps breaking and it will only get worse.  Here’s how Traversal is fixing it.",
        "Description": "Software is eating the world. AI is eating software. AI-powered SWE means a whole lot more software is going to be written that powers mission critical systems in the coming years, with hardly any of it written by humans. Hence, when these software systems inevitably break, it’s going to be next to impossible to troubleshoot them. Towards addressing this issue, we’ll do a product launch of Traversal’s AI, a significant step towards self-healing software systems. We will showcase how it is already used to autonomously troubleshoot production incidents in some of the most complex enterprise environments.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Product launch",
        "Tracks": "SWE Agents",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "431907d7-ade9-4bba-aebe-173770b772cd",
    "Name": "Raj Agrawal",
    "Company": "Traversal",
    "Company Domain": "traversal.com",
    "Company URL": "https://traversal.com/",
    "Company Website": "",
    "Title": "CTO, Cofounder",
    "TagLine": "CTO,  Cofounder",
    "Bio": "CTO,  Cofounder of Traversal.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/7c40-400o400o1-nsFrh2AwXLtDdeUmZQg9P8.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915312",
        "Title": "Production software keeps breaking and it will only get worse.  Here’s how Traversal is fixing it.",
        "Description": "Software is eating the world. AI is eating software. AI-powered SWE means a whole lot more software is going to be written that powers mission critical systems in the coming years, with hardly any of it written by humans. Hence, when these software systems inevitably break, it’s going to be next to impossible to troubleshoot them. Towards addressing this issue, we’ll do a product launch of Traversal’s AI, a significant step towards self-healing software systems. We will showcase how it is already used to autonomously troubleshoot production incidents in some of the most complex enterprise environments.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Product launch",
        "Tracks": "SWE Agents",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "1b3e98d3-0b37-4945-8ad4-8eac22ba15ed",
    "Name": "Raaz Dwivedi",
    "Company": "Traversal",
    "Company Domain": "interactionlabs.ai",
    "Company URL": "https://traversal.com/",
    "Company Website": "https://traversal.com/",
    "Title": "Chief Scientist and Co-founder",
    "TagLine": "Chief Scientist",
    "Bio": "Raaz Dwivedi is the Chief Scientist and a co-founder of Traversal. In the last year and a half, Traversal has been building an autonomous AI system, using AI agents, LLMs, and causal machine learning for root causing production incidents. Raaz is an AI researcher by training and in the past decade has built efficient decision-making systems using causal machine learning and reinforcement learning as an Assistant Professor at Cornell Tech, as a Postdoc at Harvard and MIT, and as a PhD student at UC Berkeley. His work has won him several research and teaching awards.\r\n",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/raaz-dwivedi/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/5c30-400o400o1-rs6aD9hYBxwsaGANJgtKtb.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915312",
        "Title": "Production software keeps breaking and it will only get worse.  Here’s how Traversal is fixing it.",
        "Description": "Software is eating the world. AI is eating software. AI-powered SWE means a whole lot more software is going to be written that powers mission critical systems in the coming years, with hardly any of it written by humans. Hence, when these software systems inevitably break, it’s going to be next to impossible to troubleshoot them. Towards addressing this issue, we’ll do a product launch of Traversal’s AI, a significant step towards self-healing software systems. We will showcase how it is already used to autonomously troubleshoot production incidents in some of the most complex enterprise environments.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Product launch",
        "Tracks": "SWE Agents",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "c76d65c1-a932-4649-b699-b67f0646072c",
    "Name": "Chau Tran",
    "Company": "Glean",
    "Company Domain": "gmail.com",
    "Company URL": "",
    "Company Website": "https://www.glean.com/",
    "Title": "Software Engineer",
    "TagLine": "Technical Lead",
    "Bio": "Chau Tran is a Software Engineer at Glean, currently leading the technical work on Glean Assistant and semantic search. They have been with Glean for over 3 years and have a history of impactful contributions in engineering teams. Previously, Chau worked as a Research Engineer at FAIR within Meta and held technical roles at Quora. They graduated from Brown University with a Bachelor's degree in Computer Science.",
    "X (Twitter)": "https://x.com/mr_cheu",
    "LinkedIn": "https://www.linkedin.com/in/chau-tran-ba9a5727/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/02cb-400o400o1-YcnXGLU8Boj3XwrtuAVZpX.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915338",
        "Title": "How to build Enterprise-aware agents",
        "Description": "While LLMs demonstrated impressive reasoning capabilities, their out-of-the-box reasoning is akin to hiring a brilliant but brand-new employee who doesn’t have the enterprise context of “how things are done at this company”. In this talk, I'll introduce “Workflow Search” as a paradigm to build enterprise-aware agents that can balance predictability on common tasks, and flexibility on unforeseen tasks.\r\n",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "b734b775-2254-4df3-90b1-bb2da4ac9638",
    "Name": "Brett Kotch",
    "Company": "Liquidnet",
    "Company Domain": "outlook.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "Technology Innovator",
    "TagLine": "Head of AI for Technology ",
    "Bio": "Brett Kotch has transformed trading technology at top global financial institutions, including Millennium, Citibank, Barclays, and Liquidnet, where he was part of the original team enabling anonymous execution of large trades, creating one of Wall Street’s largest pools of institutional liquidity. Brett is actively driving innovative solutions to advance AI within technology. Brett holds a degree in Computer Science from Columbia University.\r\n\r\n",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/4cd2-400o400o1-fRJj6RumYBNw3BrrMqLqbX.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915353",
        "Title": "The Evolution of Software Development with AI",
        "Description": "Artificial Intelligence is a rapidly advancing technology revolutionizing the world, especially in software creation. As AI advances, it handles more intricate tasks, significantly reshaping how we write software.\r\n\r\nThe journey through the evolution of programming with AI can be categorized into seven distinct stages. Each stage represents a unique milestone in how AI integrates with and enhances software development.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Leadership: Architects",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "ef2bca3d-26df-4a59-a8e7-f197a34abaa9",
    "Name": "Robert Brennan",
    "Company": "All Hands AI",
    "Company Domain": "all-hands.dev",
    "Company URL": "https://www.all-hands.dev/",
    "Company Website": "https://www.all-hands.dev",
    "Title": "CEO",
    "TagLine": "CEO",
    "Bio": "Robert Brennan has been writing software for 15 years, with a focus on natural language processing and developer tools. He is currently the CEO of All Hands AI, the company behind OpenHands (formerly OpenDevin), a fully autonomous AI developer. Previously he was VP of Product Development at Fairwinds, ran a startup called Datafire, and worked as a Senior Software Engineer at Google.",
    "X (Twitter)": "https://x.com/rbren_dev",
    "LinkedIn": "https://linkedin.com/in/robert-a-brennan",
    "Blog": "https://www.all-hands.dev/blog",
    "Profile Picture": "https://sessionize.com/image/62d2-400o400o1-3DaPYZY7SULucDrMfzQzkX.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915387",
        "Title": "Software Development Agents: What Works and What Doesn't",
        "Description": "The adoption of AI into software development has been bumpy. While autocomplete tools like Copilot have gone mainstream, autonomous agents like Devin and OpenHands have generated both enthusiasm and skepticism. Some engineers claim they generate a 10x productivity boost; others that they just create noise and tech debt.\r\n\r\nThe difference between the enthusiasts and the skeptics is that the enthusiasts have reasonable expectations for what these agents can do, and have both practical and intuitive knowledge for how to use them effectively.\r\n\r\nIn this session, we'll talk about what tasks are appropriate for today's software agents, what tasks they might start to succeed at in 2025, and what tasks are best left to humans no matter how good they get.\r\n\r\nSession Outline:\r\nLearn how to use software development agents like OpenHands (fka OpenDevin) effectively, without creating noise and tech debt.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "SWE Agents",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "0d17aad6-33ce-4d6b-b31c-1ad2573841cc",
    "Name": "Christopher Chedeau",
    "Company": "Facebook",
    "Company Domain": "gmail.com",
    "Company URL": "https://web.facebook.com/",
    "Company Website": "",
    "Title": "Software Engineer",
    "TagLine": "Frenchy Front-end Engineer",
    "Bio": "Co-creator of React Native and Prettier. Creator of Excalidraw, \"CSS-in-JS\", Yoga and React Conf.",
    "X (Twitter)": "https://www.twitter.com/vjeux",
    "LinkedIn": "",
    "Blog": "https://vjeux.com",
    "Profile Picture": "https://sessionize.com/image/3247-400o400o1-MT1CZUUmYRnNRwxKuu1DMZ.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915389",
        "Title": "AI and Human Whiteboarding Partnership",
        "Description": "Covid sent everybody home and created the space of virtual whiteboards. At first the experience reused the physical constraints but soon it became better than a physical whiteboard thanks to using virtual native concepts like copy-paste and using keyboard input.\r\nThe next step in this evolution is to integrate AI into the workflow. We've tried a lot of things with Excalidraw and ended up landing on turning prompt into diagram. Come to the talk to understand how it fits into the workflow and how we implemented it.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Case Study/War Story",
        "Tracks": "Design Engineering",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "546b389a-0e78-4373-8181-ad897715e90f",
    "Name": "Kyle Kranen US",
    "Company": "NVIDIA",
    "Company Domain": "nvidia.com",
    "Company URL": "https://www.nvidia.com/en-us/",
    "Company Website": "https://www.nvidia.com/en-us/",
    "Title": "Engineering Leader",
    "TagLine": "Engineering Manager - Deep Learning Algorithms ",
    "Bio": "Kyle Kranen is an engineering leader at NVIDIA, chartered on accelerating datacenter-scale LLM performance. His work bridges engineering and research, covering topics like speculation, disaggregation, and datacenter-scale scheduling.",
    "X (Twitter)": "https://x.com/kranenkyle",
    "LinkedIn": "https://www.linkedin.com/in/kyle-kranen/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/2cb8-400o400o1-K9s17jFAKYvdpuBPwednNN.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915471",
        "Title": "Hacking the Inference Pareto Frontier for Cheaper and Faster Tokens Without Breaking SLAs",
        "Description": "Your model works! It aces the evals! It even passes the vibe check! All that’s required is inference, right? Oops, you’ve just stepped into a minefield:\r\n\r\n-Not low-latency enough? Choppy experience. Users churn from your app. \r\n-Not cheap enough? You’re losing money on every query.\r\n-Not high enough output quality? Your system can’t be used for that application.\r\n\r\nA model and the inference system around it form a “token factory” associated with a Pareto frontier— a curve representing the best possible trade-offs between cost, throughput, latency and quality, outside of which your LLM system cannot be applied successfully. \r\n\r\nOutside of the Pareto frontier? You’re back to square one.\r\nThat is, unless you’re able to change the shape of the Pareto frontier.\r\n\r\nIn this session, we’ll introduce NVIDIA Dynamo, a datacenter-scale distributed inference framework as well as the bleeding-edge techniques it enables to hack the Pareto frontier of your inference systems, including:\r\n\r\n-Disaggregation - separating phases of LLM generation to make them more efficient\r\n-Speculation - predicting multiple tokens per cycle\r\n-KV routing, storage, and manipulation - ensuring that we don’t redo work that has already been done\r\n-Pipelining improvements for agents - accelerating our workflows using information about the agent\r\n\r\nBy the end of the talk, we’ll understand how the Pareto frontier limits where models can be applied, the intuition behind how inference techniques can be used to modify it, as well as the mechanics of how these techniques work.\r\n",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Introductory (landscape)",
        "Tracks": "Infrastructure",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "15688085-28bc-44b9-9c4e-08843c881790",
    "Name": "David Hsu",
    "Company": "Retool ",
    "Company Domain": "retool.com",
    "Company URL": "https://retool.com ",
    "Company Website": "https://retool.com ",
    "Title": "Founder and CEO",
    "TagLine": "CEO",
    "Bio": "David Hsu is the Founder and CEO of Retool, the leading platform for building custom internal tools. Under his leadership, Retool has transformed how companies like Amazon, DoorDash, and Airbnb develop enterprise applications—helping them move beyond rigid SaaS solutions to AI-powered, custom-built software that fit their unique workflows. ",
    "X (Twitter)": "https://x.com/dvdhsu",
    "LinkedIn": "https://www.linkedin.com/in/dvdhsu/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/0fa4-400o400o1-JkQHMM1HQ2EBxoYgf3BoaB.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915616",
        "Title": "How agents will unlock the $500B promise of AI",
        "Description": "AI agents are on the cusp of revolutionizing work as we know it. The number of use cases software can tackle is set to explode as AI handles tasks requiring real judgment. But to cross the gap between an interesting AI prototype and an essential business tool, you need agents built by developers with real guardrails and security.\r\n\r\nThis means blending AI assistance with traditional coding in a multimodal approach that maximizes efficiency and control. The future isn't about dropping in an LLM — it requires integrating any model, any data, any system to deliver results. \r\n\r\nCompanies utilizing this approach can finally turn their slice of the $500B+ of total AI investment into real business results. \r\n",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Leadership: Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "2b6fdff3-b2d4-4765-bd3a-f6146379b99c",
    "Name": "Ben Stein",
    "Company": "Teammates",
    "Company Domain": "teammates.work",
    "Company URL": "https://www.teammates.work/",
    "Company Website": "https://www.teammates.work",
    "Title": "Founder and CEO",
    "TagLine": "CEO and Founder",
    "Bio": "Ben is a customer-obsessed technology executive and product leader who seamlessly bridges the worlds of business, product, and technology. He has repeated success leading cross-functional teams at multiple lifecycle stages, from 3x startup founder, to scaling through hypergrowth, to managing mature lines of business.\r\n\r\nIn 7 years at Twilio, Ben was GM of multiple business units (Developer Experience, Enterprise), Product Director for text messaging, and Head of R&D for Twilio.org. As CPTO at Arcadia (climate tech unicorn), he led a global team building APIs to decentralize and decarbonize the electrical grid. He cofounded multiple startups including Mobile Commons (acquired by $UPLD), an early platform for SMS marketing; and QuitCarbon, an AI platform to transition 100M homes off fossil fuels. \r\n\r\nHe is currently building Teammates, a platform for designing and managing a virtual workforce of truly autonomous virtual colleagues.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/benjaminstein/",
    "Blog": "https://www.teammates.work/blog",
    "Profile Picture": "https://sessionize.com/image/75c9-400o400o1-GdKVdseJ6n3ZLeZKRBX92L.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915648",
        "Title": "Shipping Products When You Don’t Know What they Can Do",
        "Description": "A customer recently asked me: “Hey, can I tag your AI agent in a Google Doc comment?”\r\n\r\nThe honest answer: I have no idea! We never designed our agents to handle Google Doc comments, but we tried it anyway… and it worked! The agent performed beautifully, the customer was thrilled, and I was left bewildered.\r\n\r\nWelcome to Product Management for AI agents, where roadmaps are fuzzy and we only learn the boundaries of our products after they’re released. When a product doesn’t follow predefined requirements but instead learns and improvises at runtime, PMs must give up control and lean into uncertainty, curiosity, experimentation, and fast feedback loops.\r\n\r\nThis talk is a field guide for Product/Engineering teams navigating this new reality. We’ll cover how to write specs for affordances instead of features, how to use AI evals as a product development tool, and how to perform User Acceptance Testing on undocumented emergent behavior. Most importantly, we’ll explore how to build trust with customers even when the answer is, truthfully, “I don’t know.”\r\n\r\nIf you’re managing AI-native products in 2025 the same way you managed web apps in 2020, you might find yourself A/B testing an agent that decided to go off and do C, D, and E all by themselves!\r\n",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "AI Product Management",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "8baabfb1-58b9-4ab8-b3af-95a406e99707",
    "Name": "Taylor Jordan Smith",
    "Company": "Red Hat",
    "Company Domain": "gmail.com",
    "Company URL": "",
    "Company Website": "https://www.redhat.com/en/products/ai",
    "Title": "Senior Developer Advocate",
    "TagLine": "Senior Developer Advocate",
    "Bio": "Taylor Smith, Senior Developer Advocate at Red Hat, is an advocate of open source AI innovation and democratization. She has a background in software development, open source technologies like Kubernetes and linux, and technical partnerships. Taylor loves music, animals, and helping to solve real-world problems with technology. Based out of North Carolina.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/taylorjordansmith/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/56c7-400o400o1-QwkQZaQ3HC69a4FxSMzwBT.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915684",
        "Title": "Beyond Benchmarks: Strategies for Evaluating LLMs in Production",
        "Description": "Accuracy scores and leaderboard metrics look impressive—but production-grade AI requires evals that reflect real-world performance, reliability, and user happiness. Traditional benchmarks rarely help you understand how your LLM will perform when embedded in complex workflows or agentic systems. How can you realistically and adequately measure reasoning quality, agent consistency, MCP integration, and user-focused outcomes?\r\n\r\nIn this practical, example-driven talk, we'll go beyond standard benchmarks and dive into tangible evaluation strategies using various open-source frameworks like GuideLLM and lm-eval-harness. You'll see concrete examples of how to create custom eval suites tailored to your use case, integrate human-in-the-loop feedback effectively, and implement agent reliability checks that reflect production conditions. Walk away with actionable insights and best practices for evaluating and improving your LLMs, ensuring they meet real-world expectations—not just leaderboard positions!",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Evals",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "800d4109-c399-4c21-b169-f138bfaf6087",
    "Name": "Christopher Lovejoy",
    "Company": "Anterior ",
    "Company Domain": "anterior.com",
    "Company URL": "https://www.anterior.com/",
    "Company Website": "https://www.anterior.com/",
    "Title": "Head of Clinical AI",
    "TagLine": "Head of Clinical AI ",
    "Bio": "Dr Chris Lovejoy is the Head of Clinical AI at Anterior, the AI company built by clinicians to transform healthcare administration. Chris studied Medicine at the University of Cambridge and worked as a doctor in the UK's NHS before spending the last 7 years in the world of AI start-ups, as a founder, an ML engineer and an AI consultant.",
    "X (Twitter)": "https://x.com/chrislovejoy_",
    "LinkedIn": "https://www.linkedin.com/in/dr-christopher-lovejoy/",
    "Blog": "https://chrislovejoy.me/",
    "Profile Picture": "https://sessionize.com/image/2c90-400o400o1-9zfJM31RVFL4xbuBei1o46.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915738",
        "Title": "Make your LLM app a Domain Expert: How to Build an LLM-Native Expert System",
        "Description": "Vertical AI is a multi-trillion-dollar opportunity. But you can't build a domain-expert application simply by grabbing the latest LLMs off-the-shelf: you need a system for codifying latent insights from domain experts and using that to drive development of your application.\r\n\r\nIn this talk, we'll describe the system we've built at Anterior which has enabled us to achieve SOTA clinical reasoning and serve health insurance providers covering 50 million American lives. We'll share:\r\n- how and why to encode domain-specific failure modes as an ontology\r\n- a practical system for converting domain expertise into quantifiable eval metrics\r\n- how we structure work and collaboration between our clinicians, engineer and PMs\r\n- our eval-driven AI iteration process and how this can be adapted to any industry",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Leadership: Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "a035c1ab-f6b9-40d7-b626-5b2da7f43e92",
    "Name": "Michael Hunger",
    "Company": "Neo4j",
    "Company Domain": "neotechnology.com",
    "Company URL": "https://neo4j.com/developer/",
    "Company Website": "https://neo4j.com/developer",
    "Title": "Head of Product Innovation and GenAI",
    "TagLine": "VP of Product Innovation",
    "Bio": "Michael Hunger has been passionate about software development for more than 30 years.\r\n\r\nFor the last 15 years, he has been working on the open source Neo4j graph database filling many roles, most recently heading product innovation and GenAI.\r\n\r\nAs a developer Michael enjoys many aspects of software development and architecture, learning new things every day, participating in exciting and ambitious open source projects and contributing and writing software related books and articles. Michael spoke at numerous conferences and helped organize others.\r\n\r\nMichael helps kids to learn to program by running weekly girls-only coding classes at local schools.",
    "X (Twitter)": "https://twitter.com/mesirii",
    "LinkedIn": "https://www.linkedin.com/in/jexpde/",
    "Blog": "https://medium.com/@mesirii",
    "Profile Picture": "https://sessionize.com/image/9f3e-400o400o1-LUKT2k8UpemDTxay2r5BxY.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915740",
        "Title": "Practical GraphRAG - Making LLMs smarter with Knowledge Graphs",
        "Description": "RAG has become one standard architecture component for GenAI applications to address hallucinations and integrate factual knowledge. While vector search over text is common, knowledge graphs represent a proven advancement by leveraging advanced RAG patterns to access and integrate interconnected factual information, complementing the language skills of LLMs. This talk explores GraphRAG challenges, implementation patterns, and real-world agentic examples with Google's ADK, demonstrating how this approach delivers more trustworthy and explainable GenAI solutions with enhanced reasoning capabilities.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "GraphRAG",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "874892d4-9a6d-4f7b-8b43-3a73b507f586",
    "Name": "Jesús Barrasa",
    "Company": "Neo4j",
    "Company Domain": "neo4j.com",
    "Company URL": "https://neo4j.com/",
    "Company Website": "https://neo4j.com/",
    "Title": "AI Field CTO",
    "TagLine": "AI Field CTO",
    "Bio": "Dr. Jesús Barrasa is the AI Field CTO at Neo4j, where he works with organisations combining the power of GenAI with Knowledge Graphs. He co-authored \"Building Knowledge Graphs\" (O'Reilly 2023) and is cohost of the monthly Going Meta live webcast (https://goingmeta.live/) since 2022.\r\nJesús holds a Ph.D. in Artificial Intelligence/Knowledge Representation and is an active thought leader in the KG and AI space",
    "X (Twitter)": "https://x.com/BarrasaDV",
    "LinkedIn": "https://www.linkedin.com/in/jbarrasa/",
    "Blog": "https://goingmeta.live/",
    "Profile Picture": "https://sessionize.com/image/7ff8-400o400o1-PNdKVMwQUpiXioSFyPbLaw.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915740",
        "Title": "Practical GraphRAG - Making LLMs smarter with Knowledge Graphs",
        "Description": "RAG has become one standard architecture component for GenAI applications to address hallucinations and integrate factual knowledge. While vector search over text is common, knowledge graphs represent a proven advancement by leveraging advanced RAG patterns to access and integrate interconnected factual information, complementing the language skills of LLMs. This talk explores GraphRAG challenges, implementation patterns, and real-world agentic examples with Google's ADK, demonstrating how this approach delivers more trustworthy and explainable GenAI solutions with enhanced reasoning capabilities.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "GraphRAG",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "0793b99f-1282-4674-9d21-f88e30c8232e",
    "Name": "Stephen Chin",
    "Company": "Neo4j",
    "Company Domain": "steve.chin.social",
    "Company URL": "https://neo4j.com/",
    "Company Website": "https://neo4j.com/",
    "Title": "VP of Developer Relations",
    "TagLine": "VP of Developer Relations",
    "Bio": "Stephen Chin is VP of Developer Relations at Neo4j, conference chair of the LF AI & Data Foundation, and author of numerous titles including the upcoming GraphRAG: The Definitive Guide for O'Reilly. He has given keynotes and main stage talks at numerous conferences around the world including AI Engineer Summit, AI DevSummit, Devoxx, DevNexus, JNation, JavaOne, Shift, Joker, swampUP, and GIDS. Stephen is an avid motorcyclist who has done evangelism tours in Europe, Japan, and Brazil, interviewing developers in their natural habitat. When he is not traveling, he enjoys teaching kids how to do AI, embedded, and robot programming together with his daughters.",
    "X (Twitter)": "https://twitter.com/steveonjava",
    "LinkedIn": "https://www.linkedin.com/in/steveonjava/",
    "Blog": "http://steveonjava.com/",
    "Profile Picture": "https://sessionize.com/image/67c7-400o400o1-94UgqvdxnaQUpj38o9TkBX.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915740",
        "Title": "Practical GraphRAG - Making LLMs smarter with Knowledge Graphs",
        "Description": "RAG has become one standard architecture component for GenAI applications to address hallucinations and integrate factual knowledge. While vector search over text is common, knowledge graphs represent a proven advancement by leveraging advanced RAG patterns to access and integrate interconnected factual information, complementing the language skills of LLMs. This talk explores GraphRAG challenges, implementation patterns, and real-world agentic examples with Google's ADK, demonstrating how this approach delivers more trustworthy and explainable GenAI solutions with enhanced reasoning capabilities.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "GraphRAG",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "a4f09d20-4ee3-4b43-9f2e-9afac1a1b96b",
    "Name": "Misha  Laskin",
    "Company": "Reflection",
    "Company Domain": "reflection.ai",
    "Company URL": "https://www.reflection.ai/",
    "Company Website": "https://www.reflection.ai/",
    "Title": "Co-founder and CEO",
    "TagLine": "CEO & co-founder",
    "Bio": "Misha Laskin is the co-founder and CEO of Reflection AI, a company building superintelligent coding agents. He was formerly a staff research scientist at Google DeepMind, where he worked on the Gemini RL team.",
    "X (Twitter)": "https://x.com/MishaLaskin",
    "LinkedIn": "https://www.linkedin.com/in/mishalaskin/",
    "Blog": "https://www.reflection.ai/superintelligence/",
    "Profile Picture": "https://sessionize.com/image/6313-400o400o1-GnZFh6GscoxV8XhnTNgHXT.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915745",
        "Title": "Post-Training Open Models with RL for Autonomous Coding",
        "Description": "The models and techniques to build fully autonomous coding agents - not just coding copilots - are already here. In this talk, former Google DeepMind staff research scientist, now CEO of Reflection Misha Laskin will present new research on post-training open weight LLMs for autonomous SWE tasks. He’ll focus on how scaling LLMs with Reinforcement Learning improves the autonomous coding capabilities of LLMs, and provide insight on the technical challenges required to train such systems at scale. ",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "SWE Agents",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "b2ff31e4-a1fd-4f6f-9641-87c9a23c6bb0",
    "Name": "Jared Hanson",
    "Company": "Keycard",
    "Company Domain": "keycard.sh",
    "Company URL": "https://www.keycard.sh/",
    "Company Website": "https://www.keycard.sh/",
    "Title": "Co-founder",
    "TagLine": "Co-Founder",
    "Bio": "Jared Hanson is the co-founder of Keycard, a company building identity infrastructure for the agent-native world.  Previously at Okta and Auth0, Jared is an expert on OpenID, OAuth, and all things identity.  He’s also the author of Passport.js, the popular authentication framework for Node.js.  At Keycard, he is applying that knowledge to securing AI and infrastructure.",
    "X (Twitter)": "https://x.com/jaredhanson",
    "LinkedIn": "https://www.linkedin.com/in/jaredhanson/",
    "Blog": "https://www.jaredhanson.me/",
    "Profile Picture": "https://sessionize.com/image/6bc5-400o400o1-Be3w5EvJh5jBNYPiYFm9JP.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915751",
        "Title": "How to Secure Agents using OAuth",
        "Description": "We all know sharing passwords is bad (unless you want free TV), so why are we sharing API keys with AI?  We shouldn't, and that’s why we need to talk about OAuth.\r\n\r\nIn this talk, we will give a brief intro to OAuth.  Then we will talk about the state of authorization in MCP.  We will show how an MCP client uses OAuth to authenticate a user and securely access private resources and tools hosted by an MCP server.  Then we’ll look at ways autonomous agents can use OAuth on their own behalf, talking to other agents and MCP servers directly.  We’ll learn how to use OAuth to build agents that humans and machines can trust.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Security",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "a610fd51-d488-4ee7-be82-52ba1422c6f6",
    "Name": "Jeremy Silva",
    "Company": "Freeplay",
    "Company Domain": "freeplay.ai",
    "Company URL": "https://freeplay.ai/",
    "Company Website": "https://freeplay.ai",
    "Title": "Product Lead",
    "TagLine": "Product Lead ",
    "Bio": "A seasoned ML engineer with extensive experience building and deploying language models in the healthcare sector, Jeremy currently serves as Product Lead at Freeplay. At Freeplay, he oversees an enterprise-ready platform that empowers teams to run experiments, create evaluations, monitor production systems, and label data—all within a unified environment.\r\nDrawing from hands-on collaboration with Freeplay's enterprise customers, Jeremy brings valuable \"in-the-trenches\" experience building LLM systems at scale. This direct customer engagement has also positioned him as a trusted advisor, helping organizations shape and refine their AI product roadmaps for maximum impact.\r\nJeremy’s unique perspective spans technical implementation and product development making him well-positioned to share insights on effectively bridging the gap between AI capabilities and real-world product outcomes.\r\n",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/jeremyevansilva/",
    "Blog": "https://freeplay.ai/blog",
    "Profile Picture": "https://sessionize.com/image/e41a-400o400o1-aH5xPKEYWGw2f9V1SVJTuG.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915770",
        "Title": "From Hunch to Handoff: How AI PMs Can Help Turn Ideas Into Shippable Features Quickly",
        "Description": "\"We should add AI to this!\" Great, but how do you know if your idea will actually work? The gap between AI concept and engineering reality is where most promising features die.\r\nIn this talk, we will reveal a rapid validation framework developed through working with dozens of product teams—including within Workday's AI product efforts. We'll share a three-step process that starts with lightweight prototyping, builds a relevant evaluation suite, and creates the right artifacts for successful engineering handoffs. You'll see how leading teams use this approach to explore what's possible, establish practical quality benchmarks, and align cross-functional stakeholders before writing a single line of production code.\r\nEliza Cabrera (Principal PM, Workday) and Jeremy Silva (Product Lead, Freeplay) will share the playbook they use to turn “we should add AI here” hunches into AI features customers actually use and trust.\r\nAttendees will leave with a field‑tested framework, real examples from enterprise teams, and ready‑to‑use templates that let AI PMs guide ideas from first spark to successful release—cheaply, quickly, and with confidence.\r\n",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "AI Product Management",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "b3e35f24-1320-492a-99af-40f7ae49eb82",
    "Name": "Rene Brandel",
    "Company": "Casco (YC X25)",
    "Company Domain": "gmail.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "Security Researcher",
    "TagLine": "Cofounder & CEO",
    "Bio": "https://www.youtube.com/watch?v=QAXL-Lbjf94",
    "X (Twitter)": "",
    "LinkedIn": "https://linkedin.com/in/renebrandel",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/bd86-400o400o1-VusEb89Bug3H9UGtJHm22x.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915873",
        "Title": "How we hacked YC Spring 2025 batch’s AI agents",
        "Description": "We hacked 7 of the16 publicly-accessible YC X25 AI agents. This allowed us to leak user data, execute code remotely, and take over databases. All within 30 minutes each. In this session, we'll walk through the common mistakes these companies made and how you can mitigate these security concerns before your agents put your business at risk.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Security",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "0d54907d-a141-49a3-8d3c-4f5834c0cbcf",
    "Name": "Ben Hylak",
    "Company": "Raindrop.ai",
    "Company Domain": "dawnai.com",
    "Company URL": "https://raindrop.ai/",
    "Company Website": "https://raindrop.ai",
    "Title": "Co-founder",
    "TagLine": "Co-Founder",
    "Bio": "Ben Hylak is co-founder at Raindrop, building Sentry for AI products. He was previously a designer at Apple for 4 years, building the Apple Vision Pro. ",
    "X (Twitter)": "https://x.com/benhylak",
    "LinkedIn": "https://www.linkedin.com/in/benhylak/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/8705-400o400o1-PF84iPXFpuf9ff9PC2DPYA.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915921",
        "Title": "Testing the Un-Testable: Monitoring AI Products in the Wild",
        "Description": "Evals are straightforward—like unit tests, they confirm your model got specific test cases right.\r\n\r\nBut in the real world, your AI encounters millions of unpredictable interactions each day. How do you gauge user trust, identify frustrations, and adapt when there's no single \"correct\" output? Diving through endless logs and manually adding one eval at a time won't cut it.\r\n\r\nIn this session, we'll explore how leading teams are moving beyond static evals; leveraging semantic analytics, LLM teachers, and AI-powered monitoring to deeply understand user experiences at scale—building AI products that don’t just pass tests, but genuinely resonate with users.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Evals",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "188818c8-ec9f-49ac-a4a0-3df83a99dc69",
    "Name": "Ishan Anand",
    "Company": "Independent",
    "Company Domain": "gmail.com",
    "Company URL": "https://ishananand.com/",
    "Company Website": "https://spreadsheets-are-all-you-need.ai/",
    "Title": "Vice-President of Product Management",
    "TagLine": "AI Consultant and educator",
    "Bio": "Ishan Anand is an AI consultant and technology executive specializing in Generative AI and LLMs. He created \"Spreadsheets-are-all-you-need,\" an innovative course that demystifies large language models by implementing GPT-2 entirely in Excel. As the former CTO and co-founder of Layer0 (acquired by Edgio), and most recently Vice-President of Product Management for Edgio, he's led teams in developing cutting-edge solutions in web performance, edge computing, and AI/ML for enterprise web applications. Ishan brings deep technical expertise from his dual B.S. degrees in Mathematics and EECS from MIT, combined with a unique ability to make advanced technology accessible to broader audiences.",
    "X (Twitter)": "https://x.com/ianand",
    "LinkedIn": "https://www.linkedin.com/in/ishananand/",
    "Blog": "https://ishananand.com/",
    "Profile Picture": "https://sessionize.com/image/25c1-400o400o1-TEGfyxq7PWpsZSkNUpLrhm.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915928",
        "Title": "How LLMs work for Web Devs: GPT in 600 lines of Vanilla JS",
        "Description": "Don't be intimidated. Modern AI can feel like magic, but underneath the hood are principles that web developers can understand, even if you don't have a machine learning background. In this workshop, we'll explore a complete GPT-2 inference implementation built entirely in Vanilla JS. This JavaScript translation of the popular \"Spreadsheets-are-all-you-need\" approach will let you debug and step through a real LLM line by line without the overhead of learning a new language, framework, or even IDE.\r\n\r\nAll the major LLMs, including ChatGPT, Claude, DeepSeek, and Llama, inherit from GPT-2's architecture, making this exploration a solid foundation to understand modern AI systems and comprehend the latest research.\r\n\r\nWhile we won't have time to cover *everything*, you'll gain the essential knowledge to understand the key concepts that matter when building with LLMs, including how they:\r\n\r\n-Convert raw text into meaningful tokens\r\n- Represent semantic meaning through vector embeddings\r\n- Train neural networks through gradient descent\r\n- Generate text with sampling algorithms like top-k, top-p, and temperature\r\n\r\nThis intense but beginner-friendly workshop is designed specifically for web developers diving into ML and AI for the first time. It’s your \"missing AI degree\" in just two hours. You'll walk away with an intuitive mental model of how Transformers work that you can apply immediately to your own LLM-powered projects.",
        "Format": "Workshop",
        "Level": "Introductory and overview",
        "Scope": "Technical deep dive",
        "Tracks": "AI in Action",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "53080627-1738-4e9d-b645-408278d1f012",
    "Name": "Jyh-Jing Hwang",
    "Company": "Waymo ",
    "Company Domain": "waymo.com",
    "Company URL": "https://waymo.com/",
    "Company Website": "",
    "Title": "Research Scientist and TLM",
    "TagLine": "Research Scientist & TLM ",
    "Bio": "Jyh-Jing is currently a Research Scientist and TLM at Waymo Research. He also taught machine learning and computer vision as a lecturer at UPenn MCIT Online in 2022 and 2023. Before joining Waymo in 2020, Jyh-Jing received his Ph.D. degree in Computer and Information Science from University of Pennsylvania, advised by Prof. Jianbo Shi and Prof. Stella Yu at UC Berkeley / ICSI. Before coming to the U.S., he received the B.S. and M.S. degrees from National Taiwan University and worked with Dr. Tyng-Luh Liu at Academia Sinica. His research interests are broadly in artificial intelligence, computer vision, and machine learning. Particularly, he's interested in end-to-end autonomous driving, large multimodal models, general image/video structures, and sensor fusion for robust perception.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/jyh-jing-hwang-b682b561/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/7ba6-400o400o1-EQPfTaj5r2ipiSnm9DjrFR.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915934",
        "Title": "Teaching Cars to Think: Language Models and Autonomous Vehicles",
        "Description": "This session explores Waymo's latest research on the End-to-End Multimodal Model for Autonomous Driving (EMMA) and advanced sensor simulation techniques. Jyh-Jing Hwang will demonstrate how multimodal large language models like Gemini could improve autonomous driving through unified end-to-end architectures that process raw sensor data directly into driving decisions. \r\n\r\nThe presentation will showcase EMMA's state-of-the-art performance in trajectory planning, 3D object detection, and road graph understanding, as well as another Drive&Gen research approach to sensor simulation for evaluating an end-to-end motion planning model. Attendees will gain insights into the benefits of co-training across multiple autonomous driving tasks and the potential of controlled video generation for testing under various environmental conditions.\r\n\r\nMore on EMMA here: https://waymo.com/blog/2024/10/introducing-emma\r\n",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Autonomy+Robotics",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "cf3e1c15-0b38-4e11-b24d-e94b852f9789",
    "Name": "Tejas Rajurkar",
    "Company": "AMGI Studios",
    "Company Domain": "gmail.com",
    "Company URL": "",
    "Company Website": "https://www.amgistudios.com/",
    "Title": "Artificial Intelligence Engineer",
    "TagLine": "AI Engineer Lead, AMGI Studios",
    "Bio": "Tejas Rajurkar is an Artificial Intelligence Engineer with a specialized focus on enhancing human-computer interaction through the integration of AI technologies with animation and interactive media. His work emphasizes the development of emotionally responsive, real-time AI characters by leveraging large language models (LLMs), computer vision for emotion recognition, and neural animation systems.\r\n\r\nMr. Rajurkar previously conducted research at the University of Southern California, where he focused on computer vision systems aimed at environmental monitoring and behavioral analysis. His research explored the extraction of patterns and contextual understanding from visual data in dynamic, real-world environments. He further applied these capabilities in industry at Dragonfruit AI, where he was responsible for optimizing scalable video analytics pipelines used in retail and enterprise surveillance systems.\r\n\r\nIn his current role at AMGI Studios, Mr. Rajurkar leads initiatives at the intersection of generative AI, real-time animation, and cloud infrastructure, driving innovation in how AI agents perceive, interact, and express emotion in digital environments.\r\n\r\nIn addition to his engineering contributions, he has led technical seminars and discussions at USC and has instructed students in the foundational principles of machine learning and artificial intelligence, actively contributing to the education of future AI professionals.\r\n",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/tejasrajurkar/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/920a-400o400o1-K5LUiZER516ziv97WMVdfK.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915950",
        "Title": "LLMs Come Alive: Breathing Life into LLMs with Real-Time Animation",
        "Description": "Creating AI agents that communicate naturally requires more than advanced language models—it demands believable, real-time animation that feels alive. While conversational agents excel at generating text, synchronizing expressive, Disney-level animation with real-time emotional feedback remains largely unexplored. To bridge this gap, we developed a multimodal AI architecture capable of driving real-time character animation directly from conversational context, vision-based emotion detection, and dynamically updated user profiles.\r\nIn this session, we'll share our technical journey and engineering decisions, covering:\r\n\r\nReal-Time Neural-driven Animation Pipeline: Translating LLM-generated responses into precise visemes, gestures, and expressions using a transformer-based controller, guided \r\ndynamically by lightweight vision models capturing user emotions.\r\n\r\nFlexible, Provider-Agnostic LLM Integration: Using LangChain orchestration to dynamically switch between local models, AWS Bedrock, OpenAI APIs, or private deployments—carefully balancing latency, capability, and cost trade-offs.\r\n\r\nHybrid Memory & User Profile Engine: Architecting a GDPR-compliant user profile system combining structured (SQL) and unstructured (NoSQL) data, gathering user interactions and preferences for sub-10 ms personalization lookups that dynamically influence conversations and animation.\r\n\r\nScalable, Secure Serverless Infrastructure: Docker-based deployment on AWS ECS with OAuth-secured REST APIs, optimized for auto-scaling to seamlessly handle thousands of concurrent interactions.\r\n\r\nWe'll present practical benchmarks, actionable heuristics (\"async memory prefetch,\" \"prompt-tuning vs. LoRA for personalization\"), and lessons learned. Attendees will walk away with a playbook for adapting open models into hyper‑personalized, scalable roleplay experiences.\r\n",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Generative Media",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "f328e41f-bdf7-47a1-a148-e31907578835",
    "Name": "Colin Brady",
    "Company": "AMGI Studios",
    "Company Domain": "amgistudios.com",
    "Company URL": "",
    "Company Website": "Https://Amgistudios.com",
    "Title": "Chief Creative and Technology Officer",
    "TagLine": "Chief Creative and Technology Officer, Member, Academy of Motion Picture Arts and Sciences",
    "Bio": "Profile: Colin Brady\r\n\r\nColin Brady is the Chief Creative and Technology Officer at AMGI Studios and a graduate of the California Institute of the Arts (CalArts). With a career spanning three decades, his credits include Toy Story, Toy Story 2, A Bug’s Life, Men in Black II, Hugo, The Hunger Games, and Lemony Snicket’s A Series of Unfortunate Events. He has held key creative roles at leading studios such as Pixar and Industrial Light & Magic, contributing to some of the most influential animated and visual effects-driven films of the modern era.\r\n\r\nIn addition to his film work, Colin is a pioneer in real-time animation and AI-assisted storytelling. He holds several patents in animation technology and co-founded AMGI Studios to explore the intersection of cutting-edge tools and creative expression. His focus is on building intuitive, performance-driven animation systems that empower artists to work at the speed of imagination, bringing storytelling into a new era of immediacy and innovation.",
    "X (Twitter)": "https://x.com/colin_a_brady?s=21&t=Uj3As5339A347nd3if838w",
    "LinkedIn": "https://www.linkedin.com/in/colin-brady-1441312?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=ios_app",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/bf05-400o400o1-f8K89Uek7iT6Me4iWLTrgm.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915950",
        "Title": "LLMs Come Alive: Breathing Life into LLMs with Real-Time Animation",
        "Description": "Creating AI agents that communicate naturally requires more than advanced language models—it demands believable, real-time animation that feels alive. While conversational agents excel at generating text, synchronizing expressive, Disney-level animation with real-time emotional feedback remains largely unexplored. To bridge this gap, we developed a multimodal AI architecture capable of driving real-time character animation directly from conversational context, vision-based emotion detection, and dynamically updated user profiles.\r\nIn this session, we'll share our technical journey and engineering decisions, covering:\r\n\r\nReal-Time Neural-driven Animation Pipeline: Translating LLM-generated responses into precise visemes, gestures, and expressions using a transformer-based controller, guided \r\ndynamically by lightweight vision models capturing user emotions.\r\n\r\nFlexible, Provider-Agnostic LLM Integration: Using LangChain orchestration to dynamically switch between local models, AWS Bedrock, OpenAI APIs, or private deployments—carefully balancing latency, capability, and cost trade-offs.\r\n\r\nHybrid Memory & User Profile Engine: Architecting a GDPR-compliant user profile system combining structured (SQL) and unstructured (NoSQL) data, gathering user interactions and preferences for sub-10 ms personalization lookups that dynamically influence conversations and animation.\r\n\r\nScalable, Secure Serverless Infrastructure: Docker-based deployment on AWS ECS with OAuth-secured REST APIs, optimized for auto-scaling to seamlessly handle thousands of concurrent interactions.\r\n\r\nWe'll present practical benchmarks, actionable heuristics (\"async memory prefetch,\" \"prompt-tuning vs. LoRA for personalization\"), and lessons learned. Attendees will walk away with a playbook for adapting open models into hyper‑personalized, scalable roleplay experiences.\r\n",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Generative Media",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "25d55b0c-6e2d-4f9c-ba34-a369331901ff",
    "Name": "Kyle Penfound",
    "Company": "Dagger",
    "Company Domain": "pm.me",
    "Company URL": "",
    "Company Website": "https://dagger.io",
    "Title": "Ecosystem Team Member",
    "TagLine": "Solutions Engineer at Dagger",
    "Bio": "Kyle is part of the ecosystem team at Dagger working on the future of composable software. He has a background in DevOps and just loves giving demos!",
    "X (Twitter)": "https://twitter.com/kylepenfound",
    "LinkedIn": "https://www.linkedin.com/in/kyle-penfound-12aa6a65/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/3868-400o400o1-XcdJbVzoRjt9W7CVAcRgPD.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915961",
        "Title": "Ship Agents that Ship: A Hands-On Workshop for SWE Agent Builders",
        "Description": "Coding agents are transforming how software gets built, tested, and deployed, but engineering teams face a critical challenge: how to embrace this automation wave without sacrificing trust, control, or reliability.\r\nIn this 110-minute workshop, you’ll go beyond toy demos and build production-minded AI agents using Dagger, the programmable delivery engine designed for real CI/CD and AI-native workflows. Whether you're debugging failures, triaging pull requests, generating tests, or shipping features, you'll learn how to orchestrate autonomous agents that live in and around your codebase: from your laptop to your CI platform.\r\nWe’ll guide you through:\r\n\r\nBuilding real-world agents with Dagger and popular LLMs (GPT, Claude, etc.)\r\n\r\nProgramming agent environments using real languages (Go, Python, TypeScript)\r\n\r\nExecuting agent workflows locally and in GitHub Actions, so you can bring them to production\r\n\r\nUsing a composable runtime that ensures isolation, determinism, traceability, and repeatability\r\n\r\nDesigning agents that automate and enhance debugging, test generation, code review, bug fixing, and feature implementation\r\n\r\n\r\nBy the end of the workshop, you’ll walk away ready to build your own army of autonomous agents, working collaboratively across your codebase, locally and in CI, accelerating development without ceding control. Let’s build agents that don’t just talk, they ship!",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "SWE Agents",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "f76df644-e1f1-4fb1-8e2c-8df3806cc244",
    "Name": "Jeremy Adams",
    "Company": "Dagger",
    "Company Domain": "dagger.io",
    "Company URL": "",
    "Company Website": "https://dagger.io/",
    "Title": "Senior Leader",
    "TagLine": "Head of Ecosystem",
    "Bio": "Jeremy is a senior leader with both a technical and a strategic streak. Passionate about people and entrepreneurship, integration and automation. Through technical/business roles at Dagger, GitHub, Twistlock, and Puppet, Jeremy has both zoomed in and zoomed out a lot, acquiring an appreciation for the details and an ever-broader sense of the big architectural picture.",
    "X (Twitter)": "https://twitter.com/jpadamspdx",
    "LinkedIn": "https://www.linkedin.com/in/jeremy-adams-pdx/",
    "Blog": "https://dagger.io/blog",
    "Profile Picture": "https://sessionize.com/image/b1a3-400o400o1-szYMzkLrhuNU3jSFxHoghj.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915961",
        "Title": "Ship Agents that Ship: A Hands-On Workshop for SWE Agent Builders",
        "Description": "Coding agents are transforming how software gets built, tested, and deployed, but engineering teams face a critical challenge: how to embrace this automation wave without sacrificing trust, control, or reliability.\r\nIn this 110-minute workshop, you’ll go beyond toy demos and build production-minded AI agents using Dagger, the programmable delivery engine designed for real CI/CD and AI-native workflows. Whether you're debugging failures, triaging pull requests, generating tests, or shipping features, you'll learn how to orchestrate autonomous agents that live in and around your codebase: from your laptop to your CI platform.\r\nWe’ll guide you through:\r\n\r\nBuilding real-world agents with Dagger and popular LLMs (GPT, Claude, etc.)\r\n\r\nProgramming agent environments using real languages (Go, Python, TypeScript)\r\n\r\nExecuting agent workflows locally and in GitHub Actions, so you can bring them to production\r\n\r\nUsing a composable runtime that ensures isolation, determinism, traceability, and repeatability\r\n\r\nDesigning agents that automate and enhance debugging, test generation, code review, bug fixing, and feature implementation\r\n\r\n\r\nBy the end of the workshop, you’ll walk away ready to build your own army of autonomous agents, working collaboratively across your codebase, locally and in CI, accelerating development without ceding control. Let’s build agents that don’t just talk, they ship!",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "SWE Agents",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "34a27f5f-368a-4f4a-8c7b-b0413323e035",
    "Name": "Alex Duffy",
    "Company": "Every Inc.",
    "Company Domain": "every.to",
    "Company URL": "https://every.to/",
    "Company Website": "https://every.to/",
    "Title": "Lead of AI Strategy",
    "TagLine": "Head of AI",
    "Bio": "I’m Alex Duffy. I lead AI strategy at Every Inc., helping teams across industries put AI into practice. Previously, I co-founded AI Camp, teaching thousands of students to build their own AI projects, and launched Salt AI, creating tools to help researchers, designers, and creators bring ideas to life. I’m passionate about building teams and tools to empower people with AI. I really believe in creating technology that works for us, not that is work for us. ",
    "X (Twitter)": "https://x.com/alxai_",
    "LinkedIn": "https://www.linkedin.com/in/alex-d/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/6e93-400o400o1-UDESThkaig3MRZVhYqL9r9.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915974",
        "Title": "Benchmarks Are Memes: How What We Measure Shapes AI—and Us",
        "Description": "Benchmarks shape more than just AI models—they shape our future. The things we choose to measure become self-fulfilling prophecies, guiding AI toward specific abilities and, ultimately, defining humanity’s evolving role in the AI era. Today’s benchmarks have propelled incredible progress, but now we have an exciting opportunity: thoughtfully designing benchmarks around what genuinely matters to us—cooperation, creativity, education, and meaningful human experiences.\r\n\r\nIn this talk, we’ll explore how benchmarks function as powerful cultural memes, influencing not only technical outcomes but societal direction. Drawing on practical examples we have seen at Every consulting in industries like finance, journalism, education, and even personally making AI play diplomacy. We’ll uncover what makes a benchmark impactful, approachable, and inspiring. You’ll see our engaging new AI Diplomacy benchmark demo, illustrating vividly how thoughtful evaluation design can excite both engineers and the wider community.\r\n\r\nYou’ll hopefully walk away inspired and equipped to define benchmarks intentionally, helping steer AI toward outcomes that truly matter.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Evals",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "a5eaab61-2879-4f57-a709-62c7e7562ea6",
    "Name": "Leonard Tang",
    "Company": "Haize Labs",
    "Company Domain": "haizelabs.com",
    "Company URL": "https://www.haizelabs.com/",
    "Company Website": "https://haizelabs.com/",
    "Title": "Co-founder and CEO",
    "TagLine": "Founder & CEO",
    "Bio": "I  the co-founder and CEO of Haize Labs, where we are solving the ultimate extant problem in AI: ensuring its reliability, quality, and alignment for any application. You might also know of us for our red-teaming work.\r\n\r\nPrior, I studied math and computer science at Harvard. My research then covered adversarial robustness, math reasoning, computational neuroscience, interpretability, and large(-ish) language models. Much of that has now been distilled into the Haize technology agenda. I also dropped out of, before starting, a Stanford PhD in computer science.\r\n\r\nIn the limit of my life, I am chiefly invested in starting Bell Labs 2.0.",
    "X (Twitter)": "https://twitter.com/leonardtang_",
    "LinkedIn": "https://linkedin.com/in/leonardtang",
    "Blog": "https://leonardtang.me/",
    "Profile Picture": "https://sessionize.com/image/444b-400o400o1-SHYqN26nGnPTjHAE6QVgy5.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915978",
        "Title": "Fuzzing in the GenAI Era",
        "Description": "\"Evaluation\" is one of those concepts that every AI practitioner vaguely knows is important, but few practitioners truly understand. Is \"eval\" the dataset for measuring the quality of your AI system? Is \"eval\" the measure, the metric of quality? Is \"eval\" the process of human annotation and scoring? Or is \"eval\" a third-party dataset run once to benchmark a model?\r\n\r\nTo mitigate this cacophony, this talk will provide an opinionated and principled perspective for what we actually mean when we say “evaluation”, beyond the traditional for-loop-over-a-static dataset. \r\n\r\nIn particular, this perspective draws heavy inspiration from *fuzzing*, i.e. bombarding AI with simulated, unexpected user inputs to uncover corner cases at scale. This factors into sub-problems regarding:\r\n\r\n- Quality Metric. What is the actual criteria we, as humans, are using to determine if an AI system is producing good or bad responses? How do we elicit these criteria before the human SME can articulate them? How do we, as efficiently as possible, operationalize this criteria with an automated *Judge*?\r\n\r\n- Stimuli Generation. Given a metric, how do we know, with confidence, that an AI system is performing well with respect to the metric? What data is representative and sufficient for discovering all potential bugs of an AI system? And how do we generate this complex, diverse, faithful data at scale? \r\n\r\nWe will discuss in detail the philosophy, technology, and case studies behind both problems of Quality Metric and Stimuli Generation, and how they interact in concert.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Security",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "5cdd4d44-9997-4c3c-991d-c6feba3328d3",
    "Name": "Amir Haghighat",
    "Company": "Baseten",
    "Company Domain": "baseten.co",
    "Company URL": "https://www.baseten.co/",
    "Company Website": "https://www.baseten.co/",
    "Title": "Co-founder and CTO",
    "TagLine": "Co-founder and CTO",
    "Bio": "Amir Haghighat is the co-founder and CTO at Baseten, an AI infrastructure company specializing in inference. Before Baseten, Amir led engineering teams at Clover Health and Gumroad. A graduate of UC Irvine, Amir lives in San Francisco and enjoys biking and time with his family.",
    "X (Twitter)": "https://x.com/amiruci",
    "LinkedIn": "https://www.linkedin.com/in/amirhaghighat/",
    "Blog": "https://www.baseten.co/author/amir-haghighat/",
    "Profile Picture": "https://sessionize.com/image/a46b-400o400o1-DtmYnkCjJuxXsiTRqX4hi4.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915990",
        "Title": "The Rise of Open Models in the Enterprise",
        "Description": "This year kicked off with the DeepSeek-R1 news cycle breaking out of our AI Engineering bubble into the mainstream tech and business world. Leaders at the highest levels of the largest enterprises started asking how open source models could enhance and accelerate their AI strategy.\r\n\r\nOpen source models promise increased ownership of AI systems: control over performance and price, improved uptime and reliability, better compliance, and flexible hosting options. How are these promises playing out after months of implementation? In this talk, I’ll draw on hundreds of conversations with AI leaders at enterprise companies to discuss what has — and hasn’t — changed about enterprise AI strategy in a world where open-source models compete on the frontier of intelligence.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Leadership: Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "fe4a5f0e-b102-41a2-8825-bef1760970c2",
    "Name": "Mitesh Patel",
    "Company": "NVIDIA",
    "Company Domain": "nvidia.com",
    "Company URL": "https://www.nvidia.com/location-selector/",
    "Company Website": "https://www.nvidia.com",
    "Title": "Developer Advocate Manager",
    "TagLine": "Developer Advocate Manager",
    "Bio": "Mitesh Patel is a developer advocate manager at NVIDIA. His team is responsible for creating workflows to showcase how developers can harness GPU acceleration in their workflows using tools and frameworks popular in the developer community. Before NVIDIA, he was a senior research scientist at Fuji Xerox Palo Alto Laboratory Inc. (a research subsidiary of Fuji Xerox), where he worked on developing indoor localization technologies for applications such as asset tracking in hospitals and delivery cart tracking in manufacturing facilities. Mitesh received his Ph.D. in Robotics from the Center of Autonomous Systems (CAS) at the University of Technology Sydney, Australia in 2014.",
    "X (Twitter)": "https://x.com/m_i_t_e_s_h_p",
    "LinkedIn": "https://www.linkedin.com/in/patelmiteshn/",
    "Blog": "https://developer.nvidia.com/blog/author/miteshp/",
    "Profile Picture": "https://sessionize.com/image/03bc-400o400o1-Rdpv3jcCTJeLjskuwLjyVB.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "915992",
        "Title": "HybridRAG: A Fusion of Graph and Vector Retrieval to Enhance Data Interpretation",
        "Description": "Interpreting complex information from unstructured text data poses significant challenges to Large Language Models (LLM), with difficulties often arising from specialized terminology and the multifaceted relationships between entities in document architectures. Conventional Retrieval Augmented Generation (RAG) methods face limitations in capturing these nuanced interactions, leading to suboptimal performance. In our talk, we introduce a novel approach integrating Knowledge Graph-based RAG (GraphRAG) with VectorRAG, designed to refine question-answering (Q&A) systems for more effective information extraction from complex texts. Our approach employs a dual retrieval strategy that harnesses both knowledge graphs and vector databases, enabling the generation of precise and contextually appropriate answers, thereby setting a new standard for LLMs in processing sophisticated data.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "GraphRAG",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "152141e8-8994-4813-857d-c9dedda1f73f",
    "Name": "Sahil Yadav",
    "Company": "TelemeTrak",
    "Company Domain": "outlook.com",
    "Company URL": "",
    "Company Website": "https://telemetrak.com",
    "Title": "Chief Product Officer",
    "TagLine": "Chief Product Officer",
    "Bio": "Sahil Yadav is Chief Product Officer at TelemeTrak, where he leads AI-powered infrastructure platforms for government and industrial clients. He has previously launched AI based network automation platforms at Cisco, AI driven predictive analytics products at GE, and industrial AI safety systems at Guardhat, each used by Fortune 500 firms and mission-critical operations. With 13+ years of experience in AI product management, he specializes in scaling edge/cloud AI, driving enterprise adoption and operationalizing AI trust. His expertise lies in building resilient, AI-driven systems that work where others break, behind firewalls, across compliance borders, and in zero-trust environments.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/yadavsahil/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/aa4b-400o400o1-PetSwTEPaDhLYGSGW4QQAQ.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916025",
        "Title": "CIOs and Industry Leaders: Do You Trust Your AI’s Inferences?",
        "Description": "Enterprise AI adoption is accelerating, but with it comes a hard question: Do we trust the model’s decisions? In this 18-minute talk, I’ll explore the invisible risks behind automated decision-making in safety-critical and revenue-sensitive environments. Drawing on case studies across manufacturing, telecom, and industrial IoT, I’ll highlight how explainability, traceability, and robust guardrails drive adoption and protect enterprise value.\r\nAttendees will walk away with:\r\n•\tA 3-step framework for operationalizing AI trust\r\n•\tReal-world lessons from building guardrails in on-prem and hybrid systems\r\n•\tTools and techniques for debugging and explaining inferences at scale\r\n•\tA blueprint for building trust between models, engineers, and executive stakeholders",
        "Format": "Talk",
        "Level": "Expert",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "1a0174dc-9579-4c49-ace9-af98edbf57ca",
    "Name": "Hariharan Ganesan",
    "Company": "unknown",
    "Company Domain": "umich.edu",
    "Company URL": "",
    "Company Website": "",
    "Title": "Sr. Solutions Architect",
    "TagLine": "Sr. Solutions Architect",
    "Bio": "Hari. Gn is a Sr. Solutions Architect with over 15 years of experience delivering supply-chain solutions for global companies such as Google, Wayfair, and Toyota. He specializes in demand forecasting, inventory optimization, and constraint-driven planning, translating complex analytics into actionable, real-world tools.\r\n\r\nPassionate about practical applications of Explainable AI (XAI), Hari has authored two papers in the Journal of Business Forecasting and regularly shares insights with executive-level stakeholders. He believes in a straightforward, no-nonsense approach to AI: clear, practical, and genuinely usable.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/harigsn/",
    "Blog": "https://medium.com/@harign/life-the-universe-and-everything-in-supply-chain-85d0772c79a4",
    "Profile Picture": "https://sessionize.com/image/5953-400o400o1-JQ5nmny3kR7gDvYpVbNu6B.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916025",
        "Title": "CIOs and Industry Leaders: Do You Trust Your AI’s Inferences?",
        "Description": "Enterprise AI adoption is accelerating, but with it comes a hard question: Do we trust the model’s decisions? In this 18-minute talk, I’ll explore the invisible risks behind automated decision-making in safety-critical and revenue-sensitive environments. Drawing on case studies across manufacturing, telecom, and industrial IoT, I’ll highlight how explainability, traceability, and robust guardrails drive adoption and protect enterprise value.\r\nAttendees will walk away with:\r\n•\tA 3-step framework for operationalizing AI trust\r\n•\tReal-world lessons from building guardrails in on-prem and hybrid systems\r\n•\tTools and techniques for debugging and explaining inferences at scale\r\n•\tA blueprint for building trust between models, engineers, and executive stakeholders",
        "Format": "Talk",
        "Level": "Expert",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "8da471a2-9c10-4d17-b140-5e139bb30908",
    "Name": "Ola  Mabadeje",
    "Company": "Cisco",
    "Company Domain": "cisco.com",
    "Company URL": "https://www.cisco.com/",
    "Company Website": "",
    "Title": "Leader, Generative AI Incubation",
    "TagLine": "Product Leader",
    "Bio": "With decades of experience in the tech industry, Ola is an accomplished speaker and leader in product management, specializing in the creation and scaling of ventures within emerging and disruptive domains. As a current leader in the Generative AI Incubation group at Cisco, Ola drives cutting-edge Generative AI ideas from concept to scalable and profitable businesses at startup velocity.\r\nOla's mission is to harness his cross-functional expertise and wealth of experience to drive innovation and growth in enterprise AI, Generative AI, computer vision, edge computing, and other transformative technologies that are shaping the future.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/029e-400o400o1-nd3ixD6rytghYCjpQzHfH2.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916063",
        "Title": "Leveraging Multi-Agent AI and Network Knowledge Graphs for Change Management and Network Testing",
        "Description": "Traditional ticketing and testing workflows for change management and network operations often operate independently and lack critical real-world context and adaptive decision-making capabilities. This fragmented approach results in delayed resolutions, repeated incidents, escalations, and dissatisfied stakeholders.\r\n\r\nThis session explores an innovative solution leveraging the synergy of natural language processing from IT Service Management (ITSM) systems, sophisticated Multi-agent reasoning, and dynamic context derived from live knowledge network graphs. Attendees will gain insights into an end-to-end architecture where natural language intents from ITSM tickets seamlessly integrate with AI agents specifically trained for complex workflow tasks, supported by continuous network knowledge-graph ingestion pipelines.\r\n\r\nThrough a detailed production case study, we will demonstrate how AI-powered reasoning combined with dynamic network knowledge graph contexts significantly improves critical validation and workflow interactions. The showcased results will highlight dramatic improvements in ticket resolution efficiency, accuracy of network testing, and overall execution quality, delivering tangible value to both technical teams and business stakeholders.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "GraphRAG",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "7cb31c6c-fcf2-4d0a-b4bb-6461d7776369",
    "Name": "Philip Kiely",
    "Company": "Baseten",
    "Company Domain": "baseten.co",
    "Company URL": "https://www.baseten.co/",
    "Company Website": "https://baseten.co",
    "Title": "Head of Developer Relations",
    "TagLine": "Head of Developer Relations",
    "Bio": "Philip Kiely leads Developer Relations at Baseten. Prior to joining Baseten in 2022, he worked across software engineering and technical writing for a variety of startups. Outside of work, you'll find Philip practicing martial arts, reading a new book, or cheering for his adopted bay area sports teams.",
    "X (Twitter)": "https://twitter.com/philip_kiely",
    "LinkedIn": "https://linkedin.com/in/philipkiely",
    "Blog": "https://philipkiely.com",
    "Profile Picture": "https://sessionize.com/image/9495-400o400o1-U7SVLhc5ruNbNJ5xr6KF2Z.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916066",
        "Title": "Introduction to LLM serving with SGLang",
        "Description": "Do you want to learn how to serve models like DeepSeek and Qwen with SOTA speeds on launch day? SGLang is an open-source fast serving framework for LLMs and VLMs that generates trillions of tokens per day at companies like xAI, AMD, and Meituan. This workshop guides AI engineers who are familiar with serving models using frameworks like vLLM, Ollama, and TensorRT-LLM through deploying and optimizing their first model with SGLang, as well as providing guidance on when SGLang is the appropriate tool for LLM workloads.",
        "Format": "Workshop",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Infrastructure",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "4d8f9ca5-846a-4577-a858-944d5047f16d",
    "Name": "Jordan Dearsley",
    "Company": "Vapi",
    "Company Domain": "vapi.com",
    "Company URL": "https://vapi.ai/",
    "Company Website": "https://vapi.ai/",
    "Title": "Co-founder and CEO",
    "TagLine": "Co-founder and CEO ",
    "Bio": "Jordan Dearsley is the Co-founder and CEO of Vapi, the leading developer platform for deploying voice AI agents. Previously, he was the cofounder of Superpowered, an AI notetaker for meetings. He’s a YC and AI Grant founder, a University of Waterloo dropout, and a software engineer. ",
    "X (Twitter)": "https://x.com/jordan_dearsley?",
    "LinkedIn": "https://www.linkedin.com/in/jordandearsley/",
    "Blog": "https://vapi.ai/blog",
    "Profile Picture": "https://sessionize.com/image/5431-400o400o1-EgcdABn7zzY9jFyZbH9eop.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916079",
        "Title": "Building the Voice-First Future: Omnipresent Agents that Listen, Talk and Act",
        "Description": "We’re entering a world where talking to machines feels as natural as talking to people. Voice is about to become the dominant interface for technology - ambient, always-on, and human by default. To get there, we need infrastructure that can orchestrate voice, tools, memory, real-time reasoning and telephony. This talk explores the vision for voice and how we're making it work at scale. ",
        "Format": "Talk",
        "Level": "Expert",
        "Scope": "Introductory (landscape)",
        "Tracks": "Voice",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "98dc110d-5a68-453b-b1cc-8bba6f70ba6a",
    "Name": "Jaspreet Singh",
    "Company": "Intuit",
    "Company Domain": "gmail.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "Senior Staff Software Engineer",
    "TagLine": "Senior Staff Software Engineer at Intuit",
    "Bio": "I’m Jaspreet Singh, a Senior Staff Software Engineer with 12 years of experience in the tech industry. I am the tech lead for the Smart Turbotax AI team at Intuit - focusing on development of new GenAI powered experiences in Intuit Turbotax. I have worked extensively on Personalization and Recommendations problems in the past and I’m very passionate about bringing the latest in AI to help drive Taxes are done experiences for our users. I recently became a father for the first time, and enjoy spending time with my little one. As a speaker at the AI Engineer World’s Fair, I’m excited to share our journey of transforming our user’s tax filing journeys with the power of Gen AI..",
    "X (Twitter)": "https://x.com/singh_jp",
    "LinkedIn": "https://www.linkedin.com/in/jpsingh1",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/aca7-400o400o1-JvNiKdDRX2bwTvQy7Uyzhi.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916085",
        "Title": "How Intuit uses LLMs to explain taxes to millions of taxpayers",
        "Description": "I will talk about how Intuit uses LLMs to explain tax situations to Turbotax users.\r\nUsers want explanations of their tax situations - this drives confidence in the product. Over the course of last two tax years, Intuit has built out explanations using Anthropic and openAI’s models to develop genAI powered explanations. This includes design a complex system with prompt engineered solutions and both LLM & human powered evaluations to ensure high quality bar that our users expect when filing taxes with us.\r\nDuring the course of my talk, I will talk across GenAI development lifecycle at scale - including development , evaluations and scaling. And security evaluations. We also developed a fine-tuned version of Claude Haiku & shall be covering that in the presentation.\r\nWe also expanded into tax question and answering powered by RAG, including graphRAG and I would be covering those developments too.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Leadership: Fortune 500",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "a7f032d8-e2b0-4ca5-989d-820575b736d6",
    "Name": "Annika Brundyn",
    "Company": "NVIDIA",
    "Company Domain": "nvidia.com",
    "Company URL": "",
    "Company Website": "https://www.nvidia.com/en-us/",
    "Title": "Senior Solutions Architect",
    "TagLine": "GenAI Solutions Architect @ NVIDIA",
    "Bio": "Annika Brundyn is a Senior Solutions Architect at NVIDIA focused on deploying generative AI systems in the real world. She works at the intersection of inference infrastructure, reasoning models, and retrieval pipelines, and has contributed to flagship projects like NVIDIA’s NeMo Retriever and the GR00T vision-language-action model. Her experience spans frontier model research and enterprise-grade deployment. She spends a lot of time helping models make fewer “creative” mistakes in production.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/annikabrundyn",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/80ac-400o400o1-JJGDuN81u6KSFdmYWRYLxm.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916103",
        "Title": "What Is a Humanoid Foundation Model? An Introduction to GR00T N1",
        "Description": "Foundation models don’t just write or draw anymore—they’re starting to move.\r\n\r\nGR00T N1 is NVIDIA’s open Vision-Language-Action (VLA) foundation model for humanoid robots. Built with a dual-system architecture, it combines a System 2 module for high-level reasoning with a System 1 module for real-time, fluid motor control. It’s trained end-to-end on a an impressive mix of data—from human videos to robot trajectories to synthetic simulations—and deployed on a full-sized humanoid robot performing bimanual manipulation tasks in the real world.\r\nThis talk is a high-level, beginner-friendly overview of GR00T N1:\r\n- What makes a robot foundation model different from an LLM or vision model\r\n- How GR00T’s architecture is inspired by cognitive systems\r\n- Why grounding language, vision, and action together unlocks new generalist capabilities\r\n\r\nIf you’ve ever wondered how large-scale AI is crossing over into the physical world, this session will get you up to speed—no robotics PhD required.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Autonomy+Robotics",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "85704f37-4b3d-47ef-9a67-f5cd637f6f9f",
    "Name": "Aastha Jhunjhunwala",
    "Company": "NVIDIA",
    "Company Domain": "nvidia.com",
    "Company URL": "",
    "Company Website": "https://www.nvidia.com/en-us/",
    "Title": "Solutions Architect",
    "TagLine": "Solutions Architect",
    "Bio": "Aastha Jhunjhunwala is a Solutions Architect at NVIDIA, focused on building optimized generative AI applications across industries. She works at the intersection of large-scale LLM pretraining, large language model inference, and NVIDIA’s full-stack generative AI infrastructure. Aastha has helped enterprises scale LLM workflows—from training models with billions of parameters to serving them efficiently with high-throughput inference. When she’s not working with language models, you’ll find her deep in the mountains, trading tokens for trail markers.",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/307b-400o400o1-V4tq6YkdtFNb2REDEHG7vc.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916103",
        "Title": "What Is a Humanoid Foundation Model? An Introduction to GR00T N1",
        "Description": "Foundation models don’t just write or draw anymore—they’re starting to move.\r\n\r\nGR00T N1 is NVIDIA’s open Vision-Language-Action (VLA) foundation model for humanoid robots. Built with a dual-system architecture, it combines a System 2 module for high-level reasoning with a System 1 module for real-time, fluid motor control. It’s trained end-to-end on a an impressive mix of data—from human videos to robot trajectories to synthetic simulations—and deployed on a full-sized humanoid robot performing bimanual manipulation tasks in the real world.\r\nThis talk is a high-level, beginner-friendly overview of GR00T N1:\r\n- What makes a robot foundation model different from an LLM or vision model\r\n- How GR00T’s architecture is inspired by cognitive systems\r\n- Why grounding language, vision, and action together unlocks new generalist capabilities\r\n\r\nIf you’ve ever wondered how large-scale AI is crossing over into the physical world, this session will get you up to speed—no robotics PhD required.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Autonomy+Robotics",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "59e622be-92dc-41b8-b8a5-b5a541cdff17",
    "Name": "Jeff Huber",
    "Company": "Chroma",
    "Company Domain": "trychroma.com",
    "Company URL": "https://www.trychroma.com/",
    "Company Website": "https://www.trychroma.com/",
    "Title": "CEO and cofounder",
    "TagLine": "CEO",
    "Bio": "Jeff Huber is the CEO and cofounder of Chroma. Jeff's work has been featured in TechCrunch, VentureBeat, MacWorld, GQ, Fast Company, Fortune, Forbes, Business Insider, Quartz and others. Chroma is a widely-loved and adopted open-source vector database.",
    "X (Twitter)": "https://twitter.com/jeffreyhuber",
    "LinkedIn": "https://www.linkedin.com/in/jeffchuber/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/34f2-400o400o1-rnYjraDKkutyWWRmMgtkLP.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916104",
        "Title": "How to look at your data; what to look for, how to measure",
        "Description": "By the end of this talk, you'll understand what it takes to apply clustering techniques and data analysis to understand what is the valuable work that your AI application is doing through analyzing conversation histories and how to create generative evals to benchmark your newly discovered superpowers. ",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Case Study/War Story",
        "Tracks": "Evals",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "c8042607-1aa2-4286-9a44-e8f44c0ad616",
    "Name": "Jason Liu",
    "Company": "567 Studio",
    "Company Domain": "jxnl.co",
    "Company URL": "",
    "Company Website": "",
    "Title": "Machine Learning Engineer",
    "TagLine": "Principal",
    "Bio": "Machine learning engineer, consultant, educator. ",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/a19c-400o400o1-s99sCKoyTQHKYLtEdFttto.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916104",
        "Title": "How to look at your data; what to look for, how to measure",
        "Description": "By the end of this talk, you'll understand what it takes to apply clustering techniques and data analysis to understand what is the valuable work that your AI application is doing through analyzing conversation histories and how to create generative evals to benchmark your newly discovered superpowers. ",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Case Study/War Story",
        "Tracks": "Evals",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "a79d82d4-2979-4421-bdf6-25090ac5a051",
    "Name": "Itamar Friedman",
    "Company": "Qodo",
    "Company Domain": "qodo.ai",
    "Company URL": "https://www.qodo.ai/",
    "Company Website": "https://www.qodo.ai/",
    "Title": "CEO and co-founder",
    "TagLine": "CEO & Co-founder",
    "Bio": " Itamar Friedman is the CEO and co-founder of Qodo (fka CodiumAI), the leader in the emerging code integrity space.\r\nPrior to that, Itamar was the co-founder and CTO of Visualead, which Alibaba Group acquired. As a director at Alibaba, he led teams to create innovative ML-based B2C and B2D applications and tools used by millions.\r\nItamar holds a BSc & MSc in Electrical Engineering (Summa Cum Laude) from the Technion, majoring in Machine Learning and Computer Vision.\r\n\r\n",
    "X (Twitter)": "https://x.com/itamar_mar",
    "LinkedIn": "https://www.linkedin.com/in/itamarf/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/1d5e-400o400o1-NPcEvVbuqLb2gDi2dSpNsr.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916115",
        "Title": "Vibe Coding, with Confidence",
        "Description": "Everyone wants to do Vibe Code, even large Enterprises. But how can we ensure that the generated code is well-grounded with the dev team's code and software development standards? In this talk, Itamar will present how to use various tools and agents, including MCP and A2A, to achieve precisely that.",
        "Format": "Talk",
        "Level": "Advanced",
        "Scope": "Product launch",
        "Tracks": "SWE Agents",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "9df96da4-7b00-4165-8012-072770a6618b",
    "Name": "Solomon Hykes",
    "Company": "Dagger",
    "Company Domain": "dagger.io",
    "Company URL": "https://dagger.io/",
    "Company Website": "https://dagger.io",
    "Title": "Founder and CEO",
    "TagLine": "CEO & Co-founder",
    "Bio": "Solomon Hykes is best known as the creator of Docker, the open-source platform that revolutionized software development and deployment through containerization. His work fundamentally changed how applications are built, shipped, and run by standardizing their execution environments. Drawing on his deep experience tackling complexity at the infrastructure level, Solomon is now Founder and CEO of Dagger, focusing on the foundational challenges of building and operating reliable, scalable AI agent systems. He is passionate about applying platform engineering principles to the emerging AI landscape, helping engineers navigate this technological shift and build more dependable systems.",
    "X (Twitter)": "https://x.com/solomonstre",
    "LinkedIn": "https://www.linkedin.com/in/solomonhykes/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/151f-400o400o1-K24Fa4JzDNJJBc5xKnFiZ2.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916116",
        "Title": "Containing Agent Chaos",
        "Description": "AI agents promise breakthroughs but often deliver operational chaos. Building reliable, deployable systems with unpredictable LLMs feels like wrestling fog – testing outputs alone is insufficient when the underlying workflow is opaque and flaky. How do we move beyond fragile prototypes?\r\n\r\nThis talk, from the creator of Docker, argues the solution lies *outside* the model: engineering **reproducible execution workflows** built on rigorous architectural discipline. Learn how **containerization**, applied not just to deployment but to *each individual step* of an agent's workflow, provides the essential **isolation and environmental consistency** needed.\r\n\r\nDiscover how combining this granular container approach with patterns like immutable state management allows us to **contain agent chaos**, unlock effective testing, simplify debugging, and bring essential control and predictability back to building powerful AI agents you can actually ship with confidence.",
        "Format": "Keynote",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "Infrastructure",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "c447f01b-42fd-4c76-a8f3-3ed2f73731b3",
    "Name": "Tanmai Gopal",
    "Company": "Hasura",
    "Company Domain": "hasura.io",
    "Company URL": "https://hasura.io/",
    "Company Website": "https://hasura.io",
    "Title": "Co-founder and CEO",
    "TagLine": "CEO, Co-founder",
    "Bio": "Tanmai Gopal is the co-founder and CEO of Hasura, where he has been at the forefront of rethinking how organizations access and work with data. \r\n\r\nA passionate product builder, Tanmai first led the creation of the Hasura GraphQL Engine, transforming how developers interact with data to build modern applications. Hasura has since expanded beyond developers to the enterprise level, driving the adoption of Data Delivery Network (DDN) and PromptQL—technologies that CXOs are now choosing to drive mission-critical AI transformation in their organizations.\r\n\r\nBefore Hasura, Tanmai worked with large enterprises to modernize their technology stacks, moving from monoliths to cloud-native architectures. A full-stack engineer at heart, he is passionate about building technology that increases individual agency. He also created and taught one of the largest MOOCs on modern application development at the time, reaching over 250,000 students.",
    "X (Twitter)": "https://twitter.com/tanmaigo",
    "LinkedIn": "https://www.linkedin.com/in/tanmaig/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/8ff1-400o400o1-Db44ofg5z3GckqARUUGNet.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916117",
        "Title": "AI Automation that actually works: $100M impact on messy data with zero surprises",
        "Description": "We will review the different kinds of automation use-cases, and the approach we used, that will drive over a $100M of expected annual impact by deploying AI for business critical initiatives. \r\n\r\nWe will discuss what kinds of automation initiatives become possible because of Gen AI. These were not tenable before because of the amount of customization required per customer or per scenario, and the kind of data involved in these workflows. Previously, these workflows were driven manually which were both error prone and required expensive training. \r\n\r\nTo replace or augment these manual business critical processes, automation _has_ to cross a very high bar of reliability. \r\n\r\nWe will share how we addressed the inherent non-determinism of Gen AI to create a predictable system that doesn’t have any surprising failure modes. We’ll also discuss how we worked with our existing data that was spread across various systems without an expensive centralisation and clean up effort. ",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Agent Reliability",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "ccc0c352-c059-46b2-86a0-c664d12cbb97",
    "Name": "Stefania Druga",
    "Company": "Google",
    "Company Domain": "hackidemia.com",
    "Company URL": "",
    "Company Website": "",
    "Title": "Research Scientist",
    "TagLine": "AI Research Scientist ",
    "Bio": "Hi! I am Stef. I am currently a Research Scientist in Google Gemini working on novel multimodal AI applications. Previously I was a Principal Researcher in the Center of Applied AI Research at the University of Chicago. I graduated with a Ph.D. in Creative AI Literacies 🎓 at the University of Washington Information School.\r\n\r\nMy research focuses on Large Language Models and the design of Multimodal AI tools and resources 🖌️ and during grad school I built the first open-source platform for K12 AI Education - Cognimates. When I am not coding & writing papers 👩🏽",
    "X (Twitter)": "",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/2f6a-400o400o1-BS9irYXsTStZjVqcRAwREZ.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916140",
        "Title": "Real-time Experiments with an AI Co-Scientist",
        "Description": "The sheer volume of data and complexity of modern scientific challenges necessitate tools that go beyond mere analysis. The vision of an \"AI Co-scientist\" – a true collaborative partner in the lab – requires sophisticated engineering to bridge the gap between powerful AI reasoning and the dynamic reality of physical experiments. This talk dives into the engineering required to build robust AI Co-scientists for hands-on research. We will explore scalable architectures, such as multi-agent systems leveraging foundation models like Gemini for complex reasoning, hypothesis refinement (inspired by the \"generate, debate, evolve\" paradigm described in recent AI Co-scientist research), and intelligent tool use. The core focus will be on the engineering challenges and solutions for integrating diverse, real-time empirical data streams – visual data from cameras, quantitative readings from sensors, positional feedback from actuators, and instrument outputs – directly into the AI's reasoning loop. I will illustrate this with concrete, technically detailed examples in chemistry (adaptive reaction monitoring), robotics (vision-guided assembly with SO Arm 100 and LeRobot library), and synthetic biology (real-time bacterial growth monitoring & interpretation). We'll discuss engineering strategies for handling data heterogeneity, latency, noise, and enabling the AI to interpret, correlate, and act upon live experimental feedback. Finally, we will touch upon how thoughtful engineering of these AI Co-scientists can contribute to democratizing access to advanced scientific capabilities.\r\n",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Autonomy+Robotics",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "75caaf38-093d-4f2f-b4b2-8ce5aeb4bea4",
    "Name": "Nathan Wan",
    "Company": "Ensemble Health Partners",
    "Company Domain": "ensemblehp.com",
    "Company URL": "https://www.ensemblehp.com/",
    "Company Website": "",
    "Title": "Machine Learning and Engineering Leader",
    "TagLine": "Head of AI",
    "Bio": "Nathan Wan is a machine learning and engineering leader who has built production AI systems across multiple domains before healthcare. After building speech recognition and language models and leading operational teams at Google, he led scaled platforms and teams applying AI to cancer detection and drug discovery in biotech. At Ensemble Health Partners, Nathan is leading efforts to transform RCM into a tech-driven performance engine.",
    "X (Twitter)": "",
    "LinkedIn": "https://www.linkedin.com/in/nwan1/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/c9a8-400o400o1-RyRmUSQEcH7GZDx9rw5zAE.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916157",
        "Title": "AI That Pays: Lessons from Revenue Cycle",
        "Description": "While much of the AI innovation in healthcare has centered on clinical and patient-facing applications, Revenue Cycle Management (RCM) remains an underexplored yet critical domain. Given the growing financial pressures facing providers, rethinking how healthcare gets paid is essential to ensuring access and sustainability. The combination of which makes RCM an opportune area for AI disruption.\r\n\r\nThis session explores how the combination of vast structured and unstructured data, often rule-based workflows, and direct financial opportunity to drive meaningful outcomes. We’ll also share practical lessons from our journey evolving a traditional machine learning mindset to incorporate the latest advances in Generative AI, and how that shift is reshaping what's possible in healthcare operations.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Leadership: Architects",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "4e01104b-7d8e-4552-9224-6b7bd4f697fa",
    "Name": "Jesse Han",
    "Company": "Morph Labs",
    "Company Domain": "morph.so",
    "Company URL": "https://morph.so/",
    "Company Website": "https://morph.so",
    "Title": "Founder and CEO",
    "TagLine": "Founder",
    "Bio": "Jesse Han is the Founder and CEO of Morph Labs, a company building the infrastructure for the singularity. Morph is the creator of Infinibranch, a breakthrough in cloud technology that enables scaling train-time and test-time search for agentic reasoning models. Jesse began his career as a pure mathematician and research scientist at OpenAI working on test-time compute scaling, GPT-4, and reasoning.",
    "X (Twitter)": "https://twitter.com/jessemhan",
    "LinkedIn": "https://linkedin.com/in/jesse-michael-han",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/8a20-400o400o1-hXqkB3J73tudpxqaiDoWtB.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916189",
        "Title": "The infrastructure for the singularity",
        "Description": "We're at an inflection point where AI agents are transitioning from experimental tools to practical coworkers. This new world will demand new infrastructure for RL training, test-time scaling, and deployment. This is why Morph Labs developed Infinibranch last year, and we are excited to finally unveil what's next.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Product launch",
        "Tracks": "Infrastructure, Reasoning+RL",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "48bba77e-6187-42e9-bfd3-10c9ae781b89",
    "Name": "Philipp Krenn",
    "Company": "Elastic",
    "Company Domain": "xeraa.net",
    "Company URL": "",
    "Company Website": "https://www.elastic.co",
    "Title": "Head of Developer Relations",
    "TagLine": "Code and conference monkey",
    "Bio": "Philipp leads Developer Relations at Elastic — the company behind the Elasticsearch, Kibana, Beats, and Logstash. Based in San Francisco, he lives to demo interesting technology and solve challenging problems — all with a smile and a terminal window.",
    "X (Twitter)": "https://twitter.com/xeraa",
    "LinkedIn": "https://www.linkedin.com/in/philippkrenn/",
    "Blog": "https://xeraa.net/blog/",
    "Profile Picture": "https://sessionize.com/image/1520-400o400o1-75c94302-4b9c-4e3c-9e0a-42ee715c44a5.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916214",
        "Title": "Information Retrieval from the Ground Up",
        "Description": "Vector search is only a feature. Search engines and information retrieval have retaken their position as the foundation of RAG. This workshop takes you through decades of research, what has been working for a long time, and how it got better with Machine Learning.",
        "Format": "Workshop",
        "Level": "Introductory and overview",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "e5bc5c02-d408-4cb9-b70e-32ac94965e00",
    "Name": "Sherwood Callaway",
    "Company": "11x AI",
    "Company Domain": "gmail.com",
    "Company URL": "https://www.11x.ai/",
    "Company Website": "https://www.11x.ai/",
    "Title": "Engineering Manager",
    "TagLine": "Tech Lead, Alice ",
    "Bio": "Sherwood Callaway is an emerging leader in the world of AI startups and AI product development. He currently serves as the first engineering manager at 11x, a series B AI startup backed by Benchmark and Andreessen Horowitz, where he oversees technical work on \"Alice\", an AI sales rep that outperforms top human SDRs.\r\n\r\nAlice is an advanced agentic AI working in production and at scale. Under Sherwood’s leadership, the system grew from initial prototype to handling over 1 million prospect interactions per month across 300+ customers, leveraging partnerships with OpenAI, Anthropic, and LangChain while maintaining consistent performance and reliability. Alice is now generating eight figures in ARR.\r\n\r\nSherwood joined 11x in 2024 through the acquisition of his YC-backed startup, Opkit, where he built and commercialized one of the first-ever AI phone calling solutions for a specific industry vertical (healthcare). Prior to Opkit, he was the second infrastructure engineer at Brex, where he designed, built, and scaled the production infrastructure that supported Brex’s application and engineering org through hypergrowth. He currently lives in San Francisco, CA.",
    "X (Twitter)": "https://x.com/realshcallaway",
    "LinkedIn": "https://www.linkedin.com/in/sherwoodcallaway/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/d508-400o400o1-PYvpvjHEzP33kV7TZ5WgNo.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916215",
        "Title": "Ingest, Chunk, Retrieve: How We Built an AI Sales Rep that Trains Herself",
        "Description": "AI agents and digital workers are becoming an essential tool for teams of all sizes and across all industries. However, training these agents to become experts in your product, business, and customers remains a significant challenge. But what if onboarding a digital worker was as simple as uploading your pitch deck? At 11x, we built Alice, an AI sales rep that writes outbound emails with the nuance and context of a top-performing human - because she learns like one too.\r\n\r\nIn this talk, we'll share how we built a RAG system that lets users train Alice on their internal materials: PDFs, websites, call recordings, and more. We'll walk through our ingestion flow, OCR and chunking pipeline, and explain how we leveraged different technologies and vendors to support a wide-range of file types. We'll also discuss how we leveraged Pinecone and other vector embedding technologies to drive relevant, high-performing messaging. Finally, I'll share what we’ve learned running this system in production across 300+ customers and over 1m prospect interactions each month.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Retrieval+Search",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "78e6fb6b-5779-484c-b0ae-1b721861eb76",
    "Name": "Satwik Singh",
    "Company": "11x AI",
    "Company Domain": "gmail.com",
    "Company URL": "https://11x.ai/",
    "Company Website": "https://11x.ai",
    "Title": "Member of Technical Staff",
    "TagLine": "Member of Technical Staff ",
    "Bio": "Satwik Singh is a core builder and emerging technical leader in the rapidly evolving field of applied AI and agentic systems. As a Member of Technical Staff at 11x AI, Satwik is at the forefront of developing \"Alice\", an AI sales representative that operates autonomously at scale—transforming how modern GTM teams work.\r\n\r\nAt 11x, Satwik has architected and delivered several of the company's most critical agent capabilities. He led the creation of the Knowledge Base Retrieval-Augmented Generation (RAG) and Deep Research pipeline, which powers Alice's ability to reason over complex product information and tailor responses with high fidelity: a first-of-its-kind system in the GTM agent space. He has also worked across systems to handle the credits ledger, and engineered the Sourcing Agent that autonomously crafts campaigns. Satwik has been instrumental in shaping the technical foundation of Alice's intelligence and reliability.\r\n\r\nPrior to 11x, Satwik was a software engineer at Meta, where he worked on Generative AI products within the Core Ads organization and contributed to infrastructure across Reality Labs. His work helped ship first-generation GenAI creative enhancements for Feed Ads—driving significant revenue gains at scale.\r\n\r\nSatwik's unique strength lies in his ability to move seamlessly between infrastructure, AI product, and agent behavior—designing systems that are production-ready, high-impact, and aligned with real business outcomes. With deep hands-on experience and a vision for what Agentic AI can become, he's helping define the next era of intelligent software.",
    "X (Twitter)": "https://x.com/ayravart",
    "LinkedIn": "https://linkedin.com/in/itsmesatwik",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/2fa7-400o400o1-7W6CXjsx33yL3yMziQtfZd.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "916215",
        "Title": "Ingest, Chunk, Retrieve: How We Built an AI Sales Rep that Trains Herself",
        "Description": "AI agents and digital workers are becoming an essential tool for teams of all sizes and across all industries. However, training these agents to become experts in your product, business, and customers remains a significant challenge. But what if onboarding a digital worker was as simple as uploading your pitch deck? At 11x, we built Alice, an AI sales rep that writes outbound emails with the nuance and context of a top-performing human - because she learns like one too.\r\n\r\nIn this talk, we'll share how we built a RAG system that lets users train Alice on their internal materials: PDFs, websites, call recordings, and more. We'll walk through our ingestion flow, OCR and chunking pipeline, and explain how we leveraged different technologies and vendors to support a wide-range of file types. We'll also discuss how we leveraged Pinecone and other vector embedding technologies to drive relevant, high-performing messaging. Finally, I'll share what we’ve learned running this system in production across 300+ customers and over 1m prospect interactions each month.",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Case Study/War Story",
        "Tracks": "Retrieval+Search",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "262b6964-1097-4c41-9117-4fbf9aefb088",
    "Name": "Andreas Kollegger",
    "Company": "Neo4j",
    "Company Domain": "neo4j.com",
    "Company URL": "https://neo4j.com/",
    "Company Website": "https://neo4j.com",
    "Title": "unknown",
    "TagLine": "GenAI Lead for Developer Relations",
    "Bio": "Andreas is a technological humanist. Starting at NASA, Andreas designed systems from scratch to support science missions. Then in Zambia, he built medical informatics systems to apply technology for social good. Now with Neo4j, he is democratizing graph databases to validate and extend our intuitions about how the world works. Everything is connected. ",
    "X (Twitter)": "https://twitter.com/akollegger",
    "LinkedIn": "https://www.linkedin.com/in/akollegger/",
    "Blog": "https://neo4j.com/blog/developer/",
    "Profile Picture": "https://sessionize.com/image/9be1-400o400o1-3z1SkCUTLZX6NamTinAsif.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "921229",
        "Title": "Agentic Insights through Graph Analytics",
        "Description": "Advanced GraphRAG techniques apply graph ML and algorithms, wrapped into a tidy agent.",
        "Format": "Workshop",
        "Level": "Advanced",
        "Scope": "Technical deep dive",
        "Tracks": "GraphRAG",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "b51b2de9-bffc-4fca-ab1c-ecfd3932e0de",
    "Name": "Grant Lee",
    "Company": "Gamma",
    "Company Domain": "gamma.app",
    "Company URL": "https://gamma.app/",
    "Company Website": "https://gamma.app/",
    "Title": "Founder",
    "TagLine": "CEO",
    "Bio": "Grant has spent the past 10+ years building tech startups and has a background in finance and operations. He was interim CFO at Optimizely and the COO of Clearbrain, two YC startups. He grew up in the bay area and studied at Stanford, where he received his B.S. and M.S. in mechanical engineering. He is currently building Gamma, an AI-powered platform to create presentations, websites, and more.",
    "X (Twitter)": "https://x.com/thisisgrantlee",
    "LinkedIn": "https://www.linkedin.com/in/grantslee/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/a75a-400o400o1-BszmV4DtgcRQUsqSxSd7QT.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "923914",
        "Title": "Tiny Teams",
        "Description": "Sean reached out on X, happy to do a talk on how to build a tiny team",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "Tiny Teams",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "13aa4fa5-29c4-4019-b4e1-ee83caaecb54",
    "Name": "Jerry Liu",
    "Company": "LlamaIndex",
    "Company Domain": "runllama.ai",
    "Company URL": "llamaindex.ai",
    "Company Website": "",
    "Title": "Co-founder/CEO",
    "TagLine": "CEO",
    "Bio": "Jerry is the co-founder/CEO of LlamaIndex, the most accurate and flexible way to automate your document workflows with AI agents. Before this, he led the ML monitoring team at Robust Intelligence, did self-driving AI research at Uber ATG and worked on recommendation systems at Quora.",
    "X (Twitter)": "https://twitter.com/jerryjliu0",
    "LinkedIn": "https://www.linkedin.com/in/jerry-liu-64390071/",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/61b9-400o400o1-3brCmcVKAHmSGaKS6QsZmA.jpg",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "925259",
        "Title": "Building AI Agents that actually automate Knowledge Work",
        "Description": "Agents are all the rage in 2025, and every single b2b SaaS startup/incumbent promises AI agents that can \"automate work\" in some way. \r\n\r\nBut how do you actually build this? The answer is two fold: \r\n1. really really good tools \r\n2. carefully tailored agent reasoning over these tools that range from assistant-to-automation based UXs.  \r\n\r\nThe main goal of this talk is to a practical overview of agent architectures that can automate real-world work, with a focus on document-centric tasks. Learn the core building blocks of best-in-class \"tools\" around processing, manipulating, and indexing/retrieving PDFs to Excel spreadsheets. Also learn the range of agent architectures suited for different tasks, from chat assistant-based UXs with high human-in-the-loop, to automation UXs that rely on encoding a business process into an end-to-end task solver. These architectures have to be generalizable but also highly accurate as agents get increasingly better at reasoning and code-writing. ",
        "Format": "Talk",
        "Level": "Intermediate",
        "Scope": "Technical deep dive",
        "Tracks": "Retrieval+Search",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  },
  {
    "Speaker ID": "d2b57aa6-3078-480f-9bd9-c695ca74ede4",
    "Name": "Raiza Martin",
    "Company": "Huxe",
    "Company Domain": "gmail.com",
    "Company URL": "huxe.com",
    "Company Website": "",
    "Title": "Product Leader",
    "TagLine": "CEO & Co-Founder Huxe || Previously NotebookLM",
    "Bio": "A product leader with a unique lens on AI's user experience challenges, Raiza brings insights from both big tech and startup trenches. \r\n\r\nMost recently leading Google's NotebookLM team, she has shaped how millions of users interact with generative AI. Now, as a founder, she is reimagining these experiences from first principles. \r\n\r\nWith years of hands-on PM experience guiding technical teams through the practical realities of shipping AI products, Raiza offers a rare combination of enterprise-scale perspective and startup-speed execution.",
    "X (Twitter)": "https://x.com/raizamrtn",
    "LinkedIn": "",
    "Blog": "",
    "Profile Picture": "https://sessionize.com/image/4455-400o400o1-wqpaVc41zMJrRTRDbX6dtU.png",
    "Session Count": 1,
    "Sessions": [
      {
        "Session ID": "925337",
        "Title": "Everything is ugly so go build something that isn't",
        "Description": "We're in an awkward adolescent phase of AI product (design). But what if this chaotic moment is actually our greatest opportunity? Enter the rebuilding revolution.\r\n\r\nIn this talk, we'll explore how the current state of AI interfaces offers a once-in-a-career chance to rethink fundamental UX patterns, with practical guidance on avoiding common pitfalls that plague first-generation AI products. \r\n\r\nLearn how to balance technical constraints with user needs, identify which conventional wisdom to keep versus discard, and ship AI experiences that actually delight users rather than frustrate them.",
        "Format": "Talk",
        "Level": "Introductory and overview",
        "Scope": "Introductory (landscape)",
        "Tracks": "AI Product Management",
        "Room": "",
        "Scheduled At": ""
      }
    ]
  }
]